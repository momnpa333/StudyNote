### 1. 쿠키와 세션의 차이에 대해 설명해 주세요.
##### 설명
쿠키와 세션은 **웹에서 사용자의 상태(로그인 여부, 장바구니 정보 등)를 유지하기 위해 사용하는 기술**입니다. 하지만 동작 방식과 저장 위치가 다릅니다. 정리해 드리겠습니다.

---
 📌 쿠키(Cookie)

- **저장 위치**: 클라이언트(사용자 브라우저)에 저장
    
- **동작 방식**: 서버가 클라이언트에게 키-값 형태의 데이터를 응답 헤더(Set-Cookie)로 전달 → 이후 클라이언트는 요청 시 자동으로 쿠키를 포함해서 서버로 전송
    
- **특징**
    
    - 클라이언트에 저장되므로 서버 부하가 적음
        
    - 보안에 취약할 수 있음 (조작 가능, 탈취 가능 → HTTPS + HttpOnly, Secure 옵션으로 보완)
        
    - 용량 제한(브라우저마다 다르지만 보통 4KB 정도)
        
    - 만료 시간 설정 가능 (세션 쿠키: 브라우저 종료 시 삭제, 지속 쿠키: 설정된 만료 시간까지 유지)
        

---
📌 세션(Session)

- **저장 위치**: 서버에 저장 (일반적으로 메모리, Redis, DB 등)
    
- **동작 방식**:
    
    1. 사용자가 로그인하면 서버에서 세션을 생성하고 고유한 **세션 ID**를 발급
        
    2. 세션 ID는 클라이언트 측 쿠키에 저장됨(JSESSIONID 등)
        
    3. 이후 클라이언트가 요청을 보낼 때 세션 ID를 쿠키로 전달 → 서버가 해당 세션 ID로 사용자 정보를 조회
        
- **특징**
    
    - 중요한 데이터는 서버에만 저장되므로 비교적 안전
        
    - 서버 리소스를 사용하므로 사용자가 많을수록 서버 부담 증가
        
    - 브라우저를 종료하거나 일정 시간이 지나면 세션이 만료됨(타임아웃)
        

---
 📊 쿠키 vs 세션 비교

| 구분    | 쿠키(Cookie)        | 세션(Session)              |
| ----- | ----------------- | ------------------------ |
| 저장 위치 | 클라이언트(브라우저)       | 서버                       |
| 보안    | 상대적으로 취약          | 상대적으로 안전                 |
| 서버 부담 | 없음                | 있음 (메모리/스토리지 사용)         |
| 용량 제한 | 4KB 내외            | 제한 없음(서버 자원 한도 내)        |
| 유지 기간 | 만료 시간에 따라 다름      | 서버 설정된 타임아웃 동안 유지        |
| 활용 예시 | 자동 로그인, 사용자 맞춤 설정 | 로그인 유지, 장바구니, 인증된 사용자 정보 |

---

✅ **정리**
- **쿠키**는 클라이언트 쪽에 간단한 정보를 저장해두고 서버와 주고받는 데 사용.
- **세션**은 중요한 데이터를 서버에 저장하고 클라이언트는 세션 ID만 전달해서 식별.
- 보통은 **세션 기반 로그인 + 쿠키에 세션 ID 저장** 방식이 많이 쓰입니다.

세션 기반 로그인과 JWT 기반 로그인은 현대 웹 서비스에서 가장 많이 비교되는 인증 방식입니다. 차이점을 보안·성능·확장성 관점에서 정리해 드리겠습니다.

---
🔑 세션(Session) 기반 로그인

동작

- 로그인 시 서버가 세션을 생성하고 사용자 정보를 저장.
    
- 클라이언트는 세션 ID만 쿠키에 저장하고, 이후 요청마다 세션 ID를 서버로 전달.
    
- 서버가 세션 저장소에서 ID → 사용자 정보를 조회하여 인증.
    
✅ 장점

- **보안성 높음**: 클라이언트는 세션 ID만 가지고 있으므로 실제 정보 노출 위험이 낮음.
    
- **상태 관리 용이**: 로그인뿐 아니라 장바구니, 임시 데이터 등 다양한 상태 저장 가능.
    
- **세션 무효화 쉬움**: 서버에서 세션 삭제하면 즉시 로그아웃 처리 가능.
    

❌ 단점

- **확장성 문제**: 서버 여러 대 운영 시 세션 동기화 필요 (Sticky Session, Redis 같은 중앙 저장소 필요).
    
- **서버 리소스 부담**: 사용자 수가 많으면 세션 저장소 관리 비용 증가.
    

🪙 JWT(JSON Web Token) 기반 로그인

동작

- 로그인 성공 시 서버가 **JWT(서명된 토큰)**를 발급하여 클라이언트에 전달.
    
- 클라이언트는 JWT를 쿠키나 LocalStorage 등에 저장.
    
- 이후 요청 시 JWT를 함께 전송 → 서버는 토큰 검증(서명 확인)만으로 사용자 인증.
    
✅ 장점

- **무상태(Stateless)**: 서버에 별도 세션 저장 필요 없음 → 확장성이 뛰어남 (서버 증설/로드밸런싱에 유리).
    
- **빠른 인증**: DB/Redis 조회 없이 토큰만 검증하면 됨.
    
- **다중 서비스 연동 용이**: 마이크로서비스 아키텍처(MSA)에서 중앙 인증 서버가 JWT 발급 → 각 서비스가 독립적으로 검증 가능.
    
❌ 단점

- **토큰 크기**: JWT는 서명·페이로드 포함 → 세션 ID보다 큼, 매 요청마다 전송되어 네트워크 부하 발생 가능.
    
- **보안 관리 난이도**:
    
    - 탈취되면 만료 전까지 무조건 유효 → 서버에서 강제로 무효화하기 어려움 (블랙리스트 관리 필요).
        
    - LocalStorage 저장 시 XSS에 취약.
        
- **변경 불가**: 한 번 발급된 JWT는 수정 불가 → 사용자 권한 변경 시 반영 어려움(Refresh Token 전략 필요).
    

---
📊 세션 vs JWT 비교 요약

|구분|세션(Session)|JWT|
|---|---|---|
|저장 위치|서버(세션 저장소)|클라이언트|
|서버 확장성|낮음 (세션 동기화 필요)|높음 (무상태)|
|서버 부하|많음 (세션 관리)|적음 (토큰 검증만)|
|인증 속도|세션 조회 필요|서명 검증만으로 빠름|
|보안성|높음 (서버 관리)|중간 (탈취 시 만료 전까지 위험)|
|무효화 용이성|쉬움 (서버에서 세션 삭제)|어려움 (블랙리스트/만료 관리 필요)|
|토큰 크기|작음 (세션 ID)|큼 (페이로드 포함)|
|활용 예시|전통적인 웹/모놀리식 앱|MSA, 모바일, API 서버 간 인증|

---

✅ **정리**

- **세션 기반**: 보안이 중요하고 서버 규모가 크지 않은 경우 적합 (예: 기업 내부 시스템, 소규모 웹 서비스).
    
- **JWT 기반**: 확장성과 API 간 인증이 중요한 경우 적합 (예: 모바일 앱 + 서버, MSA 환경, 대규모 분산 서비스).
##### 세션 방식의 로그인 과정에 대해 설명해 주세요.
세션(Session) 방식의 로그인은 **서버가 사용자 인증 상태를 직접 관리하는 방식**입니다. 과정별로 단계적으로 정리해 드리겠습니다.

---
 🔑 세션 기반 로그인 과정
 1. 로그인 요청

- 사용자가 로그인 페이지에서 **아이디/비밀번호**를 입력하여 서버로 전송합니다.
    
- 일반적으로 **POST /login** 요청을 통해 전달되며, 이때는 아직 세션이 없습니다.
    

---
2. 인증 처리

- 서버는 DB 등에 저장된 사용자 정보를 확인하여 **아이디/비밀번호 일치 여부**를 검증합니다.
    
- 검증에 성공하면 새로운 **세션(Session 객체)**을 생성하고, 사용자 정보를 세션에 저장합니다.
    
    - 예: `session.setAttribute("userId", 1234)`
        

---
 3. 세션 ID 발급

- 서버는 생성된 세션에 대한 고유한 식별자(**세션 ID**)를 만듭니다.
    
- 이 세션 ID를 응답 헤더의 `Set-Cookie`에 담아 브라우저로 전송합니다.
    
    - 예: `Set-Cookie: JSESSIONID=abc123xyz; HttpOnly; Secure`
        
- 브라우저는 이 쿠키를 저장합니다.
    

---
4. 인증된 요청

- 이후 사용자가 다른 페이지 요청을 보낼 때마다 브라우저는 자동으로 쿠키(JSESSIONID)를 포함해 서버에 요청을 보냅니다.
    
- 서버는 세션 저장소(메모리, Redis, DB 등)에서 **세션 ID → 세션 객체**를 찾아 사용자 정보를 확인합니다.
    
- 이를 통해 서버는 사용자를 식별하고 로그인 상태를 유지할 수 있습니다.
    

---
 5. 로그아웃 / 세션 만료

- 사용자가 로그아웃하면 서버는 세션을 삭제합니다.
    
- 또는 설정된 **세션 타임아웃(예: 30분)**이 지나면 자동으로 세션이 만료됩니다.
    
- 만료되면 쿠키에 세션 ID가 있어도 더 이상 유효하지 않으므로 다시 로그인해야 합니다.
    

---
 📊 요약 (흐름도 형태)

1. 클라이언트 → 서버: 아이디/비밀번호 전송
    
2. 서버: 사용자 검증 → 세션 생성 → 세션 ID 발급
    
3. 서버 → 클라이언트: 세션 ID를 쿠키에 담아 응답
    
4. 클라이언트: 쿠키(JSESSIONID) 저장
    
5. 이후 요청 시 쿠키 자동 전송 → 서버에서 세션 조회로 로그인 상태 유지
    
6. 로그아웃 or 세션 만료 → 세션 삭제
    

---

✅ **핵심 포인트**

- 실제 사용자 정보(아이디, 권한 등)는 **서버 세션 저장소에 저장**
    
- 클라이언트에는 **세션 ID(토큰 역할)**만 쿠키로 저장
    
- 따라서 **보안상 쿠키 조작으로는 서버의 세션 정보를 바꿀 수 없음**
##### HTTP의 특성인 Stateless에 대해 설명해 주세요.
좋은 질문입니다 👍  
HTTP의 핵심적인 특징 중 하나가 바로 **Stateless(무상태성)**입니다. 차근차근 설명드리겠습니다.

---
📌 Stateless란 무엇인가?

- **Stateless**란, **서버가 클라이언트의 이전 요청 상태를 보존하지 않는 특성**을 말합니다.
    
- 즉, HTTP 요청(Request) 하나하나는 독립적으로 처리되며, 서버는 **이전 요청과 현재 요청을 연결해서 기억하지 않습니다.**
    
- 매 요청은 완전히 새로운 요청으로 간주되고, 필요한 모든 정보가 요청에 포함되어야 합니다.
    

---
📌 Stateless의 특징

1. **독립성**
    
    - 각 요청은 독립적으로 처리됨 → 이전 요청의 맥락(Context)을 서버가 기억하지 않음.
        
2. **무상태성**
    
    - 서버는 클라이언트의 로그인 상태, 세션 정보 등을 기본적으로 저장하지 않음.
        
3. **요청에 필요한 정보 포함**
    
    - 클라이언트가 서버에 요청할 때, 인증/파라미터 등 필요한 정보를 항상 함께 보내야 함.
        

---
 📌 장점

- **서버 확장성(Scalability) 향상**:  
    서버가 클라이언트 상태를 기억할 필요가 없으므로, 여러 서버를 두어도 부하 분산이 쉽습니다.
    
- **단순함(Simple)**:  
    서버는 요청만 처리하면 되고, 별도의 상태 관리 로직이 필요 없습니다.
    
- **유연한 서비스**:  
    클라이언트가 어느 서버에 요청하더라도 같은 응답을 받을 수 있습니다. (Load Balancing에 적합)
    

---
📌 단점

- **상태 유지가 필요한 경우 불편**  
    예: 로그인, 장바구니 등 "이전 요청의 맥락"이 필요한 경우, HTTP의 Stateless 특성만으로는 부족합니다.
    
- **추가 메커니즘 필요**  
    → 그래서 등장한 것이 **쿠키, 세션, JWT** 등 상태를 유지하기 위한 기술입니다.
    

---
 📌 예시

- 사용자가 로그인 후 "내 정보 조회" 요청을 보낸다고 가정해 봅시다.
    
- **Stateless 환경**이라면 서버는 이전 로그인 사실을 기억하지 않으므로,  
    매번 요청에 로그인 정보(아이디/비밀번호 or 토큰 등)를 포함해야 합니다.
    

---

✅ **정리**

- **HTTP는 기본적으로 Stateless**: 요청과 응답 간에 상태를 저장하지 않음.
    
- **장점**: 단순성, 확장성, 부하 분산 용이.
    
- **단점**: 로그인/장바구니처럼 상태 유지가 필요한 경우 불편 → 이를 해결하기 위해 쿠키/세션/JWT 같은 보조 기술 사용.
##### Stateless의 의미를 살펴보면, 세션은 적절하지 않은 인증 방법 아닌가요?
HTTP의 **Stateless(무상태성)**와 **세션(Session) 기반 인증**은 얼핏 보면 서로 상충하는 개념처럼 보입니다. 하지만 실제 서비스에서는 **Stateless 특성을 유지하면서도 상태 유지가 필요한 요구사항을 해결하기 위해 세션을 도입**하는 것이죠. 정리해 드리겠습니다.

---
📌 Stateless의 원칙

- HTTP는 본질적으로 **Stateless**: 서버는 클라이언트의 요청 간 상태를 기억하지 않습니다.
    
- 따라서 각 요청은 독립적이며, 서버는 "이전 요청에서 로그인 했는지" 같은 맥락을 알 수 없습니다.
    
- 원칙적으로라면, **클라이언트는 매 요청마다 인증 정보를 모두 포함해야 한다**는 의미입니다. (예: `Authorization` 헤더에 토큰)
    

---
 📌 세션(Session) 기반 인증은 왜 Stateless와 어긋나는가?

- 세션은 서버가 **사용자의 로그인 상태를 서버 저장소에 유지**하는 방식입니다.
    
- 즉, 서버가 클라이언트의 상태(로그인 여부, 사용자 ID 등)를 "기억"하는 것이므로 **Strict한 의미에서 Stateless와는 맞지 않습니다.**
    
- 서버 간 확장 시 세션 동기화 문제(Sticky Session, Redis 공유 등)가 생기는 이유도 바로 상태를 서버가 보관하기 때문입니다.
    

---
📌 그럼에도 세션이 널리 쓰이는 이유

1. **보안성**
    
    - 서버가 직접 상태를 관리하므로 토큰 탈취, 위·변조 위험이 상대적으로 적습니다.
        
2. **구현 용이성**
    
    - 초기 웹 애플리케이션(모놀리식 구조)에서는 서버 메모리에 세션 저장하는 방식이 가장 단순하고 직관적이었음.
        
3. **서비스 요구사항 충족**
    
    - 로그인 유지, 장바구니, 맞춤형 서비스 같은 기능은 **상태(state)** 없이는 구현하기 어렵기 때문입니다.
        

---
📌 대안: JWT와 같은 토큰 기반 인증

- **JWT 기반 인증**은 **Stateless 원칙에 더 부합**합니다.
    
    - 서버는 상태를 저장하지 않고, 클라이언트가 JWT를 매 요청마다 전송.
        
    - 서버는 단순히 토큰의 서명을 검증하는 것만으로 인증을 수행.
        
- 다만, JWT는 무효화가 어렵고 탈취 시 보안 문제가 있으므로, Refresh Token, 블랙리스트 등 보완 장치가 필요합니다.
    

---
📊 정리

- **Stateless 원칙**: 서버는 요청 간 상태를 기억하지 않는다.
    
- **세션 인증**: 서버가 상태(로그인)를 저장하므로 원칙과는 다소 어긋남.
    
- **실무 선택**:
    
    - **소규모/전통 웹**: 세션 기반 → 구현 간단, 보안 용이.
        
    - **대규모/분산 시스템(MSA, 모바일, API 서버)**: JWT 기반 → 확장성, Stateless에 가까움.
        

---

👉 따라서 면접에서 답변할 때는 이렇게 말하면 좋습니다:  
“**세션은 HTTP의 Stateless 특성과는 어긋나는 방식이지만, 보안성과 편의성 때문에 오랫동안 표준적인 로그인 방식으로 사용되었습니다. 반면 JWT 같은 토큰 기반 인증은 Stateless 원칙에 더 충실해 대규모 분산 환경에서 적합합니다.**”
##### 규모가 커져 서버가 여러 개가 된다면, 세션을 어떻게 관리할 수 있을까요?
단일 서버 환경에서는 세션을 서버 메모리에 두면 간단하지만, **규모가 커져 서버가 여러 대(멀티 서버, 분산 환경)**가 되면 문제가 생깁니다.  
왜냐하면, 사용자가 A 서버에서 로그인했더라도, 다음 요청이 B 서버로 가면 세션 정보가 없기 때문입니다.  
이를 해결하기 위해 몇 가지 방법이 있습니다.

---
 📌 세션 관리 방식 (멀티 서버 환경)
1. **Sticky Session (세션 고정화)**

- **로드밸런서**가 클라이언트의 요청을 항상 같은 서버로 전달하도록 함.
    
- 즉, A 서버에서 로그인한 사용자는 이후에도 계속 A 서버로만 요청이 가도록 설정.
    
- **장점**: 구현 간단, 기존 세션 관리 방식 그대로 사용 가능.
    
- **단점**: 특정 서버에 부하 집중, 서버 장애 시 세션 유실 위험.
    

---
 2. **세션 복제(Session Replication)**

- 각 서버가 자신의 세션을 다른 서버와 **동기화(복제)**하여 동일한 세션 정보를 유지.
    
- 사용자가 A 서버에서 로그인해도, B/C 서버에 세션이 자동 반영됨.
    
- **장점**: 장애 대응 가능, 어느 서버로 가도 동일 세션 유지.
    
- **단점**: 서버 간 네트워크 트래픽과 동기화 비용이 크다. (사용자 많아지면 비효율적)
    

---
3. **공유 세션 저장소 사용 (가장 많이 쓰임)**

- 세션을 서버 메모리에 두지 않고, **외부 저장소(공유 DB, Redis, Memcached 등)**에 저장.
    
- 각 서버는 클라이언트의 세션 ID를 받아서 이 저장소에서 사용자 정보를 조회.
    
- **장점**: 확장성 높음, 서버 장애에도 세션 유지.
    
- **단점**: 저장소 장애 시 전체 서비스에 영향 → 보통 Redis 클러스터 같은 고가용성 구조 사용.
    
- **실무 표준**: 대부분 Redis 같은 인메모리 DB를 세션 저장소로 활용.
    

---
4. **세션 대신 JWT 같은 토큰 기반 인증 사용**

- 아예 세션 저장 자체를 없애고, 클라이언트가 인증 정보를 담은 토큰(JWT)을 요청마다 전송.
    
- 서버는 상태를 저장하지 않고, 토큰 검증만으로 인증 처리 → Stateless 보장.
    
- **장점**: 확장성 최강, 서버 간 동기화 필요 없음.
    
- **단점**: 토큰 무효화가 어렵고, 탈취 시 위험 → Refresh Token, 블랙리스트 관리 필요.
    

---
📊 비교 요약

| 방법               | 특징             | 장점                   | 단점                    |
| ---------------- | -------------- | -------------------- | --------------------- |
| Sticky Session   | 특정 서버에 묶음      | 구현 간단                | 서버 장애 시 세션 유실, 부하 불균형 |
| 세션 복제            | 서버 간 세션 동기화    | 장애 대응 가능             | 동기화 비용 큼              |
| 공유 저장소 (Redis 등) | 중앙 저장소에 세션 저장  | 확장성, 장애 대응           | 저장소 의존성 ↑             |
| JWT              | 세션 없이 토큰 기반 인증 | 완전 Stateless, 확장성 최강 | 무효화 어려움, 탈취 시 위험      |

---

✅ **정리**  
규모가 커진다면 보통 **공유 세션 저장소(특히 Redis)**를 두고, 세션을 중앙에서 관리하는 방식이 가장 일반적입니다.  
더 나아가 마이크로서비스 환경에서는 **JWT 같은 토큰 기반 인증**으로 넘어가는 경우가 많습니다.

---

면접에서 이 질문을 받는다면 이렇게 답하면 좋습니다:  
“**멀티 서버 환경에서는 Sticky Session, 세션 복제, 공유 세션 저장소 같은 방식을 고려할 수 있습니다. 특히 실무에서는 Redis 같은 인메모리 저장소를 세션 서버로 두는 방식이 가장 흔하고, 더 큰 규모로 가면 JWT 기반 인증을 도입하여 Stateless를 보장하는 경우도 많습니다.**”
### 2. HTTP 응답코드에 대해 설명해 주세요.
##### 설명
📌 HTTP 응답 코드 분류

1xx : Informational (정보)

- 요청을 잘 받았으며, 계속 진행 중임을 알림.
    
- **예시**
    
    - **100 Continue**: 요청의 일부를 받았으니 계속 전송하라는 의미. (대용량 업로드 시 유용)
        
    - **101 Switching Protocols**: 프로토콜 전환(WebSocket 등).
        

---
2xx : Success (성공)

- 클라이언트의 요청이 성공적으로 처리됨.
    
- **예시**
    
    - **200 OK**: 요청 성공 (가장 일반적).
        
    - **201 Created**: 요청 성공, 새로운 리소스가 생성됨 (POST로 회원가입, 글쓰기 등).
        
    - **204 No Content**: 요청 성공했지만 응답 본문 없음 (예: DELETE 요청).
        

---
 3xx : Redirection (리다이렉션)

- 요청한 리소스가 다른 위치로 이동했음을 알려줌. 클라이언트는 새로운 URL로 재요청 필요.
    
- **예시**
    
    - **301 Moved Permanently**: 리소스가 영구적으로 다른 URL로 이동.
        
    - **302 Found**: 일시적으로 다른 URL 사용.
        
    - **304 Not Modified**: 클라이언트 캐시 사용해도 됨 (조건부 GET 요청 시).
        

---
4xx : Client Error (클라이언트 오류)

- 클라이언트 잘못된 요청. (URI 오류, 권한 부족, 잘못된 데이터 등)
    
- **예시**
    
    - **400 Bad Request**: 잘못된 요청 (파라미터 오류, 형식 오류 등).
        
    - **401 Unauthorized**: 인증 필요 (로그인 안 함, 토큰 없음/잘못됨).
        
    - **403 Forbidden**: 인증했지만 권한 없음 (접근 금지).
        
    - **404 Not Found**: 요청한 리소스 없음.
        
    - **405 Method Not Allowed**: 허용되지 않은 HTTP 메서드 사용.
        

---
5xx : Server Error (서버 오류)

- 서버에서 요청을 처리하는 도중 문제가 발생.
    
- **예시**
    
    - **500 Internal Server Error**: 일반적인 서버 오류.
        
    - **502 Bad Gateway**: 게이트웨이/프록시 서버가 잘못된 응답을 받음.
        
    - **503 Service Unavailable**: 서버 과부하, 점검 중.
        
    - **504 Gateway Timeout**: 게이트웨이/프록시 서버가 응답을 제때 받지 못함.
        

---
📊 요약표

| 구분  | 범위      | 의미       | 대표 코드                                                               |
| --- | ------- | -------- | ------------------------------------------------------------------- |
| 1xx | 100~199 | 정보 전달    | 100 Continue                                                        |
| 2xx | 200~299 | 성공       | 200 OK, 201 Created                                                 |
| 3xx | 300~399 | 리다이렉션    | 301 Moved Permanently, 302 Found                                    |
| 4xx | 400~499 | 클라이언트 오류 | 400 Bad Request, 401 Unauthorized, 403 Forbidden, 404 Not Found     |
| 5xx | 500~599 | 서버 오류    | 500 Internal Server Error, 502 Bad Gateway, 503 Service Unavailable |

---

✅ **정리**

- 1xx: 진행 중 알림
    
- 2xx: 성공
    
- 3xx: 다른 곳으로 이동
    
- 4xx: 클라이언트 잘못
    
- 5xx: 서버 잘못
##### 401 (Unauthorized) 와 403 (Forbidden)은 의미적으로 어떤 차이가 있나요?
📌 401 Unauthorized

- **의미**: _"인증(Authentication)이 필요하다"_
    
- 서버가 사용자를 **식별할 수 없거나**, 제공한 인증 정보가 유효하지 않은 경우 발생합니다.
    
- 즉, "누군지 모르겠다 → 먼저 로그인부터 해라"에 해당합니다.
    
- **예시 상황**
    
    - 로그인하지 않은 사용자가 인증이 필요한 API 호출.
        
    - 잘못된 토큰/만료된 토큰을 보낸 경우.
        
    - 잘못된 아이디/비밀번호 입력 시.
        

👉 해결 방법: **올바른 인증 정보(로그인, 토큰 등)를 제공**해야 함.

---
 📌 403 Forbidden

- **의미**: _"인증은 되었지만, 권한(Authorization)이 부족하다"_
    
- 서버는 사용자를 알고 있고 인증도 성공했지만, 요청한 자원에 접근할 권한이 없을 때 발생합니다.
    
- 즉, "누군지는 알겠는데, 이 자원은 네 권한 밖이야"에 해당합니다.
    
- **예시 상황**
    
    - 일반 사용자가 관리자(admin) 전용 페이지 접근 시.
        
    - 특정 게시물은 본인만 볼 수 있는데, 다른 사용자가 접근했을 때.
        
    - 권한 레벨이 낮은 사용자가 금지된 API 호출.
        

👉 해결 방법: **권한을 부여하거나 요청 자원 접근 자체를 막아야 함.**

---
📊 요약 비교

| 코드                   | 이름    | 의미              | 상황                 |
| -------------------- | ----- | --------------- | ------------------ |
| **401 Unauthorized** | 인증 실패 | "누군지 몰라"        | 로그인 안 함, 잘못된/만료 토큰 |
| **403 Forbidden**    | 권한 거부 | "누군진 알지만 권한 없음" | 일반 유저가 관리자 기능 접근   |

---

✅ **정리**

- **401 → 인증(Authentication) 문제**: "로그인 필요"
    
- **403 → 인가(Authorization) 문제**: "권한 부족"
    

---

면접 대비 짧게 답한다면 이렇게 말할 수 있습니다:

> **401은 인증이 안 된 상태(로그인 필요), 403은 인증은 되었지만 권한이 없는 상태를 의미합니다.**
##### 200 (ok) 와 201 (created) 의 차이에 대해 설명해 주세요.
📌 200 OK

- **의미**: 요청이 정상적으로 처리되었음을 의미.
    
- 가장 범용적으로 사용되는 응답 코드.
    
- 보통 **조회(READ)**, **수정(UPDATE)**, **삭제(DELETE)** 같은 요청에서 많이 사용됨.
    
- **예시 상황**
    
    - `GET /users/1` → 해당 유저 정보 반환 성공.
        
    - `PUT /users/1` → 수정 성공 후 결과 반환.
        
    - `DELETE /users/1` → 삭제 성공 후 결과 반환.
        

👉 핵심: **리소스의 생성이 일어나지 않고**, 기존 리소스를 정상적으로 조회/수정/삭제했을 때 사용.

---
📌 201 Created

- **의미**: 요청 성공 + **새로운 리소스가 생성되었음**을 의미.
    
- 보통 **생성(CREATE)** 요청 (`POST`)에서 사용됨.
    
- 응답 시에는 보통 **Location 헤더**에 생성된 리소스의 URI를 포함하는 것이 REST Best Practice.
    
- **예시 상황**
    
    - `POST /users` → 새로운 유저가 생성됨 → **201 Created** + `Location: /users/123`
        
    - `POST /articles` → 새 게시글 작성됨 → **201 Created** + 생성된 게시글 내용 반환
        

👉 핵심: **새로운 리소스가 생성되었을 때** 반드시 201을 사용.

---
📊 비교 요약

| 코드              | 의미             | 사용 상황               | 예시                             |
| --------------- | -------------- | ------------------- | ------------------------------ |
| **200 OK**      | 요청 성공          | 조회/수정/삭제 등 일반 요청    | `GET /users/1`, `PUT /users/1` |
| **201 Created** | 요청 성공 + 리소스 생성 | 리소스가 새로 생길 때 (POST) | `POST /users` → 새 유저 생성        |

---

✅ **정리**

- **200 OK** → 요청 성공 (리소스 상태가 변하지 않거나 단순히 갱신된 경우)
    
- **201 Created** → 요청 성공 + 새로운 리소스 생성됨 (생성된 리소스 위치를 알려주는 게 권장됨)
    

---

면접에서 짧게 답변한다면 이렇게 말하면 좋습니다:

> **200은 요청 성공을 의미하고, 201은 성공과 동시에 새로운 리소스가 생성되었음을 의미합니다. 예를 들어 GET/PUT/DELETE는 200, POST는 보통 201을 사용합니다.**
##### 필요하다면 저희가 직접 응답코드를 정의해서 사용할 수 있을까요? 예를 들어 285번 처럼요.
HTTP 응답코드(Status Code)는 **IANA(Internet Assigned Numbers Authority)**에서 표준으로 관리합니다. 그래서 **100~599 범위의 상태 코드는 표준에 정의된 의미를 따라야 하고**, 임의로 정의해서 사용하면 브라우저나 클라이언트 라이브러리에서 오해가 생길 수 있습니다.

---
📌 1. 응답 코드 범위

- **100~599**: HTTP 표준에서 예약된 영역 (이미 정의된 코드들).
    
- **600 이상**: 표준이 아닌 영역. 클라이언트는 보통 알 수 없는 코드로 처리합니다.
    

---
📌 2. 임의 코드 정의 가능 여부

- **기술적으로는 가능**합니다. 서버는 285 같은 코드를 응답으로 내려줄 수 있습니다.
    
- 하지만 클라이언트(브라우저, HTTP 라이브러리)가 이 코드를 인식하지 못하면 **"알 수 없는 상태 코드"**로만 처리하고, 의미를 해석하지 못합니다.
    
- 예: 브라우저는 2xx면 성공, 4xx면 클라이언트 오류, 5xx면 서버 오류로 범주를 구분합니다.
    
    - 따라서 285는 "2xx 범위 → 성공" 정도로만 이해됩니다.
        

---
 📌 3. 실무에서 권장되는 방식

1. **표준 코드 내에서 의미를 맞춰 쓰기**
    
    - 예를 들어 `200 OK`, `202 Accepted`, `422 Unprocessable Entity` 등 이미 존재하는 코드를 상황에 맞게 사용하는 게 최선.
        
    - REST API 설계 가이드에서도 "가급적 표준 코드 사용"을 강하게 권장합니다.
        
2. **표준 코드 + 응답 바디 활용**
    
    - 세부적인 비즈니스 상황은 응답 바디(JSON 등)에 커스텀 에러 코드를 정의해 전달합니다.
        
    - 예:
        
        `{   "errorCode": "USER-285",   "message": "비밀번호 5회 이상 틀림" }`
        
    - 이렇게 하면 클라이언트가 표준 코드(예: 403 Forbidden)로 1차 처리하고, 바디의 커스텀 코드를 통해 세부 상황을 구분할 수 있습니다.
        
3. **헤더 활용**
    
    - 필요하다면 커스텀 헤더(`X-Error-Code`)를 정의해 추가 정보를 제공할 수도 있습니다.
        

---
📊 정리

- 285 같은 응답 코드를 **기술적으로는 정의할 수 있지만**, **표준이 아니므로 권장되지 않습니다.**
    
- 보통은 **표준 HTTP Status Code + 응답 바디의 커스텀 에러 코드** 조합을 사용합니다.
    
- 예: 로그인 실패 시 → `401 Unauthorized` + JSON 바디에 `"errorCode": "AUTH-001"`
    

---

👉 면접에서 답할 때는 이렇게 말하면 좋습니다:

> “HTTP 응답코드는 표준에 따라 해석되므로 285처럼 임의로 정의하는 것은 권장되지 않습니다. 대신 표준 코드를 사용하면서, 추가적인 의미가 필요하다면 응답 바디에 별도의 커스텀 에러 코드를 정의해 전달하는 것이 일반적인 방식입니다.”
맞습니다 🙂  
말씀처럼 **클라이언트와 서버가 미리 약속만 한다면, 285 같은 비표준 상태 코드를 사용하는 것도 기술적으로는 가능합니다.**  
즉, 서버가 `285`를 내리고 클라이언트가 `"아, 이건 우리 서비스에서 비밀번호 5회 이상 틀린 상태구나"`라고 이해할 수 있다면 기능적으로 동작하는 데는 문제가 없습니다.

하지만 여기에는 **표준과 실무적인 관점에서의 리스크**가 존재합니다.

---

📌 클라이언트와 약속하면 충분하지 않은 이유

1. **표준성 저하**
    
    - HTTP는 전 세계적으로 표준화된 프로토콜입니다.
        
    - 상태 코드를 임의로 정의하면, API Gateway, 로드밸런서, 보안 장비, 모니터링 시스템 같은 **중간 장치들이 해석하지 못하는 상태**가 생깁니다.
        
    - 예: `285`는 표준이 아니므로 모니터링 도구에서는 단순히 `"Unknown 2xx code"`로만 기록됩니다.
        
2. **호환성 문제**
    
    - 다른 팀이나 외부 시스템에서 API를 사용할 경우, `285`의 의미를 알지 못하면 혼란이 생깁니다.
        
    - 특히 SDK, 라이브러리(fetch, axios, OkHttp 등)는 2xx 범위를 그냥 `"성공"`으로 처리해 버립니다 → 클라이언트는 의도한 분기 처리를 못할 수 있습니다.
        
3. **장기 유지보수의 어려움**
    
    - 지금은 “우리 클라이언트만 쓰니까 괜찮아”라고 해도, 나중에 API를 공개하거나, 다른 시스템과 연동해야 한다면 문제가 됩니다.
        
    - REST API Best Practice 문서나 Swagger/OpenAPI 문서에서도 비표준 상태코드는 권장하지 않습니다.
        

---
📌 실무에서의 대안 (Best Practice)

👉 그래서 실무에서는 다음과 같은 방식을 씁니다:

- **표준 Status Code 사용**:
    
    - 예: 인증 실패 시 `401 Unauthorized`, 권한 부족 시 `403 Forbidden`
        
- **세부 에러는 바디에서 정의**:
    
    `{   "errorCode": "AUTH-005",   "message": "비밀번호 5회 이상 틀림" }`
    
    - 이렇게 하면 **표준 해석 가능 + 클라이언트와의 상세 약속도 가능**합니다.
        

---
📊 정리

- **클라이언트와 서버가 약속하면 비표준 코드(285 등)도 사용 가능**합니다.
    
- 하지만 **표준 해석 불가, 호환성 문제, 유지보수 문제** 때문에 권장되지 않습니다.
    
- 따라서 **실무에서는 표준 상태코드를 쓰고, 추가 의미는 바디(JSON 등)에서 커스텀 코드로 정의**하는 방식을 선택합니다.
    

---

👉 면접 답변 팁:  
“**285 같은 비표준 코드를 내려도 클라이언트와 약속하면 동작은 합니다. 다만 HTTP는 표준 프로토콜이라 중간 장비나 라이브러리가 알 수 없는 상태가 되어버립니다. 그래서 보통은 표준 Status Code를 지키고, 세부 상황은 응답 바디의 커스텀 코드로 표현하는 것이 가장 실무적입니다.**”

### 3. HTTP Method 에 대해 설명해 주세요.
##### 설명
좋은 질문입니다 🙂  
HTTP Method(메서드)는 **클라이언트가 서버의 리소스에 대해 어떤 동작을 요청하는지 표현하는 방식**입니다.  
즉, 같은 URL(예: `/users`)이라도 메서드에 따라 의미가 달라집니다.

---
📌 주요 HTTP 메서드
 1. **GET**

- 리소스 조회(Read)
    
- 요청 본문(body) 없음, 필요한 데이터는 보통 쿼리 파라미터(`?id=1`)로 전달
    
- 응답에 리소스 데이터가 담김
    
- **특징**:
    
    - 멱등성(Idempotent) 보장 (몇 번 요청해도 결과 동일)
        
    - 캐싱 가능        

---
2. **POST**

- 리소스 생성(Create)
    
- 요청 본문(body)에 데이터 포함하여 서버에 전송
    
- 서버는 새로운 리소스를 만들고 보통 `201 Created` 반환
    
- **특징**:
    
    - 멱등성이 없음 (같은 요청을 여러 번 보내면 데이터가 중복 생성될 수 있음)
---
3. **PUT**

- 리소스 전체 수정(Update)
    
- 요청 본문에 해당 리소스를 **완전히 대체할 데이터**를 담음
    
- 예: `PUT /users/1` → user 1번의 모든 속성을 새 데이터로 교체
    
- **특징**:
    
    - 멱등성 있음 (같은 요청을 여러 번 보내도 결과 동일)
        

---
4. **PATCH**

- 리소스 부분 수정(Partial Update)
    
- 리소스의 일부분만 변경할 때 사용
    
- 예: `PATCH /users/1` → user 1번의 `email`만 수정
    
- **특징**:
    
    - 멱등성을 보장하지 않을 수도 있음 (구현 방식에 따라 다름)
        

---
5. **DELETE**

- 리소스 삭제(Delete)
    
- 예: `DELETE /users/1` → user 1번 삭제
    
- **특징**:
    
    - 멱등성 있음 (같은 요청 여러 번 보내도 결과는 "삭제됨")
        

---
6. **HEAD**

- GET과 동일하지만 응답 본문(body)을 반환하지 않음
    
- 주로 **메타데이터(헤더)만 확인**할 때 사용 (파일 크기 확인, 리소스 존재 여부 체크 등)
    

---
7. **OPTIONS**

- 서버가 해당 리소스에 대해 지원하는 메서드를 알려줌
    
- 예: `OPTIONS /users` → `Allow: GET, POST, PUT, DELETE`
    
- **CORS(교차 출처 요청)** 사전 요청(Preflight Request)에서 사용
    

---
8. **TRACE**

- 요청이 서버까지 도달하는 경로를 따라 그대로 되돌려주는 메서드 (디버깅용)
    
- 보안상의 이유로 거의 사용되지 않음
    

---
📊 정리 (CRUD 매핑)

|Method|동작|CRUD 매핑|특징|
|---|---|---|---|
|GET|조회|READ|멱등성 있음, 캐싱 가능|
|POST|생성|CREATE|멱등성 없음|
|PUT|전체 수정|UPDATE|멱등성 있음|
|PATCH|부분 수정|UPDATE|멱등성 보장 안 될 수도 있음|
|DELETE|삭제|DELETE|멱등성 있음|
|HEAD|헤더만 조회|-|본문 없음|
|OPTIONS|지원 메서드 조회|-|CORS Preflight|
|TRACE|경로 추적|-|보안상 거의 안 씀|

---

✅ **정리**

- HTTP 메서드는 **리소스에 대한 의도(조회, 생성, 수정, 삭제 등)**를 명확히 나타내기 위한 규약입니다.
    
- RESTful API 설계에서는 주로 **GET, POST, PUT, PATCH, DELETE** 5개가 핵심적으로 쓰입니다.
##### HTTP Method의 멱등성에 대해 설명해 주세요.
📌 멱등성(Idempotency) 이란?

- 어떤 연산을 여러 번 반복해도 결과가 동일하게 유지되는 성질을 말합니다.
    
- 즉, 같은 요청을 1번 보내나 100번 보내나 **최종 결과는 동일**해야 합니다.
    

---
📌 HTTP Method와 멱등성
 ✅ 멱등성을 보장하는 메서드

- **GET**:
    
    - 단순 조회 → 몇 번 호출해도 리소스 변화 없음.
        
- **PUT**:
    
    - 전체 리소스를 대체 → 같은 데이터로 여러 번 갱신해도 결과는 동일.
        
    - 예: `PUT /user/1` {name: "Kim"} → 몇 번 호출해도 user 1의 name은 "Kim".
        
- **DELETE**:
    
    - 삭제 요청을 여러 번 보내도 최종 상태는 "삭제됨".
        
- **HEAD**:
    
    - GET과 동일하지만 본문 없이 헤더만 반환 → 조회이므로 멱등성 있음.
        
- **OPTIONS**:
    
    - 단순히 메서드 지원 여부를 반환 → 멱등성 있음.
        

❌ 멱등성을 보장하지 않는 메서드

- **POST**:
    
    - 새로운 리소스 생성 → 같은 요청을 여러 번 보내면 리소스가 계속 늘어남.
        
    - 예: `POST /users` {name: "Kim"} → 호출할 때마다 새로운 유저 생성.
        
- **PATCH**:
    
    - 부분 수정 → 구현 방식에 따라 다름.
        
    - 예: "잔액 +1000" 같은 연산이라면 멱등성이 없음, "잔액을 1000으로 변경"이라면 멱등성이 있음.
        

---
📊 정리 (멱등성 여부)

|Method|멱등성 여부|이유|
|---|---|---|
|GET|✅ 있음|조회만 하므로 상태 변화 없음|
|POST|❌ 없음|호출할 때마다 새로운 리소스 생성 가능|
|PUT|✅ 있음|동일한 리소스로 대체하므로 결과 동일|
|PATCH|⚠️ 경우에 따라 다름|값 덮어쓰기면 있음, 누적 연산이면 없음|
|DELETE|✅ 있음|여러 번 호출해도 최종 상태는 “삭제됨”|
|HEAD|✅ 있음|조회만 하므로 동일|
|OPTIONS|✅ 있음|메서드 정보만 반환|

---
📌 정리

- **멱등성은 "최종 상태"가 동일해야 한다는 개념**입니다.
    
- 멱등성이 있으면 클라이언트나 중간 네트워크 장비(프록시, 로드밸런서 등)가 재시도 로직을 구현할 때 안전합니다.
    
- 따라서 REST API 설계에서는 **POST를 제외한 대부분의 메서드는 멱등성을 지키도록 구현하는 것이 원칙**입니다.

📌 왜 멱등성이 중요한가?

네트워크 환경에서는 요청이 전송 중 끊기거나, 서버가 응답을 주기 전에 클라이언트가 타임아웃을 오해할 수 있습니다.  
이때 클라이언트나 프록시 서버는 **"혹시 실패했나?" 하고 같은 요청을 재전송**할 수 있습니다.

- 만약 그 메서드가 **멱등하다면**, 재시도를 해도 서버의 최종 상태는 동일 → 안전.
    
- 멱등하지 않다면, 같은 요청이 중복 적용되어 원하지 않는 결과가 발생.
    

---
📌 시나리오별 예시

 1. GET (멱등 O)

`GET /users/1`

- 유저 1번 정보 요청.
    
- 1번 보내나 100번 보내나 결과는 동일 → **재시도해도 안전**.
    

---
2. PUT (멱등 O)

`PUT /users/1 { "name": "Kim" }`

- user 1의 name을 "Kim"으로 덮어쓰기.
    
- 네트워크 오류로 요청이 두 번 가도 최종적으로 name은 "Kim" → **안전**.
    

---
3. DELETE (멱등 O)

`DELETE /users/1`

- user 1을 삭제.
    
- 첫 번째 요청에 이미 삭제됨 → 두 번째 요청은 "이미 없음"만 반환.
    
- 최종 상태는 동일 → **안전**.
    

---
4. POST (멱등 ✗)

`POST /orders { "item": "Book" }`

- 주문 생성.
    
- 네트워크 오류로 요청이 두 번 가면 → 같은 주문이 2개 생성됨.
    
- 최종 상태가 달라지므로 멱등하지 않음 → **주의 필요**.
    

---
 5. PATCH (조건부)

`PATCH /users/1 { "point": +1000 }`

- 포인트 1000 증가 요청.
    
- 두 번 가면 최종적으로 +2000 → **멱등하지 않음**.
    

`PATCH /users/1 { "point": 1000 }`

- 포인트를 1000으로 설정.
    
- 몇 번 가도 최종 상태는 동일 → **멱등**.
    

---
 📊 정리

- **멱등성 있는 메서드(GET, PUT, DELETE)** → 네트워크 재시도 상황에서도 안전.
    
- **멱등성 없는 메서드(POST, 일부 PATCH)** → 재시도 시 의도치 않은 중복 결과 가능 → 중복 방지 로직(Idempotency Key 등) 필요.
    

---

✅ 면접 답변용 한 줄 요약:

> "멱등성은 네트워크 장애로 요청이 중복 전송되더라도 최종 상태가 변하지 않는 성질입니다. GET, PUT, DELETE는 안전하지만, POST는 멱등하지 않아 중복 생성 문제가 생길 수 있습니다."

POST는 본질적으로 **“새로운 리소스를 생성”**하는 동작이라 멱등하지 않은데, 실무에서는 **중복 생성 방지**를 위해 여러 방법을 씁니다.

---
📌 1. Idempotency Key (멱등성 키)

- **클라이언트가 요청마다 고유한 키(Idempotency-Key)를 생성해서 함께 전송**
    
- 서버는 이 키를 저장하고, 같은 키가 다시 들어오면 **중복 생성하지 않고 이전 결과를 반환**
    
- 예시 (결제 API에서 자주 사용)
    
    `POST /payments Headers: Idempotency-Key: abc123 Body: { "amount": 10000, "userId": 1 }`
    
    - 첫 요청 → 결제 처리 후 응답 저장
        
    - 두 번째 요청(같은 키) → 새 결제 생성 안 하고, 첫 번째 응답 그대로 반환
        

👉 Stripe, PayPal, Toss 같은 **결제 시스템에서 표준적으로 사용하는 방법**입니다.

---
📌 2. 비즈니스 키 제약 (Unique Constraint)

- 요청에 포함된 비즈니스 로직 상의 고유 값(예: 주문번호, 이메일)을 **DB에서 Unique 제약 조건으로 관리**
    
- 같은 값으로 두 번 `POST`가 들어오면 DB에서 중복 오류 발생 → 서버는 에러 반환
    
- 예시:
    - `POST /users { "email": "test@test.com" }`
    - 같은 이메일로 여러 번 요청 시, 두 번째부터는 `409 Conflict` 반환        
👉 회원가입, 주문번호 같은 “고유성이 보장돼야 하는 리소스”에 적합

---
 📌 3. 서버 단에서 중복 체크 로직

- 서버가 요청 처리 시, **최근 요청 내역을 캐시/DB에 저장**해 두고 같은 요청이 들어오면 무시
    
- Redis 같은 인메모리 DB로 “짧은 시간 동안 동일 요청 차단”을 구현하기도 함
    
- 예:
    
    - 사용자가 버튼을 두 번 연속 클릭했을 때 중복 요청 차단
        

---
 📌 4. 클라이언트 단 방지

- UX 레벨에서 “버튼 1회만 클릭 가능, 이후 비활성화” 같은 방법
    
- 근본적 해결은 아니지만, 불필요한 중복 요청을 줄여줌
    

---
 📊 비교 요약

|방법|특징|사용 사례|
|---|---|---|
|Idempotency Key|클라이언트가 키 발급, 서버에서 응답 재사용|결제 API, 주문 API|
|비즈니스 키 제약|DB Unique 제약으로 중복 방지|회원가입(이메일), 주문번호|
|서버 중복 체크|캐시/DB로 요청 이력 관리|버튼 중복 클릭, 단시간 중복 요청 방지|
|클라이언트 방지|UI 제약으로 중복 클릭 차단|UX 개선 차원|

---

✅ **정리**

- POST는 본질적으로 멱등하지 않지만,
    
- **Idempotency Key**, **비즈니스 키 제약**, **중복 체크 로직** 등을 통해 실무에서는 안전하게 멱등성을 보장합니다.
    
- 특히 **금융·결제 서비스**에서는 Idempotency Key를 거의 필수적으로 사용합니다.
    

---

👉 면접 답변 포인트:  
“**POST는 멱등하지 않지만, 실무에서는 Idempotency Key를 두거나 비즈니스 키 제약을 걸어 멱등성을 보장합니다. 특히 결제 같은 경우는 중복 결제가 치명적이므로 반드시 이런 전략을 사용합니다.**”
##### GET과 POST의 차이는 무엇인가요?
좋은 질문입니다 🙂  
HTTP에서 가장 많이 쓰이는 메서드가 **GET**과 **POST**인데, 둘은 목적과 동작 방식이 확실히 다릅니다.

---
📌 1. 의미적 차이

- **GET**
    
    - 서버의 리소스를 **조회(Read)**하는 요청
        
    - “데이터를 가져온다”
        
- **POST**
    
    - 서버에 데이터를 **전송해서 생성(Create) 또는 처리(Process)**하는 요청
        
    - “데이터를 새로 만든다 / 서버에 뭔가를 맡긴다”
        

---

📌 2. 데이터 전달 방식

- **GET**
    
    - 데이터를 **URL 쿼리 파라미터**에 담아 전달 (`?key=value`)
        
    - 예: `GET /users?id=1`
        
- **POST**
    
    - 데이터를 **HTTP Body**에 담아 전달 (JSON, FormData 등)
        
    - 예: `POST /users` `{ "name": "Kim" }`
        

---
📌 3. 캐싱 가능 여부

- **GET**
    
    - 안전하고 멱등적이므로 캐싱 가능 (브라우저/프록시 캐시 활용)
        
- **POST**
    
    - 멱등하지 않으므로 기본적으로 캐싱하지 않음 (필요 시 별도 설정 필요)
        

---
📌 4. 멱등성 / 안전성

- **GET**
    
    - 안전(Safe) → 서버 상태 변경 없음
        
    - 멱등(Idempotent) → 여러 번 요청해도 같은 결과
        
- **POST**
    
    - 안전하지 않음 → 새로운 리소스 생성 등 서버 상태 변경
        
    - 멱등성 없음 → 같은 요청을 여러 번 보내면 리소스가 중복 생성될 수 있음
        

---
📌 5. 길이 제한

- **GET**
    
    - URL 길이에 제한이 있음 (브라우저/서버에 따라 다르지만 보통 2,048자 내외)
        
- **POST**
    
    - Body에 담으므로 데이터 크기 제한이 훨씬 큼 (실질적으로 서버 설정에 따름)
        

---
📊 요약 비교

|구분|GET|POST|
|---|---|---|
|의미|조회(Read)|생성(Create)/처리|
|데이터 전달|URL 쿼리 파라미터|HTTP Body|
|서버 상태|변경 없음 (Safe)|변경 있음 (Not Safe)|
|멱등성|있음|없음|
|캐싱|가능|불가능(기본)|
|데이터 크기|URL 길이 제한 있음|Body로 대량 전송 가능|
|사용 예시|게시글 목록 조회, 사용자 정보 조회|회원가입, 로그인, 주문 생성|

---

✅ **정리**

- **GET**: 단순 조회, 안전, 캐싱 가능
    
- **POST**: 리소스 생성/변경, 멱등성 없음, 상태 변화 발생
    

---

👉 면접식으로 짧게 말하면:

> “GET은 서버 리소스를 조회할 때 쓰고, POST는 리소스를 생성하거나 처리할 때 씁니다. GET은 멱등적이고 캐싱이 가능하지만, POST는 멱등성이 없고 서버 상태를 바꿉니다.”
##### POST와 PUT, PATCH의 차이는 무엇인가요?
좋은 질문입니다 👍  
POST, PUT, PATCH는 모두 **리소스 생성/수정에 관련된 메서드**인데, 의도가 다릅니다. REST API 설계에서 많이 헷갈리는 부분이라서 확실히 정리해 두시면 좋아요.

---
📌 1. POST

- **의미**: 새로운 리소스 생성(Create), 혹은 서버 측에서 어떤 처리를 위임할 때 사용
    
- **특징**
    
    - 멱등성 ❌ (같은 요청 여러 번 보내면 리소스가 중복 생성될 수 있음)
        
    - 새 리소스를 만들고 보통 `201 Created` 반환
        
- **예시**
    
    `POST /users { "name": "Kim", "email": "kim@test.com" } → 새로운 유저 생성 (id=10)`
    

---
📌 2. PUT

- **의미**: 리소스 전체 교체(Update)
    
- **특징**
    
    - 멱등성 ✅ (같은 요청 여러 번 보내도 최종 결과는 동일)
        
    - 요청에 전달한 JSON 문서가 **리소스 전체를 대체**해야 함
        
    - 없는 리소스에 PUT을 하면 생성하기도 함 (서버 구현 방식에 따라 다름)
        
- **예시**
    
    `PUT /users/10 { "name": "Lee", "email": "lee@test.com" } → user 10의 정보를 통째로 새로운 값으로 교체`
    

---
📌 3. PATCH

- **의미**: 리소스 일부 수정(Partial Update)
    
- **특징**
    
    - 멱등성 ❓ (구현 방식에 따라 다름 → “값을 덮어쓰기”면 멱등, “증가/감소 연산”이면 비멱등)
        
    - 리소스 전체가 아니라 특정 필드만 변경 가능 → 네트워크 비용 절약
        
- **예시**
    
    `PATCH /users/10 { "email": "newmail@test.com" } → user 10의 email만 변경`
    

---
📊 비교 요약

| 구분  | POST              | PUT                     | PATCH                   |
| --- | ----------------- | ----------------------- | ----------------------- |
| 목적  | 새 리소스 생성          | 전체 리소스 교체               | 리소스 일부 수정               |
| 대상  | 컬렉션(/users) 주로 사용 | 단일 리소스(/users/10)       | 단일 리소스(/users/10)       |
| 멱등성 | ❌ 없음              | ✅ 있음                    | ⚠️ 경우에 따라 다름            |
| 응답  | 201 Created       | 200 OK / 204 No Content | 200 OK / 204 No Content |
| 예시  | 회원가입, 주문 생성       | 유저 전체 정보 교체             | 유저 이메일만 수정              |

---
✅ 정리

- **POST**: 새로운 리소스를 “추가”
    
- **PUT**: 리소스를 “통째로 교체”
    
- **PATCH**: 리소스의 “일부만 수정”
    

---

👉 면접식으로 짧게 말하면:

> “POST는 리소스 생성, PUT은 리소스 전체 교체, PATCH는 리소스 일부 수정입니다. POST는 멱등성이 없지만, PUT은 멱등성을 보장합니다. PATCH는 상황에 따라 멱등성을 가질 수도 있고 아닐 수도 있습니다.”
##### HTTP 1.1 이후로, GET에도 Body에 데이터를 실을 수 있게 되었습니다. 그럼에도 불구하고 왜 아직도 이런 방식을 지양하는 것일까요?
말씀하신 것처럼 **HTTP/1.1 명세(RFC 7231)**에서는 GET 요청에도 Body를 담는 것이 **문법적으로 금지된 것은 아닙니다.**  
하지만, 실무에서는 **GET + Body**를 사실상 지양합니다. 이유는 크게 세 가지입니다.

---
📌 1. 명세의 모호성

- RFC 7231에 따르면:
    
    > “A payload within a GET request message has no defined semantics; sending a payload body on a GET request might cause some existing implementations to reject the request.”
    
    - 즉, **GET의 Body는 정의된 의미가 없다.**
        
    - 서버/클라이언트 구현에 따라 다르게 해석될 수 있다는 뜻입니다.
        

---
 📌 2. 실무 호환성 문제

- **많은 클라이언트/프록시/캐시 서버**가 GET 요청은 Body가 없다고 가정하고 구현되어 있습니다.
    
- 따라서 GET Body는 **무시되거나, 아예 오류 처리**될 수 있습니다.
    
- 예: 일부 프록시/로드밸런서는 GET 요청에서 Body를 strip(삭제)해버립니다.
    
---
📌 3. 캐싱 / REST 의미적 혼란

- GET은 본질적으로 **안전(Safe)** 하고 **멱등(Idempotent)** 하며, **캐시 가능**한 메서드입니다.
    
- Body에 의미를 부여하기 시작하면,
    
    - 캐시 키(Cache Key)를 URI가 아닌 Body까지 포함해야 함 → 캐싱 시스템 혼란
        
    - RESTful 설계 원칙에서 “GET = 조회”라는 명확한 의미가 흐려짐
        
- 따라서 대부분의 API 설계 가이드라인(REST Best Practice)에서는 GET에 Body 사용을 금지합니다.
    

---
📌 결론

- HTTP/1.1부터 **GET + Body는 문법적으로 가능하지만, 의미가 표준화되어 있지 않고 호환성 문제가 많기 때문에 지양**합니다.
    
- 따라서 **데이터를 반드시 Body에 담아야 한다면 POST/PUT/PATCH** 같은 메서드를 사용합니다.
    
- GET은 “리소스 식별자(URI + Query String)”로만 요청해야 하는 것이 사실상 업계 표준입니다.
    

---

👉 면접 답변 예시:

> “HTTP/1.1부터 GET에도 Body를 담을 수는 있지만, 명세에서 의미가 정의되지 않았고, 캐시/프록시/클라이언트 구현 호환성이 보장되지 않습니다. 그래서 실무에서는 GET 요청에는 Body를 쓰지 않고, 데이터를 전달해야 한다면 Query String을 쓰거나 POST 등 다른 메서드를 활용하는 것이 일반적입니다.”

###### **GET 요청에 Body를 넣었을 때 실제로 발생할 수 있는 문제 시나리오**
> 그럼 **GET 요청에 Body를 넣었을 때 실제로 발생할 수 있는 문제 시나리오**를 정리해 보겠습니다.

---
📌 1. 캐싱 시스템과의 충돌

- **문제 상황**:
    
    - HTTP 캐시는 보통 **URI + Query Parameter**를 캐시 키(Cache Key)로 사용합니다.
        
    - 그런데 GET Body는 캐시 키에 포함되지 않습니다.
        
- **결과**:
    
    - Body 내용이 달라도 URI가 같으면, 캐시는 같은 요청으로 인식 → **잘못된 데이터 반환** 가능.
        
- **예시**:
    
    `GET /products   Body: { "category": "book" } GET /products   Body: { "category": "electronics" }`
    
    → 캐시 서버는 둘 다 같은 `/products` 요청으로 처리 → book 목록을 요청했는데 electronics 목록이 돌아올 수 있음.
    

---
📌 2. 프록시 / 로드밸런서에서 Body 무시

- **문제 상황**:
    
    - 많은 프록시(nginx, Squid, HAProxy)나 로드밸런서는 **GET에는 Body가 없다고 가정**합니다.
        
    - 따라서 GET Body를 **삭제하거나 무시**해 버립니다.
        
- **결과**:
    
    - 서버는 Body를 못 받고, 클라이언트는 의도한 요청을 전달하지 못함.
        
- **실제 사례**:
    
    - 일부 AWS API Gateway나 Cloudflare 같은 서비스는 GET Body를 자동으로 제거 → “Body 왜 안 와요?” 현상 발생.
        

---
📌 3. 클라이언트 라이브러리 호환성

- **문제 상황**:
    
    - `fetch`, `axios`, `OkHttp`, `Java HttpClient` 같은 라이브러리 중 일부는 **GET Body를 아예 지원하지 않거나 경고 발생**.
        
- **결과**:
    
    - 클라이언트 개발자가 `body` 넣었는데 서버로 전달되지 않음.
        
- **예시**:
    
    `fetch("/api/data", { method: "GET", body: JSON.stringify({ id: 1 }) }) // 일부 브라우저에서는 body가 무시됨`
    

---
 📌 4. RESTful 의미적 혼란

- **문제 상황**:
    
    - REST 설계 원칙에서 GET은 **안전(Safe), 멱등(Idempotent), 캐싱 가능**해야 합니다.
        
    - Body를 통해 조건을 달기 시작하면 사실상 POST처럼 동작.
        
- **결과**:
    
    - API 문서화 / 협업에서 혼란 → “이거 조회용인데 POST로 바꿔야 하는 거 아닌가요?”
        
    - 팀 간 합의가 안 되면 유지보수 악몽 시작 😅
        

---
📊 정리

- GET + Body는 RFC상 허용되지만,
    
    1. **캐시 시스템 무시** (Body 반영 안 됨 → 잘못된 캐시 응답)
        
    2. **프록시/로드밸런서에서 Body 삭제**
        
    3. **클라이언트 라이브러리 미지원**
        
    4. **RESTful 의미적 혼란**
        

→ **표준적 의미가 없고, 생태계 지원도 불안정**하기 때문에 지양합니다.

---

👉 면접용으로 짧게 답하면:

> “GET Body는 RFC상 허용되지만 캐싱 시스템에서 무시되고, 프록시/로드밸런서가 Body를 날려버릴 수 있습니다. 또 라이브러리 호환성 문제도 있어 실무에서는 절대 권장되지 않습니다. 대신 Query String이나 POST를 씁니다.”

### 4. HTTP에 대해 설명해 주세요.
##### 설명
좋습니다 🙂  
**HTTP(HyperText Transfer Protocol)**는 웹에서 가장 기본이 되는 통신 규약(Protocol)입니다. 브라우저와 서버가 **문서, 이미지, 동영상, JSON 데이터** 같은 리소스를 주고받을 때 사용하는 표준 방식이죠.

---
📌 1. HTTP의 정의

- **HyperText Transfer Protocol** → "하이퍼텍스트 전송 규약"
    
- **클라이언트–서버 모델** 기반: 클라이언트(브라우저, 앱)가 요청(Request)을 보내면 서버가 응답(Response)을 반환.
    
- 애플리케이션 계층(Application Layer) 프로토콜 (OSI 7계층 중 7계층).
    

---
📌 2. HTTP의 특징

1. **Stateless (무상태성)**
    
    - 각 요청은 독립적 → 서버는 이전 요청 상태를 기억하지 않음.
        
    - 로그인 유지 등 상태가 필요하면 쿠키/세션/JWT 같은 기술을 추가로 사용.
        
2. **Connectionless (비연결성)**
    
    - 요청-응답 후 연결을 바로 끊음.
        
    - HTTP/1.1에서는 Keep-Alive로 연결 유지 가능, HTTP/2/3는 다중화 지원.
        
3. **Request-Response 구조**
    
    - 클라이언트가 반드시 먼저 요청을 보내고, 서버가 응답.
        
    - 요청과 응답은 **헤더(Header) + 바디(Body)**로 구성.
        

---
📌 3. HTTP 메시지 구조

 요청(Request)

`GET /users/1 HTTP/1.1 Host: example.com User-Agent: Chrome/120 Accept: application/json`

- **메서드(Method)**: GET, POST, PUT, PATCH, DELETE …
    
- **URI**: `/users/1`
    
- **헤더(Header)**: 클라이언트 정보, 인증 정보 등
    
- **바디(Body)**: 주로 POST/PUT/PATCH에서 데이터 포함
    
응답(Response)

`HTTP/1.1 200 OK Content-Type: application/json Content-Length: 34  {   "id": 1,   "name": "Kim" }`

- **상태 코드(Status Code)**: 200 OK, 404 Not Found, 500 Internal Server Error …
    
- **헤더(Header)**: 응답 타입, 캐시 정책 등
    
- **바디(Body)**: 실제 데이터(JSON, HTML 등)
    

---
📌 4. HTTP 버전별 특징

- **HTTP/1.0 (1996)**
    
    - 요청-응답마다 TCP 연결 새로 맺음 → 비효율적
        
- **HTTP/1.1 (1997)**
    
    - Keep-Alive 도입 → 연결 재사용 가능
        
    - Host 헤더 도입 (가상호스팅 가능)
        
- **HTTP/2 (2015)**
    
    - 바이너리 프로토콜, 요청 다중화(Multiplexing), 헤더 압축
        
    - 성능 대폭 향상
        
- **HTTP/3 (2022, 최신)**
    
    - TCP 대신 **QUIC(UDP 기반)** 사용 → 더 빠른 연결, 지연 줄임
        

---
📌 5. HTTP의 주요 활용

- 웹 브라우저 ↔ 서버 간 문서/이미지/동영상 전송
    
- REST API, GraphQL, gRPC (HTTP/2 기반)
    
- 모바일 앱 ↔ 백엔드 서버 데이터 통신
    

---

✅ **정리**

- HTTP는 **웹에서 클라이언트와 서버가 데이터를 주고받는 규약**
    
- 특징: **무상태성, 요청-응답 구조, 버전에 따라 성능 발전**
    
- 상태 유지 필요 시 → **쿠키/세션/JWT** 같은 별도 기술 필요
    
- 최신 서비스들은 **HTTP/2, HTTP/3**를 활용해 성능 최적화
    

---

👉 면접에서 짧게 말하면:

> “HTTP는 클라이언트와 서버가 데이터를 주고받는 애플리케이션 계층 프로토콜입니다. Stateless 특성을 가지며, 요청-응답 구조로 동작합니다. 현재는 HTTP/2, HTTP/3까지 발전해 성능과 안정성이 강화되었습니다.”

##### 공개키와 대칭키에 대해 설명해 주세요.
좋은 질문입니다 👍  
암호화 방식에는 크게 **대칭키(Symmetric Key)**와 **공개키(Public Key, 비대칭키)** 방식이 있습니다.  
두 방식은 **키를 어떻게 사용하느냐**에 따라 차이가 납니다.

---
📌 1. 대칭키 암호화 (Symmetric Key Encryption)

- **원리**: 암호화(Encryption)와 복호화(Decryption)에 **같은 키**를 사용합니다.
    
- **예시**
    - Alice가 "Hello"를 대칭키로 암호화 → `abcd1234`
        
    - Bob이 같은 키를 가지고 있으면 이를 복호화해서 "Hello" 확인 가능
        
- **장점**
    - 알고리즘이 단순하고 빠름 (대용량 데이터 암호화에 적합)
        
    - 예: AES, DES
        
- **단점**
    - 키를 안전하게 공유해야 함 → 네트워크에서 키가 유출되면 보안 취약
        
    - 사용자 수가 많아질수록 키 관리가 어렵다 (N명일 때 N(N-1)/2개의 키 필요)
        

---
 📌 2. 공개키 암호화 (Asymmetric Key Encryption)

- **원리**: **서로 다른 키 쌍(공개키 Public Key + 개인키 Private Key)**을 사용
    
    - 공개키: 누구나 알 수 있음
        
    - 개인키: 오직 본인만 보관
        
- **동작 방식**
    
    1. **암호화 용도**: 공개키로 암호화 → 개인키로 복호화
        
        - 예: 서버의 공개키로 암호화 → 서버만 가진 개인키로 복호화 가능
            
        - 즉, 통신의 **기밀성(Confidentiality)** 보장
            
    2. **전자서명 용도**: 개인키로 서명 → 공개키로 검증
        
        - 즉, 데이터의 **무결성/인증(Authentication)** 보장
            
- **장점**
    
    - 키 교환 문제 해결 (공개키는 누구나 배포 가능)
        
    - 인증/서명 가능 → 신뢰성 높은 통신
        
- **단점**
    
    - 대칭키보다 연산 속도가 느림 → 대용량 암호화에는 비효율적
        
    - 예: RSA, ECC
        

---
📌 3. 실제 사용 (혼합 방식: HTTPS)

실제 인터넷 보안(HTTPS)에서는 두 방식을 **함께 사용**합니다.

1. 클라이언트와 서버가 연결할 때, **공개키 암호화**로 안전하게 **세션키(대칭키)**를 교환
    
2. 이후 데이터 전송은 **대칭키 암호화**로 빠르게 처리
    

👉 이렇게 하면 **보안성과 성능**을 모두 잡을 수 있습니다.

---
📊 요약 표

| 구분      | 대칭키         | 공개키            |
| ------- | ----------- | -------------- |
| 키 개수    | 1개(공유)      | 2개(공개키+개인키)    |
| 암호화/복호화 | 같은 키 사용     | 서로 다른 키 사용     |
| 속도      | 빠름          | 느림             |
| 보안성     | 키 교환 취약     | 키 배포 안전        |
| 활용      | 대용량 데이터 암호화 | 키 교환, 전자서명, 인증 |
| 대표 알고리즘 | AES, DES    | RSA, ECC       |

---

✅ **정리**

- **대칭키**: 하나의 키로 암호화·복호화 → 빠르지만 키 교환이 문제
    
- **공개키**: 공개키/개인키 쌍 → 안전하지만 느림
    
- **실무**: 공개키로 대칭키를 교환하고, 실제 데이터는 대칭키로 암호화 (HTTPS)
    

---
##### 왜 HTTPS Handshake 과정에서는 인증서를 사용하는 것 일까요?
https://brunch.co.kr/@sangjinkang/38
📌 HTTPS Handshake에서의 목표

클라이언트(브라우저)와 서버가 안전하게 통신하기 위해서는 두 가지가 보장되어야 합니다.

1. **서버가 진짜 서버인지 확인 (인증)**
    
2. **데이터를 안전하게 교환하기 위한 세션키(대칭키) 협상**
    

---
 📌 왜 인증서가 필요한가?

 1. 서버 신원 보장 (Authentication)

- 만약 인증서가 없다면?  
    클라이언트는 공개키를 받았을 때 “이게 정말 서버의 공개키인지” 알 수 없습니다.  
    → 공격자가 중간에 끼어(MITM) 자신이 발급한 공개키를 넘겨줄 수 있음.
    
- 인증서는 **공인된 기관(CA, Certificate Authority)**이 서버의 공개키와 도메인을 묶어 서명한 문서입니다.
    
    - 브라우저는 내장된 CA 리스트로 인증서의 진위 여부를 검증합니다.
        
    - 따라서 클라이언트는 “이 공개키는 example.com 서버의 것이 맞다”라는 것을 신뢰할 수 있습니다.
        

---
2. 중간자 공격(Man-In-The-Middle, MITM) 방지

- 인증서가 없다면 공격자가 이렇게 할 수 있습니다:
    
    1. 클라이언트에게 가짜 공개키 제공
        
    2. 클라이언트 요청을 복호화 후 다시 서버로 전달
        
    3. 서버 응답도 공격자가 복호화 후 다시 클라이언트로 전달
        
- 인증서가 있으면?
    
    - 공격자가 CA로부터 위조된 인증서를 발급받을 수 없으므로 신뢰할 수 없는 키는 거부됩니다.
        

---
3. 안전한 세션키 교환

- 실제 데이터 전송은 **대칭키**가 빠르고 효율적이라 대칭키를 사용합니다.
    
- Handshake에서 서버는 인증서를 통해 공개키를 제공하고, 클라이언트는 이를 이용해 세션키를 안전하게 교환합니다.
    
- 인증서가 없다면 클라이언트는 “안전한 키 교환”이 불가능해집니다.
    

---
📊 요약

- **인증서의 역할**
    
    1. 서버 신원을 보장 (이 서버가 진짜인지 확인)
        
    2. 중간자 공격 방지 (위조 키 차단)
        
    3. 안전한 세션키 교환 지원
        

---

✅ **정리**  
HTTPS Handshake에서 인증서를 사용하는 이유는  
👉 “서버가 진짜임을 보장하고, 중간자 공격을 막으며, 클라이언트가 서버의 공개키를 안전하게 신뢰하도록 하기 위함”입니다.

---

👉 면접식으로 짧게 말하면:

> “인증서를 통해 클라이언트는 서버의 공개키가 진짜 서버의 것임을 검증할 수 있습니다. 이는 중간자 공격을 막고 안전한 세션키 교환을 보장하기 위해 필요합니다.”

3. 핸드셰이크 과정 요약

핸드셰이크는 브라우저와 서버 간의 “악수” 단계로, 보안 통신의 기틀을 마련합니다[Brunch Story](https://brunch.co.kr/%40sangjinkang/38?utm_source=chatgpt.com).

단계별 순서

1. **ClientHello**
    
    - 클라이언트가 TLS 버전, 지원 가능한 암호화 방식(cipher suite), 랜덤 값 등을 서버에 전송합니다
        
2. **ServerHello + 인증서**
    
    - 서버가 선택된 암호화 방식, 서버 랜덤 값, 그리고 자신의 **SSL 인증서(공개키 포함, CA 서명됨)**를 클라이언트에 보냅니다
        
3. **인증서 검증**
    
    - 브라우저는 내장된 **CA 공개키로 인증서의 진위를 확인**하고, 유효한 인증서일 경우 통과합니다
        
4. **세션키 교환**
    
    - 브라우저는 클라이언트·서버 랜덤 값을 활용하여 **Pre‑Master Secret**을 생성, 서버 공개키로 암호화해 전송.
        
    - 서버는 자신의 **개인키**로 이를 복호화해 **Master Secret**을 얻고, 양측에 같은 세션키(대칭키)를 생성합니다
        
5. **HTTPS 암호화 통신 시작**
    
    - 세션키를 바탕으로 대칭키 암호화 방식으로 안전한 데이터 전송이 시작됩니다.
        
    - 이미 핸드셰이크가 완료된 경우, 다음부터는 세션 ID로 빠른 재연결이 가능합니다
        

6. HTTPS만으로 충분한가?

- HTTPS는 전달 구간의 보안을 확보하지만, 웹 서버 자체가 해킹당하거나 클라이언트-서버 중간에서 내부자가 개입할 경우, 내용이 노출될 수 있습니다.
    
- 특히 민감한 개인 대 개인 통신에서는 **종단 간 암호화(E2E)**를 추가로 도입하는 추세입니다
    

---
요약 정리

|단계|설명|
|---|---|
|1. 인증서 포함한 핸드셰이크|서버 신원 확인과 세션키 생성 방식 설정|
|2. 공개키 기반 세션키 교환|클라이언트가 Pre-Master Secret을 서버 공개키로 암호화하여 전송|
|3. 대칭키 기반 데이터 통신|핸드셰이크 완료 후 빠르고 안전한 대칭키 암호화 통신 수행|

핵심은, **인증서를 통해 서버의 신원을 검증하고, 세션키 교환 과정의 안전성을 확보한 후에 암호화된 통신이 이루어진다는 점**입니다.
##### SSL과 TLS의 차이는 무엇인가요?
둘은 정확히 말하면 **세대(버전)**가 다른 프로토콜입니다.

---
📌 1. SSL (Secure Sockets Layer)

- 넷스케이프(Netscape)에서 1990년대 초반 개발한 보안 프로토콜.
    
- **웹 브라우저와 서버 간 데이터를 암호화**하기 위해 등장.
    
- 버전 역사:
    
    - SSL 1.0 → 내부에서만 테스트, 공개 안 됨
        
    - SSL 2.0 (1995) → 최초 상용화, 보안 취약점 발견
        
    - SSL 3.0 (1996) → 널리 사용되었지만 이후 POODLE 공격 등 치명적 취약점 발견
        

👉 현재는 **SSL은 보안상 완전히 폐기(deprecated)** 되었습니다.

---
 📌 2. TLS (Transport Layer Security)

- SSL을 기반으로 IETF(국제 인터넷 표준화 기구)가 표준화한 후속 프로토콜.
    
- 이름만 바뀐 게 아니라, 암호화 방식·핸드셰이크 과정 등 여러 부분이 강화됨.
    
- 버전 역사:
    
    - TLS 1.0 (1999, SSL 3.1 기반)
        
    - TLS 1.1 (2006)
        
    - TLS 1.2 (2008) → 현재 가장 많이 사용되는 버전
        
    - TLS 1.3 (2018) → 최신, 성능·보안 대폭 향상
        

---
📌 3. SSL vs TLS 차이

| 구분    | SSL                        | TLS                    |
| ----- | -------------------------- | ---------------------- |
| 개발 주체 | 넷스케이프                      | IETF (표준화 기구)          |
| 보안성   | 이미 폐기 (2.0, 3.0 모두 취약점 존재) | 현재 표준 (1.2, 1.3)       |
| 핸드셰이크 | 취약점 존재, 오래된 알고리즘 사용        | 보안 강화, 최신 암호화 알고리즘 사용  |
| 사용 현황 | 더 이상 사용 안 함                | HTTPS, VPN 등 인터넷 보안 표준 |
| 표현 방식 | 흔히 “SSL 인증서”라고 부름          | 실제는 전부 TLS 사용          |

---
📌 4. 왜 지금도 “SSL 인증서”라고 부르나요?

- 역사적으로 SSL이 먼저 등장했고, 이후 TLS로 발전했지만 **이름이 너무 널리 퍼져버림**.
    
- 현재 우리가 쓰는 인증서는 사실상 “TLS 인증서”이지만, 관습적으로 “SSL 인증서”라고 부릅니다.
    
- 즉, “SSL 인증서” = “TLS 인증서” = “HTTPS 보안 인증서” (동일 의미).
    

---
✅ 정리

- **SSL**: 과거 프로토콜 (보안 취약, 폐기됨).
    
- **TLS**: SSL의 후속 표준, 현재 사용되는 보안 프로토콜.
    
- 우리가 말하는 **SSL 인증서**는 사실상 **TLS 인증서**를 뜻합니다.
    

---

👉 면접용으로 짧게 답하면:

> “SSL은 넷스케이프가 만든 초기 암호화 프로토콜이고, 보안 취약점 때문에 폐기되었습니다. 현재는 그 후속인 TLS가 표준으로 쓰입니다. 우리가 흔히 ‘SSL 인증서’라고 부르는 건 사실상 TLS 인증서를 뜻합니다.”

### 5. 웹소켓과 소켓 통신의 차이에 대해 설명해 주세요.
##### 설명
📌 1. 소켓 통신 (Socket Communication)

- **개념**:
    
    - OS가 제공하는 **저수준 네트워크 통신 API**
        
    - TCP/UDP 같은 전송 계층 프로토콜 위에서 동작
        
    - 애플리케이션이 직접 소켓을 열고 데이터를 송수신
        
- **특징**
    
    - **양방향 통신** 가능 (TCP 소켓은 연결 기반 스트림, UDP 소켓은 비연결 기반 데이터그램)
        
    - **프로토콜 정의 자유로움**: 데이터를 어떤 형식으로 보낼지는 애플리케이션이 직접 설계해야 함
        
    - 성능 좋음, 하지만 **브라우저 환경에서는 직접 사용 불가** (브라우저는 TCP/UDP 소켓에 직접 접근 못 함)
        
- **사용 예시**
    
    - 게임 서버 (TCP/UDP 소켓)
        
    - 채팅 서버 (TCP 소켓)
        
    - IoT 디바이스 간 통신
        

---
📌 2. 웹소켓 (WebSocket)

- **개념**:
    
    - 웹 환경에서 **실시간 양방향 통신**을 가능하게 하기 위해 만들어진 프로토콜
        
    - **HTTP 프로토콜 위에서 업그레이드(Handshake)** 한 뒤, **풀 이중통신(Full-Duplex)** 채널 생성
        
- **특징**
    
    - 처음에는 HTTP 요청(`GET /chat HTTP/1.1` + Upgrade 헤더)으로 연결 시작
        
    - 서버가 이를 승인하면 **HTTP → WebSocket 프로토콜 전환**
        
    - 이후에는 헤더 없이 가벼운 프레임 형태로 메시지 송수신 가능
        
    - 브라우저에서 표준 API(`new WebSocket(url)`)로 쉽게 사용 가능
        
- **사용 예시**
    
    - 웹 채팅 서비스 (카톡 웹버전, 슬랙 등)
        
    - 주식/코인 시세 실시간 스트리밍
        
    - 온라인 게임 웹 클라이언트
        

---
📊 비교 정리

| 구분     | 소켓(Socket)          | 웹소켓(WebSocket)           |
| ------ | ------------------- | ------------------------ |
| 레벨     | 저수준 API (TCP/UDP)   | 응용 계층 프로토콜 (HTTP 위에서 동작) |
| 환경     | 서버/클라이언트 네이티브 앱 가능  | 웹 브라우저에서 표준 지원           |
| 연결 방식  | TCP(연결형), UDP(비연결형) | HTTP Handshake 후 양방향 전환  |
| 데이터 형식 | 애플리케이션이 직접 정의       | 표준화된 메시지 프레임 구조          |
| 실시간성   | 지원 (프로토콜 설계 필요)     | 지원 (바로 사용 가능)            |
| 사용 사례  | 게임 서버, IoT, 채팅 서버   | 웹 채팅, 실시간 알림, 주식 시세      |

---
✅ 정리

- **소켓 통신**: OS 수준의 네트워크 API, TCP/UDP 기반, 저수준이지만 유연함 → 브라우저에서는 직접 사용 불가.
    
- **웹소켓**: 웹 환경을 위한 실시간 양방향 통신 프로토콜, HTTP 업그레이드 후 사용, 브라우저/서버 모두 쉽게 지원.
    

---

👉 면접식으로 짧게 말하면:

> “소켓 통신은 TCP/UDP 기반의 저수준 통신이고, 웹소켓은 웹 환경에서 HTTP 연결을 업그레이드해서 사용하는 실시간 양방향 통신 프로토콜입니다. 소켓 통신은 범용성이 넓지만 브라우저에서 직접 못 쓰고, 웹소켓은 브라우저에서 쉽게 사용할 수 있도록 표준화되어 있습니다.”

##### 소켓과 포트의 차이가 무엇인가요?
📌 포트 (Port)

- **정의**:
    
    - 운영체제의 네트워크 계층(전송 계층, TCP/UDP)에서 **프로세스를 구분하는 번호**
        
    - 하나의 IP 주소(=호스트)에 여러 애플리케이션이 동시에 네트워크를 사용할 수 있도록 “출입구” 역할을 함.
        
- **특징**
    
    - 16비트 숫자 (0 ~ 65535)
        
    - 0~1023: well-known port (HTTP=80, HTTPS=443, FTP=21, …)
        
    - 클라이언트도 보통 **동적 포트(ephemeral port)**를 임시로 사용
        
- **비유**: “아파트(IP 주소)” 안에 있는 “호실 번호(Port)”.
    

---
📌 소켓 (Socket)

- **정의**:
    
    - 네트워크 통신의 **종단점(End Point)**
        
    - IP 주소 + 포트 번호 + 프로토콜(TCP/UDP)을 합쳐서 하나의 소켓을 구성
        
- **특징**
    
    - 클라이언트 소켓과 서버 소켓이 연결되면 실제 데이터 통신 가능
        
    - `IP:PORT` 조합이 있어야 네트워크에서 특정 애플리케이션을 식별 가능
        
- **비유**: 아파트(IP)와 호실번호(Port)를 합친 후, 실제 사람이 살고 있는 “집(소켓)”이 완성되는 것.
    

---
📊 비교 정리

|구분|포트(Port)|소켓(Socket)|
|---|---|---|
|의미|프로세스를 식별하는 번호|네트워크 통신의 종단점|
|구성 요소|0 ~ 65535 번호|(IP 주소 + 포트 번호 + 프로토콜)|
|역할|"출입구 번호"|"실제 통신 창구"|
|예시|80번 → HTTP 서비스|`192.168.0.10:80 (TCP)` 소켓|

---
📌 예시 시나리오

- 서버: `192.168.0.10` IP에서 **80번 포트** 열어 HTTP 서버 실행
    
- 클라이언트: `192.168.0.20` IP에서 **동적 포트(예: 52345)** 열어 요청 보냄
    
- 연결된 소켓 쌍:
    
    - 클라이언트 소켓: `192.168.0.20:52345 (TCP)`
        
    - 서버 소켓: `192.168.0.10:80 (TCP)`
        

👉 이 두 소켓이 연결되어 실제 데이터 송수신이 가능해집니다.

---

✅ **정리**

- **포트**는 “번호표” → 어떤 프로세스와 통신할지 구분.
    
- **소켓**은 “실제 통신 창구” → IP + Port + 프로토콜을 합쳐 만든 네트워크 통신의 종단점.
##### 여러 소켓이 있다고 할 때, 그 소켓의 포트 번호는 모두 다른가요?
📌 소켓을 유일하게 구분하는 요소

TCP/UDP 소켓은 단순히 **포트 번호만으로 구분되지 않습니다.**  
소켓을 구별하는 4가지 요소가 있습니다:

**(IP 주소 + 포트 번호) 쌍**이 송신측과 수신측 모두 합쳐져서  
👉 **(출발지 IP, 출발지 Port, 목적지 IP, 목적지 Port)**  
이 네 가지가 합쳐져야 하나의 연결을 유일하게 식별합니다.

이를 흔히 **4-튜플(4-tuple)**이라고 부릅니다.

---
📌 케이스별 설명
1. 서버 소켓 (Listening Socket)

- 서버는 보통 하나의 고정 포트만 사용합니다.
    
    - 예: `0.0.0.0:80` (모든 인터페이스의 80번 포트에서 요청 대기)
        
- 여러 클라이언트가 접속해도 서버 측 포트 번호는 동일합니다.
    
    - 클라이언트A → `192.168.0.10:80`
        
    - 클라이언트B → `192.168.0.10:80`
        

→ 서버는 클라이언트의 출발지 IP/Port 조합으로 각각의 연결을 구분합니다.

---
2. 클라이언트 소켓

- 클라이언트는 서버에 연결할 때 **동적 포트(Ephemeral Port)**를 임시로 할당받습니다.
    
- 예:
    
    - 클라이언트A: `192.168.0.20:52345 → 192.168.0.10:80`
        
    - 클라이언트B: `192.168.0.21:52346 → 192.168.0.10:80`
        

→ 클라이언트끼리는 포트 번호가 다를 수 있지만, 서버 포트는 동일할 수 있습니다.

---
3. 여러 소켓의 포트 번호

- **같은 호스트(동일 IP)**에서 **동일 프로토콜(TCP/UDP)** 기준으로 **동일한 포트를 두 개의 소켓이 동시에 바인딩할 수는 없습니다.**
    
    - 예: 같은 서버에서 두 개의 프로세스가 동시에 `8080` 포트를 열면 충돌(`Address already in use`).
        
- 하지만 **다른 IP에 바인딩**하거나 **다른 프로토콜(TCP vs UDP)**로 열면 같은 포트 번호 사용 가능.
    

---
📊 정리

- 소켓을 유일하게 구분하는 건 **(출발지 IP, 출발지 Port, 목적지 IP, 목적지 Port)** 네 가지 조합.
    
- 따라서 **서버는 같은 포트로 여러 클라이언트와 동시에 통신 가능**. (클라이언트 출발지 포트가 다르기 때문에 구분됨)
    
- 하지만 **같은 호스트에서 같은 프로토콜로 같은 포트를 여러 소켓이 동시에 바인딩할 수는 없다.**
    

---

👉 면접용 한 줄 답변:

> “소켓은 단순히 포트 번호만으로 구분되지 않고, 출발지/목적지의 IP와 Port 네 가지 조합으로 식별됩니다. 그래서 서버는 하나의 포트(예: 80)만 열고도 여러 클라이언트와 동시에 통신할 수 있습니다.”
##### 사용자의 요청이 무수히 많아지면, 소켓도 무수히 생성되나요?
핵심은 **요청(Request)**과 **소켓(Socket)**이 **1:1 관계가 아니라는 것**입니다.

---
📌 소켓은 "연결(Connection)" 단위

- 소켓은 단순 요청 단위로 생기는 게 아니라, **네트워크 연결(커넥션)을 표현하는 객체**입니다.
    
- TCP의 경우, 소켓은 **클라이언트 ↔ 서버 사이의 연결**을 나타내고, 이는 4-튜플 `(출발지 IP, 출발지 Port, 목적지 IP, 목적지 Port)`로 구분됩니다.
    

---
 📌 요청이 많아질 때 소켓 생성 동작

1. **HTTP/1.0 (초기)**

- 요청 1개 → TCP 연결 1개(소켓 생성) → 응답 후 소켓 닫음
    
- 요청이 많으면 소켓도 매번 새로 생성 → 비효율적
    
2. **HTTP/1.1 (Keep-Alive)**

- 하나의 소켓 연결을 여러 요청이 재사용 가능
    
- 요청-응답을 여러 번 처리할 수 있음 → 소켓 생성 횟수 줄어듦
    
3. **HTTP/2**

- 하나의 소켓(하나의 TCP 연결) 안에서 **스트림(Stream)**이라는 가상 채널로 여러 요청을 동시에 처리
    
- 소켓 개수가 폭발적으로 늘어나지 않음
    
4. **WebSocket**

- 초기엔 HTTP 요청으로 핸드셰이크 → 이후 **하나의 소켓 연결을 계속 유지**
    
- 요청/응답 상관없이 양방향으로 무제한 메시지 송수신 가능
    

---
📌 정리

- 요청 개수 = 소켓 개수 ❌ (항상 그런 건 아님)
    
- **소켓은 연결 단위**라서,
    
    - **HTTP/1.0**: 요청마다 소켓 새로 열음 → 요청 폭증 시 소켓도 폭증
        
    - **HTTP/1.1 이후**: 소켓 재사용 가능 (Keep-Alive, Connection Pool)
        
    - **HTTP/2/3, WebSocket**: 하나의 소켓 안에서 다중 요청 처리 가능
        

---
 ✅ 면접식 답변

> “요청이 많다고 해서 무조건 소켓이 무수히 늘어나는 건 아닙니다. 소켓은 연결 단위이기 때문에, HTTP/1.0은 요청마다 새 소켓을 열었지만, HTTP/1.1부터는 Keep-Alive로 재사용이 가능해졌고, HTTP/2는 한 소켓에서 여러 요청을 병렬 처리합니다. 따라서 현대 웹에서는 요청 수가 많아도 소켓 수는 제한적으로 관리됩니다.”

### 6. HTTP/1.1과 HTTP/2의 차이점은 무엇인가요?
##### 설명
📌 HTTP/1.1

- **1997년 표준화**
    
- 현재까지도 가장 널리 쓰이는 HTTP 버전
    
특징

1. **Persistent Connection (Keep-Alive)**
    
    - 한 번 연결한 TCP 소켓을 여러 요청에 재사용 가능
        
    - 하지만 요청은 **순차적**으로 처리됨 → 응답 대기 시간 증가
        
2. **파이프라이닝(Pipelining)** 시도
    
    - 여러 요청을 연속해서 보내는 기능
        
    - 하지만 응답은 반드시 요청 순서대로 와야 해서 → **Head-of-Line Blocking (HOL 문제)** 발생
        
    - 그래서 대부분 브라우저는 파이프라이닝을 비활성화
        
3. **텍스트 기반 프로토콜**
    
    - 요청과 응답이 전부 ASCII 텍스트로 전송
        
    - 헤더 중복이 많음 (예: `Cookie`, `User-Agent` 등)
        

---
📌 HTTP/2

- **2015년 표준화**
    
- HTTP/1.1의 성능 문제를 해결하기 위해 개발
    
특징

1. **Binary Protocol (이진 프로토콜)**
    - 텍스트 대신 바이너리 프레이밍을 사용 → 파싱 속도 향상
        
2. **Multiplexing (다중화)**
    - 하나의 TCP 연결에서 여러 요청/응답을 동시에 처리 가능
    - 요청과 응답이 **순서에 구애받지 않음** → HOL 문제 해결
        
3. **Header Compression (HPACK)**
    - 중복되는 HTTP 헤더를 압축하여 전송량 절감
        
4. **Server Push**
    - 클라이언트가 요청하지 않은 리소스도 서버가 미리 전송 가능 (예: HTML 받으면 JS/CSS 자동 푸시)
        

---
📊 차이점 요약

|구분|HTTP/1.1|HTTP/2|
|---|---|---|
|데이터 표현|텍스트 기반|바이너리 프레임|
|요청 처리|순차적, HOL 문제 있음|다중화(Multiplexing), 동시 처리|
|연결|Keep-Alive (재사용 가능)|하나의 연결에서 여러 요청 병렬 처리|
|헤더|중복 많음 (텍스트)|HPACK 압축|
|추가 기능|-|Server Push 지원|
|성능|상대적으로 느림|지연 감소, 대역폭 효율적 사용|

---
✅ 정리

- **HTTP/1.1**: 텍스트 기반, 순차 처리, HOL 문제 존재
    
- **HTTP/2**: 이진 기반, 다중화 지원, 헤더 압축, 서버 푸시 → 훨씬 빠르고 효율적
    

---

👉 면접식으로 짧게 말하면:

> “HTTP/1.1은 텍스트 기반이고 요청을 순차적으로 처리해서 HOL 문제가 발생합니다. 반면 HTTP/2는 이진 프로토콜을 쓰고 하나의 연결에서 여러 요청을 동시에 처리하는 Multiplexing, 헤더 압축, 서버 푸시 같은 기능이 있어 성능이 훨씬 개선됐습니다.”


##### HOL Blocking 에 대해 설명해 주세요.
**HOL(Head-of-Line) Blocking**은 네트워크에서 자주 나오는 성능 저하 문제입니다.  
특히 **HTTP/1.1**과 **TCP 계층**에서 대표적으로 발생합니다.

---
 📌 HOL Blocking (Head-of-Line Blocking)이란?

- **대기열(Queue)의 맨 앞에 있는 요청/패킷이 지연되면서, 뒤에 있는 요청/패킷들도 함께 지연되는 현상**을 말합니다.
    
- 즉, **앞줄이 막히면 뒷줄도 같이 막히는 문제**.
    

---
📌 HTTP/1.1에서의 HOL Blocking

1. **HTTP/1.1의 요청-응답 처리 방식**
    
    - 한 TCP 연결에서 요청을 순차적으로 보냄 → 응답도 요청 순서대로 와야 함.
        
2. **문제 상황**
    
    - 요청 A, B, C를 보냈는데, A 처리에 시간이 오래 걸린다면?
        
    - B와 C는 이미 서버에서 준비됐더라도, **A 응답이 끝날 때까지 대기**해야 함.
        
    - 결과: 전체 지연(latency) 증가
        
3. **실제 예시**
    
    - 웹 페이지를 불러올 때, 큰 이미지 파일(A)이 늦게 오면 작은 JS/CSS(B, C)도 함께 늦게 로드됨.
        

---
📌 TCP 계층에서의 HOL Blocking

- TCP는 **신뢰성(순서 보장)** 때문에 패킷 손실이 발생하면 재전송될 때까지 이후 패킷을 애플리케이션에 전달하지 않음.
    
- 즉, 앞선 패킷 하나가 손실되면 뒤의 모든 패킷도 함께 대기 → HOL Blocking.
    
---
📌 해결 방법

1. **HTTP/2**
    
    - **Multiplexing** 지원: 한 TCP 연결에서 여러 요청/응답을 **동시에 병렬 처리**
        
    - 요청 A가 느려도 요청 B, C는 독립적으로 먼저 도착 가능 → HOL Blocking 완화
        
2. **HTTP/3 (QUIC)**
    
    - TCP 대신 **UDP 기반 QUIC 프로토콜** 사용
        
    - 스트림 단위로 패킷 관리 → 한 스트림 패킷 손실이 다른 스트림에 영향 주지 않음
        
    - 네트워크 레벨 HOL Blocking까지 해결
        

---
📊 요약

- **HOL Blocking**: 맨 앞 요청/패킷이 막히면 뒤 요청/패킷도 함께 지연되는 현상
    
- **HTTP/1.1**: 요청 순차 처리 때문에 HOL Blocking 발생
    
- **HTTP/2**: Multiplexing으로 응용 계층 HOL Blocking 완화
    
- **HTTP/3**: QUIC(UDP 기반)으로 전송 계층 HOL Blocking까지 해결
    

---

👉 면접용 짧은 답변:

> “HOL Blocking은 맨 앞 요청이나 패킷이 지연되면서 뒤에 있는 것들도 함께 지연되는 현상입니다. HTTP/1.1은 순차 응답 때문에 HOL 문제가 심했지만, HTTP/2는 Multiplexing으로 완화했고, HTTP/3는 QUIC을 사용해 전송 계층 HOL까지 해결했습니다.”
##### HTTP/3.0의 주요 특징에 대해 설명해 주세요.
**HTTP/3.0**은 최신 웹 표준 프로토콜로, 기존 **HTTP/2가 TCP 위에서 동작**했던 것과 달리 **UDP 기반 QUIC 프로토콜 위에서 동작**하는 것이 가장 큰 차이입니다.

---
📌 HTTP/3의 주요 특징

1. **QUIC 기반 (UDP 위에서 동작)**

- HTTP/1.1, HTTP/2 → TCP 기반
    
- HTTP/3 → UDP 기반 QUIC 사용
    
- QUIC은 TCP의 신뢰성과 보안 기능을 UDP 위에 재구현한 프로토콜
    
- 장점: **빠른 연결 수립, 전송 계층 HOL Blocking 해소**
    

---
 2. **빠른 연결 수립 (0-RTT, 1-RTT)**

- TCP는 연결 시 **3-way handshake** 필요
    
- TLS도 별도로 핸드셰이크 진행 → 초기 연결 지연(latency) 발생
    
- QUIC은 **TLS 1.3을 프로토콜에 내장** → 연결과 보안 협상을 동시에 진행
    
- 기존 연결 정보가 있다면 0-RTT로 거의 지연 없이 재연결 가능
    

---
 3. **HOL Blocking 해결**

- **HTTP/2 Multiplexing의 한계**
    
    - 여러 스트림을 동시에 전송 가능했지만, TCP 위에 동작하기 때문에 **패킷 손실 시 전체 연결이 블로킹**되는 문제가 남음 (전송 계층 HOL)
        
- **HTTP/3 (QUIC)**
    
    - 각 스트림을 독립적으로 관리 → 특정 스트림 패킷 손실이 다른 스트림에 영향을 주지 않음
        

---
 4. **내장된 보안 (TLS 1.3)**

- TCP+TLS 구조와 달리, QUIC 자체에 TLS 1.3이 통합됨
    
- 별도의 보안 계층 협상 필요 없음 → 성능 + 보안 강화
    

---
 5. **모바일 환경 최적화**

- TCP는 IP 주소가 바뀌면(예: LTE → Wi-Fi 전환) 연결이 끊김
    
- QUIC은 **Connection ID**를 사용 → 네트워크 변경에도 연결 유지 가능
    
- 모바일 환경에서 더 안정적인 통신 제공
    

---
📊 HTTP/2 vs HTTP/3 비교

|구분|HTTP/2|HTTP/3|
|---|---|---|
|전송 계층|TCP|UDP (QUIC)|
|보안|TLS 별도|TLS 1.3 내장|
|Multiplexing|지원 (응용 계층 HOL만 해결)|지원 (전송 계층 HOL도 해결)|
|연결 성립|3-way + TLS Handshake 필요|0-RTT/1-RTT, 빠른 연결|
|네트워크 이동성|TCP 연결 끊김|QUIC Connection ID로 유지|

---
✅ 정리

- **HTTP/3 = HTTP/2 + QUIC**
    
- 핵심 특징: **UDP 기반, QUIC 사용, 전송 계층 HOL Blocking 해결, TLS 1.3 내장, 빠른 연결 수립, 모바일 최적화**

📌 HTTP/3.0 (QUIC) 한계점

1. **UDP 기반으로 인한 네트워크 인프라 호환성 문제**

- QUIC은 UDP를 기반으로 동작합니다.
    
- 일부 방화벽, NAT, IDS/IPS 같은 보안 장비는 TCP만 안정적으로 지원하고, UDP 트래픽은 차단하거나 제한하기도 합니다.
    
- 따라서 HTTP/3를 지원하지 않는 네트워크 환경에서는 여전히 HTTP/2(TCP)로 폴백(fallback) 필요.
    

---
 2. **CPU 사용량 증가**

- QUIC은 사용자 공간(User Space)에서 구현된 프로토콜 (TCP는 커널 레벨).
    
- 암호화(TLS 1.3)까지 프로토콜에 내장 → 패킷 처리 비용 증가.
    
- 따라서 고성능 서버에서는 CPU 부하가 TCP보다 커질 수 있음.
    

---
 3. **패킷 손실 시 오버헤드**

- QUIC은 스트림 단위로 독립적으로 패킷을 처리하지만, 손실 패킷 재전송 로직이 TCP만큼 최적화되어 있지 않음.
    
- 무선 환경(LTE/5G, Wi-Fi)에서 패킷 손실률이 높을 경우 TCP 대비 성능이 나빠질 수 있음.
    

---
 4. **네트워크 장비 모니터링/관리 어려움**

- TCP는 커널에서 관리되므로 네트워크 장비에서 상태 모니터링이 용이함.
    
- QUIC은 사용자 공간 구현 + 암호화가 강제되므로, **네트워크 장비 입장에서 패킷 내용을 분석하거나 최적화하기 어려움**.
    
- ISP/기업 네트워크에서 트래픽 관리가 까다로워짐.
    

---
 5. **배포 및 지원 성숙도**

- HTTP/3는 아직 모든 브라우저, 서버, 네트워크 장비에서 100% 지원되지 않음.
    
- CDN(Cloudflare, Akamai 등)과 최신 브라우저는 지원하지만, 구형 환경에서는 HTTP/2로 다운그레이드 필요.
    

---
 📊 요약: HTTP/3.0 한계

1. UDP 기반 → 일부 방화벽/NAT에서 차단될 수 있음
    
2. CPU 사용량 증가 (User Space + TLS 1.3 암호화)
    
3. 무선 네트워크 환경에서 패킷 손실 시 성능 저하 가능
    
4. 네트워크 장비 모니터링·트래픽 관리 어려움
    
5. 지원 성숙도 낮음 → 여전히 HTTP/2 fallback 필요
    

---
 ✅ 정리

HTTP/3는 **빠른 연결, HOL Blocking 해결, 모바일 최적화**라는 장점이 있지만,  
아직은 **호환성과 성능 오버헤드 문제** 때문에 모든 서비스가 단독으로 HTTP/3만 쓰기는 어렵습니다.  
그래서 **실무에서는 HTTP/2와 함께 혼합 지원(negotiation/fallback)**하는 게 일반적입니다.
### 7. TCP와 UDP의 차이에 대해 설명해 주세요.
##### 설명
**TCP**와 **UDP**는 모두 전송 계층(Transport Layer) 프로토콜이지만, 성격과 사용 목적이 확실히 다릅니다.

---
📌 TCP (Transmission Control Protocol)

- **연결형 프로토콜 (Connection-oriented)**
    
- 데이터를 보내기 전에 **3-way Handshake**로 연결을 확립해야 함
    
- **특징**
    1. **신뢰성 보장**
        
        - 패킷 손실 시 재전송, 순서 보장, 오류 검출
            
    2. **흐름 제어 & 혼잡 제어 지원**
        - 네트워크 상태에 따라 전송 속도 조절
            
    3. **속도보다 정확성 우선**
        
- **사용 예시**: 웹(HTTP/HTTPS), 이메일(SMTP, IMAP, POP3), 파일 전송(FTP)
    

---
📌 UDP (User Datagram Protocol)

- **비연결형 프로토콜 (Connectionless)**
    
- 데이터를 보내기 전에 연결 과정 없음 → 그냥 “던지고 끝” (Best-effort)
    
- **특징**
    
    1. **신뢰성 보장 없음**
        
        - 패킷 손실 가능, 순서 보장 없음
            
    2. **오버헤드 적음**
        
        - 헤더가 단순 → 처리 속도 빠름
            
    3. **실시간성 중요**
        
        - 약간의 손실보다 지연 없는 전송이 더 중요할 때 적합
            
- **사용 예시**: 화상통화, 온라인 게임, 스트리밍, DNS 조회
    

---
 📊 TCP vs UDP 비교 표

| 구분       | TCP                   | UDP              |
| -------- | --------------------- | ---------------- |
| 연결 방식    | 연결형 (3-way Handshake) | 비연결형             |
| 신뢰성      | 보장 (재전송, 순서 유지)       | 보장하지 않음          |
| 전송 속도    | 상대적으로 느림              | 빠름               |
| 헤더 크기    | 20바이트 이상              | 8바이트             |
| 흐름/혼잡 제어 | 있음                    | 없음               |
| 사용 사례    | 웹, 메일, 파일 전송          | 실시간 통신, 게임, 스트리밍 |

---
 ✅ 정리

- **TCP**: 연결형, 신뢰성 보장, 순서 유지 → 정확성이 중요한 서비스에 적합
    
- **UDP**: 비연결형, 빠르고 단순, 손실 허용 → 실시간성이 중요한 서비스에 적합
    

---

👉 면접식으로 짧게 말하면:

> “TCP는 연결 기반으로 신뢰성과 순서를 보장하지만 느리고, UDP는 연결 과정 없이 빠르지만 신뢰성을 보장하지 않습니다. 그래서 TCP는 웹/메일에, UDP는 게임/스트리밍 같은 실시간 서비스에 적합합니다.”
##### Checksum이 무엇인가요?
좋은 질문이에요 👍  
**Checksum(체크섬)**은 네트워크나 파일 전송에서 **데이터의 무결성(Integrity)**을 확인하기 위해 사용되는 값입니다.

---
📌 정의

- **Checksum** = 데이터를 일정한 규칙(보통 덧셈)으로 계산한 **검증용 숫자**
    
- 전송 중 데이터가 손상되었는지(비트 오류 발생 여부)를 확인하는 간단한 방식
    
---
📌 동작 원리

1. **송신 측**
    
    - 보낼 데이터를 바이트 단위(혹은 워드 단위)로 나눔
        
    - 특정 알고리즘(단순 합, 보수 연산 등)으로 합계를 계산 → **Checksum 값** 생성
        
    - 데이터 + Checksum을 함께 전송
        
2. **수신 측**
    
    - 받은 데이터에 대해 동일한 방식으로 Checksum 계산
        
    - 송신자가 보낸 Checksum과 비교
        
    - 두 값이 같으면 "데이터 이상 없음", 다르면 "오류 발생"
        

---
📌 네트워크에서의 예

- **IP 헤더, TCP, UDP** 모두 Checksum 필드를 포함
    
- 예: UDP 헤더 구조
    
    `| Source Port | Destination Port | | Length      | Checksum         |`
    
    → 여기서 Checksum은 UDP 헤더 + 데이터 전체를 기반으로 계산
    

---
📌 장단점

- **장점**
    
    - 계산이 빠르고 구현이 단순
        
    - 네트워크에서 기본 무결성 검증 수단으로 널리 사용
        
- **단점**
    
    - 단순 오류(비트 뒤집힘 등)는 잘 잡아내지만,
        
    - 복잡한 오류(순서 바뀜, 특정 패턴 오류)는 놓칠 수 있음
        
    - 더 강력한 무결성 검증은 **CRC, 해시(MD5, SHA)** 같은 방식 사용
        

---
📊 예시

데이터: `10101010, 11110000, 00001111`

- 합계 계산 → `11111111`
    
- 보수 취하면 Checksum = `00000000`
    
- 수신 측이 데이터를 합쳐서 Checksum을 포함한 결과가 `11111111`이 나오면 정상
    

---
✅ 정리

- **Checksum은 데이터 전송 중 손상 여부를 확인하는 검증값**
    
- 송신 측에서 계산해 함께 보내고, 수신 측에서 다시 계산해 비교
    
- 네트워크(TCP/UDP/IP)에서 기본적인 무결성 확인 용도로 사용
    

---

👉 면접용으로 짧게 답하면:

> “Checksum은 데이터를 전송할 때 손상 여부를 검증하기 위해 계산된 값입니다. 송신자가 계산해 보내면, 수신자가 다시 계산해 비교함으로써 오류 여부를 확인할 수 있습니다. TCP/UDP/IP 헤더에도 이 필드가 포함돼 있습니다.”
##### TCP와 UDP 중 어느 프로토콜이 Checksum을 수행할까요?
정답은 **TCP와 UDP 모두 Checksum을 수행합니다.**

---
📌 TCP의 Checksum

- TCP 헤더에는 **Checksum 필드(16비트)**가 있습니다.
    
- 계산 범위:
    
    1. **TCP 헤더**
        
    2. **TCP 데이터(payload)**
        
    3. **의사 헤더(Pseudo Header)**
        
        - 출발지 IP, 목적지 IP, 프로토콜 번호, TCP 길이 포함
            
        - 이걸 넣는 이유: IP 계층에서 라우팅 중에 다른 호스트로 잘못 가지 않았는지 확인하기 위함
            

👉 TCP는 신뢰성 보장을 위해 반드시 Checksum을 사용합니다. (의무적)

---
📌 UDP의 Checksum

- UDP 헤더에도 **Checksum 필드(16비트)**가 있습니다.
    
- 계산 범위:
    
    1. **UDP 헤더**
        
    2. **UDP 데이터(payload)**
        
    3. **의사 헤더(Pseudo Header)** (TCP와 동일 구조)
        

👉 차이점:

- **IPv4에서는 Checksum이 옵션(optional)** → 값이 0이면 "사용하지 않음"을 의미
    
- **IPv6에서는 필수(mandatory)** → 항상 Checksum을 계산해야 함
    

---
📊 비교 정리

|구분|TCP|UDP|
|---|---|---|
|Checksum 유무|항상 수행 (필수)|IPv4에서는 옵션, IPv6에서는 필수|
|계산 범위|TCP 헤더 + 데이터 + 의사 헤더|UDP 헤더 + 데이터 + 의사 헤더|
|목적|데이터 무결성 + 라우팅 오류 검출|데이터 무결성 + 라우팅 오류 검출|

---
✅ 정리

- **TCP와 UDP 모두 Checksum 수행**
    
- TCP는 무조건 필수, UDP는 IPv4에서는 옵션이지만 IPv6에서는 필수
    
- 계산 시 TCP/UDP 헤더와 데이터 외에도 **의사 헤더(Pseudo Header)**를 포함해 IP 계층 오류까지 잡아낼 수 있음
    

---

👉 면접식 짧은 답변:

> “TCP와 UDP 모두 Checksum을 수행합니다. TCP는 필수이고, UDP는 IPv4에서는 옵션이지만 IPv6에서는 필수입니다. 계산할 때는 헤더와 데이터뿐 아니라 출발지/목적지 IP를 담은 의사 헤더도 함께 포함해 무결성을 검증합니다.”

###### ipv6만 필수인 이유
📌 1. IPv4에서 Checksum이 선택이었던 이유

- IPv4는 원래 **IP 헤더 자체에 Checksum 필드(16비트)**가 있었습니다.
    
- 즉, 네트워크 계층(IP)에서도 오류 검출을 했고, 전송 계층(UDP)에서도 오류 검출을 하면 **중복 검사**가 된다고 본 거예요.
    
- 그래서 UDP Checksum은 IPv4에서 **0(=사용하지 않음)**으로 설정할 수 있었습니다.
    
- 실제로 성능을 위해 많은 시스템이 UDP Checksum을 꺼 버리기도 했습니다(DNS, 스트리밍 등).
    

---
📌 2. IPv6에서 Checksum이 필수가 된 이유

IPv6에서는 **IP 헤더의 Checksum 필드가 제거**되었습니다.

- 이유: 라우터가 패킷을 전달할 때 TTL(Time To Live) 같은 필드를 매번 감소시키면서 헤더 체크섬을 다시 계산해야 했습니다.
    
- 이게 **라우터 성능을 크게 저하**시키는 원인이었어요.
    
- 그래서 IPv6에서는 IP 계층에서 오류 검출을 아예 제거 → 상위 계층(TCP/UDP)에서 책임지도록 설계
    

따라서 UDP에서는 더 이상 “옵션”이 될 수 없고, **데이터 무결성을 반드시 보장하기 위해 필수**가 되었습니다.

---
📌 3. 추가 배경

- IPv6는 **end-to-end 설계 철학**을 따릅니다.  
    → 네트워크(라우터)가 중간에서 불필요하게 검사하지 말고, **종단 노드(송신자·수신자)**가 책임지고 데이터 무결성을 검증.
    
- 그래서 UDP도 IPv6에서는 Checksum을 **반드시 수행해야 한다**는 규칙이 생겼습니다.
    

---
📊 요약

|구분|IPv4|IPv6|
|---|---|---|
|IP 헤더|Checksum 필드 있음|Checksum 필드 없음|
|UDP Checksum|선택 (0이면 미사용 가능)|필수 (반드시 사용)|
|이유|IP 계층에서 이미 오류 검출 가능|IP 계층에 오류 검출 기능 없음 → 전송 계층에서 책임|
|설계 철학|중복 체크 허용|단순화 + end-to-end 무결성 보장|

---
✅ 정리

- IPv4: IP 계층에도 Checksum이 있어서 UDP Checksum은 중복적이라 선택 가능.
    
- IPv6: IP 헤더에서 Checksum을 없앴기 때문에, UDP가 반드시 무결성을 확인해야 함 → **필수**.
    

---

👉 면접 답변식으로 짧게 말하면:

> “IPv4에는 IP 헤더에 이미 Checksum이 있어서 UDP Checksum은 선택이었지만, IPv6는 성능 최적화를 위해 IP 헤더에서 Checksum을 제거했습니다. 그래서 IPv6에서는 UDP Checksum이 데이터 무결성을 보장하는 유일한 수단이 되어 필수가 되었습니다.”
##### 그렇다면, Checksum을 통해 오류를 정정할 수 있나요?
👉 **Checksum은 오류를 “검출(Detect)”할 수는 있지만, “정정(Correct)”할 수는 없습니다.**

---
📌 Checksum의 역할

- **송신 측**: 데이터를 일정한 규칙(보통 16비트 단위 합산)으로 더해서 Checksum 생성
    
- **수신 측**: 받은 데이터로 다시 계산한 Checksum과 송신자가 보낸 값 비교
    
- 일치하면 “정상”, 다르면 “오류 발생”
    

즉, **데이터가 손상되었는지 여부**만 알 수 있습니다.

---
📌 왜 오류 정정은 불가능한가?

- Checksum은 단순히 **검증값(요약값)**만 보내기 때문
    
- “어느 비트가 잘못됐는지” 정보가 없으므로 수신 측은 오류 위치를 알 수 없음
    
- 따라서 수신 측은 **재전송 요청(ARQ)**을 통해 데이터를 다시 받아야 합니다
    

---
📌 오류 검출 vs 오류 정정

- **오류 검출 (Error Detection)**
    
    - Checksum, CRC(Cyclic Redundancy Check), 해시(MD5, SHA 등)
        
    - 데이터 손상 여부만 확인 가능 → 정정 불가
        
- **오류 정정 (Error Correction)**
    
    - ECC 메모리, Hamming Code, Reed-Solomon Code 등
        
    - 데이터 자체에 **冗長 정보(추가 비트)**를 넣어서, 수신 측이 스스로 오류를 복구 가능
        

---
📊 예시

- Checksum:
    
    - “데이터에 오류 있음!” 🚨 은 알림
        
    - “어디가 잘못됐는지는 모름” → 재전송 필요
        
- Error Correction Code(ECC):
    
    - “3번째 비트가 잘못됐네 → 고쳐야지” ✨
        
    - 오류를 직접 수정 가능
        

---
✅ 정리

- **Checksum = 오류 검출만 가능, 정정 불가**
    
- 오류가 발견되면 TCP 같은 신뢰성 프로토콜은 **재전송**을 통해 복구
    
- 정정이 필요한 경우에는 **에러 정정 코드(ECC)** 같은 별도의 방식 사용
    

---

👉 면접용 짧은 답변:

> “Checksum은 오류를 검출할 수는 있지만 정정할 수는 없습니다. 오류가 나면 TCP 같은 신뢰성 프로토콜이 재전송을 요청해 복구합니다. 오류 정정이 필요하다면 Hamming Code 같은 ECC 기법을 사용합니다.”
##### TCP가 신뢰성을 보장하는 방법에 대해 설명해 주세요.
좋은 질문이에요 👍  
**TCP(Transmission Control Protocol)**가 신뢰성을 보장한다는 건,  
데이터가 **손실·중복·순서 뒤바뀜 없이 정확히** 도착하도록 여러 메커니즘을 갖추고 있다는 뜻입니다.

---
📌 TCP가 신뢰성을 보장하는 주요 방법

1. **연결 설정 (3-Way Handshake)**

- 데이터를 전송하기 전에 클라이언트와 서버가 **논리적 연결**을 맺음
    
- 양쪽이 서로 송수신 준비가 됐음을 확인 → 신뢰성 있는 시작
    
---
2. **순서 보장 (Sequence Number)**

- TCP 세그먼트마다 **시퀀스 번호(Sequence Number)**를 붙임
    
- 수신 측은 이 번호를 기준으로 세그먼트를 재조립 → 순서가 뒤바뀌어도 원래 순서대로 복원 가능
    

---
3. **데이터 검증 (Checksum)**

- TCP 세그먼트마다 **Checksum 필드** 존재
    
- 수신 측에서 계산해 송신 측 값과 비교 → 데이터 손상 여부 확인
    
- 오류 발생 시 해당 세그먼트 폐기 + 재전송 요청
    

---
 4. **수신 확인 (ACK, Acknowledgment)**

- 수신 측은 세그먼트를 받으면 **ACK 응답**을 보냄
    
- 송신 측은 ACK를 받아야 다음 데이터 전송
    
- ACK가 오지 않으면 **재전송** 수행
    

---
5. **흐름 제어 (Flow Control, Sliding Window)**

- 수신 측 버퍼에 맞게 송신 속도를 조절
    
- 수신 측은 `Window Size`를 알려줌 → 송신 측은 그 범위 내에서만 데이터 전송
    
- 수신 측이 과부하로 터지지 않도록 보호
    

---
 6. **혼잡 제어 (Congestion Control)**

- 네트워크 자체가 혼잡하면 손실·지연 발생
    
- TCP는 네트워크 상태를 감지하여 전송 속도를 줄이거나 늘림
    
- 대표 알고리즘: Slow Start, Congestion Avoidance, Fast Retransmit, Fast Recovery
    

---
📊 요약

TCP의 신뢰성 보장은 아래 요소들의 조합으로 이루어집니다:

1. 연결 설정 (3-Way Handshake)
    
2. 시퀀스 번호로 순서 보장
    
3. 체크섬으로 데이터 오류 검출
    
4. ACK/재전송으로 손실 복구
    
5. 흐름 제어로 수신 측 과부하 방지
    
6. 혼잡 제어로 네트워크 안정성 확보
    

---
✅ 정리

👉 TCP는 단순히 “데이터를 보내는 것”이 아니라, **데이터가 손실·중복·순서 뒤바뀜 없이 정확하게 도착하도록 보장하는 프로토콜**입니다.  
이를 위해 **시퀀스 번호, ACK, 체크섬, 흐름 제어, 혼잡 제어** 같은 메커니즘을 사용합니다.
##### TCP의 혼잡 제어 처리 방법에 대해 설명해 주세요.
좋은 질문이에요 👍  
**TCP 혼잡 제어(Congestion Control)**는 네트워크가 한 번에 처리할 수 있는 용량을 초과하지 않도록 송신 속도를 조절하는 메커니즘입니다.  
즉, **네트워크 전체가 혼잡해지지 않도록 제어하는 것**이에요.

---
📌 TCP 혼잡 제어의 기본 개념

- TCP는 네트워크 상황을 직접 알 수 없으므로 **패킷 손실(Timeout, 중복 ACK)**을 혼잡 신호로 간주합니다.
    
- 전송 윈도우(`Congestion Window`, cwnd)를 조절해 송신 속도를 제어합니다.
    
- 핵심 목표: **네트워크를 과부하시키지 않고, 가능한 한 최대 속도로 전송**
    

---
 📌 TCP 혼잡 제어 단계별 동작

 1. **Slow Start (느린 시작)**

- 처음 연결 시, 작은 `cwnd`(보통 1 MSS)부터 시작
    
- ACK가 올 때마다 `cwnd`를 **지수적으로 증가** (1, 2, 4, 8…)
    
- 네트워크 용량을 빠르게 찾는 과정
    

---
 2. **Congestion Avoidance (혼잡 회피)**

- `cwnd`가 **임계값(ssthresh)**에 도달하면 증가 속도를 늦춤
    
- 지수 증가 대신, **선형 증가** (매 RTT마다 +1)
    
- → 네트워크를 안정적으로 사용하려는 단계
    

---
3. **Fast Retransmit (빠른 재전송)**

- 송신자가 **중복 ACK 3개**를 받으면, 패킷 손실을 감지
    
- 타임아웃 기다리지 않고 즉시 해당 세그먼트 재전송
    

---
4. **Fast Recovery (빠른 회복)**

- Fast Retransmit 후, 혼잡 윈도우를 절반으로 줄이고 선형 증가
    
- 완전히 Slow Start로 돌아가지 않고, 네트워크가 어느 정도 용량을 유지하도록 함
    

---
📊 요약 그림 (흐름)

```
패킷 전송 시작
   ↓
[Slow Start] → cwnd 지수 증가
   ↓ (임계값 도달)
[Congestion Avoidance] → cwnd 선형 증가
   ↓ (손실 감지)
[Fast Retransmit + Fast Recovery]
   ↓
cwnd 조정 후 다시 증가

```

---

📌 혼잡 제어와 흐름 제어의 차이

- **혼잡 제어**: 네트워크 전체가 혼잡하지 않게 송신 속도 조절 (네트워크 보호)
    
- **흐름 제어**: 수신자가 감당할 수 있는 만큼만 송신 (수신자 보호)
    

---
✅ 정리

TCP 혼잡 제어는 크게 네 단계로 요약할 수 있습니다:

1. **Slow Start**: 처음에는 지수적으로 빠르게 증가
    
2. **Congestion Avoidance**: 임계값 이후에는 선형 증가
    
3. **Fast Retransmit**: 중복 ACK 3개로 빠른 재전송
    
4. **Fast Recovery**: cwnd 절반으로 줄인 뒤 회복
##### 왜 HTTP는 TCP를 사용하나요?
**HTTP가 왜 TCP 위에서 동작하는지**는 HTTP 자체의 성격(웹 문서 전송 프로토콜)과 TCP의 특성이 맞아떨어지기 때문입니다.

---

📌 1. HTTP의 요구사항

HTTP는 원래 **하이퍼텍스트 문서(HTML)와 리소스(이미지, CSS 등)**를 안정적으로 전달하기 위해 설계되었습니다.  
따라서 HTTP가 필요로 하는 것은:

1. **데이터 신뢰성**
    
    - HTML 문서의 태그 하나라도 빠지면 웹페이지가 깨집니다.
        
    - 데이터가 손실되거나 순서가 바뀌면 안 됨.
        
2. **전송 순서 보장**
    
    - `<head>`가 `<body>`보다 늦게 오면 브라우저가 올바르게 해석하지 못함.
        
3. **전송 오류 검출**
    
    - 데이터가 손상되면 재전송할 수 있어야 함.
        

👉 즉, **정확성과 신뢰성이 최우선**이었음.

---
📌 2. TCP의 특징

TCP는 전송 계층에서 다음을 제공합니다:

- **연결 지향 (3-Way Handshake)** → 안정적인 연결 수립
    
- **신뢰성 보장**
    
    - 손실 시 재전송(ARQ)
        
    - 데이터 순서 보장(Sequence Number)
        
    - 중복 제거, 오류 검출(Checksum)
        
- **흐름 제어 & 혼잡 제어** → 네트워크 안정성
    

👉 TCP는 **HTTP가 필요로 하는 신뢰성·정확성 요구사항**을 완벽하게 충족

---
📌 3. UDP 대신 TCP인 이유

- **UDP는 빠르지만 신뢰성을 보장하지 않음**
    
    - 패킷이 유실되거나 순서가 바뀔 수 있음
        
    - 웹 문서나 이미지처럼 **완전성이 중요한 데이터**에는 적합하지 않음
        
- 반대로, **영상 스트리밍·게임**처럼 실시간성이 중요한 경우는 UDP를 활용
    

---
📌 4. 변화: HTTP/3

- HTTP/1.1, HTTP/2 → TCP 기반
    
- 하지만 TCP 기반 한계(HOL Blocking, 연결 지연) 때문에
    
- **HTTP/3는 UDP 기반 QUIC**을 사용하여 신뢰성과 속도를 모두 잡음
    

---
✅ 정리

HTTP는 원래 **정확한 데이터 전송**이 목적이라 TCP의 **신뢰성·순서 보장·오류 복구** 특성이 적합해서 TCP 위에서 동작합니다.  
실시간성이 중요한 경우에는 UDP가 더 맞지만, 일반적인 웹 브라우징은 데이터 손실 없는 신뢰성이 훨씬 더 중요했기 때문에 TCP가 선택된 겁니다.

---

👉 면접용 짧은 답변:

> “HTTP는 문서와 리소스를 정확하게 전송해야 하기 때문에 신뢰성과 순서를 보장하는 TCP 위에서 동작합니다. UDP는 빠르지만 손실이 발생할 수 있어 적합하지 않고, 그래서 HTTP/1.1과 2는 TCP를 사용합니다. 다만 HTTP/3는 QUIC(UDP 기반)를 사용해 성능 한계를 극복했습니다.”
##### 그렇다면, 왜 HTTP/3 에서는 UDP를 사용하나요? 위에서 언급한 UDP의 문제가 해결되었나요?
📌 UDP 자체의 문제

- **비연결형** → 순서 보장 없음
    
- **신뢰성 부족** → 손실·중복·손상 시 보장 안 됨
    
- **혼잡 제어 없음** → 네트워크 과부하 방지 장치 없음
    

👉 그래서 UDP는 원래 “빠르지만 대충 던지는” 방식이라 HTTP 같은 신뢰성이 중요한 프로토콜에는 부적합했습니다.

---
📌 HTTP/3에서 UDP 사용 이유

HTTP/3는 **UDP를 그대로 쓰는 게 아니라, UDP 위에 QUIC이라는 전송 계층 프로토콜을 새로 설계**해서 사용합니다.  
즉, **UDP의 장점을 살리면서 TCP의 단점을 극복**한 것이 QUIC입니다.

---
📌 QUIC(Quick UDP Internet Connections)이 UDP의 문제를 해결하는 방법

1. **신뢰성 보장**

- QUIC은 **패킷 재전송, 순서 보장, 흐름 제어**를 자체적으로 구현
    
- 즉, UDP 위에서 TCP가 제공하던 신뢰성을 다시 제공 → UDP의 가장 큰 단점 해결
    

---
 2. **HOL Blocking 문제 해결**

- TCP: 하나의 패킷 손실이 나면 전체 스트림이 블로킹됨 (Head-of-Line Blocking)
    
- QUIC: 스트림을 독립적으로 관리 → 특정 스트림이 손실돼도 다른 스트림은 정상 전송 가능
    
---
3. **빠른 연결 수립**

- TCP: 3-way Handshake + TLS Handshake → 최소 2~3 RTT 필요
    
- QUIC: **TLS 1.3을 프로토콜에 통합** → 연결 수립과 암호화를 동시에 (1-RTT, 재연결은 0-RTT)
    

---
 4. **모바일 환경 최적화**

- TCP: IP 주소가 바뀌면 연결 끊김 (예: LTE → Wi-Fi 전환 시 재연결 필요)
    
- QUIC: **Connection ID**를 사용해 네트워크가 바뀌어도 연결 유지 가능
    

---
5. **사용자 공간(User-space) 구현**

- TCP는 커널에 구현되어 있어 새로운 기능 도입이 느림
    
- QUIC은 사용자 공간에 구현되어 업데이트와 배포가 빠름 (구글·클라우드플레어 등에서 적극 사용)
    

---
📊 TCP vs QUIC 비교

|구분|TCP|QUIC(UDP 기반)|
|---|---|---|
|신뢰성|기본 제공|QUIC이 구현|
|HOL Blocking|있음|없음 (스트림 독립 전송)|
|연결 수립|3-way + TLS → 2~3 RTT|1-RTT (재연결은 0-RTT)|
|암호화|TLS 별도 계층|TLS 1.3 내장|
|네트워크 이동성|IP 바뀌면 끊김|Connection ID로 유지|
|구현 위치|커널|사용자 공간|

---
 ✅ 정리

- HTTP/3는 UDP의 문제를 그대로 쓰지 않고, **UDP 위에 QUIC을 올려서 TCP 수준의 신뢰성과 더 나은 성능**을 확보했습니다.
    
- 즉, **UDP의 문제는 QUIC이 해결했기 때문에 HTTP/3에서 UDP를 쓸 수 있게 된 것**입니다.
    

---

👉 면접용 짧은 답변:

> “HTTP/3는 TCP 대신 UDP 기반 QUIC을 사용합니다. QUIC은 UDP 위에서 TCP의 기능(재전송, 순서 보장, 혼잡 제어 등)을 구현해 신뢰성을 확보했고, 동시에 TCP의 HOL Blocking과 연결 지연 문제를 해결했습니다. 또 TLS 1.3을 내장해 빠른 연결 수립이 가능하고, 네트워크 이동성도 지원합니다.”
##### 그런데, 브라우저는 어떤 서버가 TCP를 쓰는지 UDP를 쓰는지 어떻게 알 수 있나요?
좋은 질문이에요 👍  
HTTP/3(=UDP 기반 QUIC)와 HTTP/1.1,2(=TCP 기반)가 공존하는 현재, **브라우저는 어떻게 서버가 TCP를 쓸지 UDP를 쓸지 알아낼까요?**

---
📌 1. 기본 원칙

- 브라우저는 무작정 UDP로 먼저 접속하지 않습니다.
    
- **기본은 TCP(HTTP/1.1 또는 2)로 시작** → 이후 서버가 “나 HTTP/3 지원해”라고 알리면 UDP/QUIC로 업그레이드 시도합니다.
    

---
📌 2. 서버가 HTTP/3 지원을 알리는 방법

서버는 **HTTP 응답 헤더 또는 DNS 레코드**를 통해 HTTP/3 지원을 광고합니다.

(1) Alt-Svc 헤더 (Alternative Services)

- 서버가 초기 HTTP 응답에서 `Alt-Svc` 헤더로 HTTP/3 지원을 알립니다.
    
- 예시:
    
    `Alt-Svc: h3=":443"; ma=86400`
    
    - `h3` = HTTP/3 지원
        
    - `:443` = 포트
        
    - `ma=86400` = 24시간 동안 캐시 가능
        

👉 브라우저는 이후 같은 도메인에 요청할 때 UDP/QUIC(HTTP/3) 시도

---
 (2) DNS HTTPS RR (DNS Resource Record, aka HTTPSSVC)

- 최신 방식: DNS 조회 시 **HTTPS RR 레코드**를 반환
    
- 예시:
    
    `example.com. IN HTTPS 1 . alpn="h3" port="443"`
    
- 브라우저가 DNS 조회만으로도 HTTP/3 지원 여부를 알 수 있음
    

---
📌 3. 브라우저 동작 흐름

1. 클라이언트(브라우저)가 서버에 접속 → 기본적으로 TCP 기반 HTTP/1.1 또는 2로 시작
    
2. 서버 응답 헤더에 `Alt-Svc`나 DNS에서 `HTTPS RR`을 받음
    
3. 브라우저는 다음 요청부터 HTTP/3(UDP/QUIC) 연결 시도
    
4. HTTP/3 연결이 성공하면, 그 이후엔 HTTP/3로 통신
    

👉 즉, **TCP → UDP(HTTP/3)로 점진적 업그레이드** 방식

---
📊 요약

- 브라우저는 처음부터 “UDP 쓸래?” 하고 접속하지 않음
    
- 서버가 `Alt-Svc` 헤더나 `DNS HTTPS RR`로 HTTP/3 지원을 광고
    
- 브라우저는 이를 보고, 다음 요청부터 UDP/QUIC(HTTP/3)를 시도
    

---
✅ 정리

브라우저는 **Alt-Svc 헤더** 또는 **DNS HTTPS RR**을 통해 서버가 HTTP/3(UDP 기반)을 지원하는지 확인합니다.  
처음엔 TCP 기반으로 접속하고, 서버가 광고하면 이후 UDP/QUIC으로 업그레이드하는 방식입니다.

---

👉 면접용 짧은 답변:

> “브라우저는 기본적으로 TCP로 접속한 뒤, 서버가 Alt-Svc 헤더나 DNS HTTPS RR을 통해 HTTP/3 지원을 광고하면 그다음 요청부터 UDP/QUIC을 사용합니다.”
##### 본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?좋은 질문이에요 👍 (면접에서 정말 많이 물어볼 만한 질문입니다)  
“새로운 통신 프로토콜을 TCP로 만들지, UDP로 만들지 선택한다면 어떤 기준으로 고를까?”를 답하려면 **TCP와 UDP의 장단점을 기준으로 서비스 요구사항과 매칭**하는 사고를 보여주면 됩니다.

---
📌 선택 기준 정리

1. **신뢰성(데이터 무결성) 요구**

- **필수**라면 → **TCP**
    
    - 데이터 유실·순서 뒤바뀜 없이 100% 전달 보장
        
    - 예: 웹 요청/응답, 파일 전송, 금융 거래, 메일
        
- **부분적 손실 허용** 가능하다면 → **UDP**
    
    - 약간의 데이터 손실이 있어도 서비스 영향이 크지 않음
        
    - 예: 화상회의, 온라인 게임, 스트리밍
        

---

2. **실시간성 요구**

- **지연(latency)이 중요한 경우** → **UDP**
    
    - TCP는 손실 시 재전송 때문에 지연 발생
        
    - UDP는 재전송 없음 → 끊김은 있어도 실시간성 보장
        
    - 예: 음성/영상 통화, 온라인 방송
        
- **지연보다 정확성이 중요한 경우** → **TCP**
    
    - 예: 전자상거래 결제, 파일 다운로드
        

---

3. **네트워크 환경**

- **방화벽/NAT 환경**에서는 TCP가 더 호환성 높음
    
- UDP는 일부 네트워크 장비에서 제한될 수 있음 → 이 경우 TCP 기반 프로토콜 선택
    

---
4. **구현 복잡성**

- TCP는 이미 신뢰성·흐름제어·혼잡제어를 OS 커널에서 제공  
    → 애플리케이션은 “데이터만 쓰면 됨”
    
- UDP는 단순하지만, 신뢰성·순서 보장을 원하면 애플리케이션 레벨에서 직접 구현해야 함 (QUIC처럼)
    

---
📊 정리 표

|기준|TCP|UDP|
|---|---|---|
|신뢰성|보장 (재전송, 순서 유지)|보장 안 함|
|지연|재전송 때문에 느릴 수 있음|빠름 (지연 최소화)|
|손실|불허|일부 허용 가능|
|구현 난이도|단순 (커널이 처리)|신뢰성을 직접 구현해야 할 수 있음|
|사용 사례|HTTP, 메일, 파일 전송|실시간 스트리밍, 게임, VoIP|

---
✅ 면접식 답변 예시

> “저라면 서비스의 특성에 맞춰 선택하겠습니다.  
> 데이터의 **신뢰성과 순서 보장**이 가장 중요하다면 TCP를 선택할 것이고,  
> **실시간성과 저지연**이 더 중요하다면 UDP 기반으로 설계하겠습니다.  
> 만약 UDP를 쓰면서도 신뢰성이 필요하다면 QUIC처럼 애플리케이션 레벨에서 재전송·순서 제어를 구현할 수도 있을 것입니다.”


맞습니다 👍 정확히 짚으셨어요.  
UDP는 기본적으로 **“비연결형, 신뢰성 없음”**이지만, 애플리케이션 계층에서 기능을 추가하면 TCP처럼 **신뢰성과 순서 보장**을 구현할 수 있습니다.

대표적인 예가 바로 **QUIC(HTTP/3)** 입니다.

---

📌 UDP 위에서 TCP 기능을 재구현할 수 있는 방법

1. **신뢰성 보장**
    
    - 패킷마다 **Sequence Number** 부여
        
    - 수신 측이 ACK(확인 응답) 전송
        
    - 손실 시 송신 측이 재전송 (ARQ, Automatic Repeat reQuest)
        
2. **순서 보장**
    
    - 수신 측이 Sequence Number를 보고 재조립
        
    - 순서가 어긋난 패킷은 버퍼에 저장 후 정렬
        
3. **흐름 제어 (Flow Control)**
    
    - 수신 측이 `Window Size`를 알려 송신 측 전송량 제한
        
4. **혼잡 제어 (Congestion Control)**
    
    - 네트워크 혼잡 시 패킷 손실·지연 탐지
        
    - 전송 속도 동적으로 줄였다가 회복 (TCP Reno, CUBIC 등 알고리즘 차용 가능)
        

---
📌 그렇다면, “UDP로 TCP 재구현”의 장단점?

✅ 장점

- **자유도 높음**: 필요한 기능만 구현 → 오버헤드 줄일 수 있음
    
- **애플리케이션 레벨 최적화 가능**: TCP는 커널에 박혀 있지만, UDP는 사용자 공간에서 직접 구현 → 업데이트·실험 용이
    
- **실시간성 강화**: TCP는 전체 스트림 HOL Blocking 문제 → UDP 위에서는 스트림 독립 처리 가능 (QUIC이 이 방식)
    
- **네트워크 이동성 지원**: TCP는 IP가 바뀌면 연결 끊기지만, QUIC은 Connection ID 사용
    

❌ 단점

- **복잡성 증가**: 신뢰성·순서 보장·혼잡 제어 등을 직접 구현해야 함
    
- **성능 비용**: 사용자 공간에서 모든 걸 처리해야 하므로 CPU 부하 ↑
    
- **호환성 문제**: 일부 네트워크 환경(방화벽, NAT)은 UDP 트래픽을 차단하거나 제한
    

---
📌 실제 사례

- **QUIC (HTTP/3)**: UDP 위에 TCP 기능 + 추가 기능 구현
    
    - 신뢰성, 순서 보장, 혼잡 제어까지 자체 내장
        
    - TCP보다 빠른 연결 성립(0-RTT), HOL Blocking 해결
        
- **온라인 게임 프로토콜**: UDP를 기본으로 쓰되, 중요한 패킷(예: 위치 동기화)에는 자체 ACK 붙여서 신뢰성 보장
    

---
✅ 정리

👉 UDP 위에 TCP 기능을 얹으면 **신뢰성과 순서 보장도 가능**합니다.  
하지만 그만큼 **구현 복잡도와 CPU 비용이 증가**하기 때문에, 보편적인 경우엔 TCP를 그대로 쓰는 게 더 효율적이고,  
**특수한 경우(저지연·실시간성 필요)**에만 UDP 커스터마이징을 선택합니다.

---

👉 면접식 답변 예시:

> “UDP는 기본적으로 신뢰성이 없지만, 애플리케이션 계층에서 ACK, 재전송, 순서 제어를 구현하면 TCP처럼 동작할 수 있습니다. QUIC이 그 대표적인 사례죠. 다만 이런 방식은 구현 복잡성과 CPU 오버헤드가 크기 때문에, 일반적인 신뢰성 요구에는 TCP를 쓰고, 저지연·실시간성이 중요한 경우에만 UDP를 커스터마이징하는 게 합리적입니다.”

### 8. DHCP가 무엇인지 설명해 주세요.

### 9. IP 주소는 무엇이며, 어떤 기능을 하고 있나요?

### 10. OSI 7계층에 대해 설명해 주세요.

### 11. 3-Way Handshake에 대해 설명해 주세요.

### 12. 4-Way Handshake에 대해 설명해 주세요.


### 13. [www.github.com을](http://www.github.xn--com-of0o/) 브라우저에 입력하고 엔터를 쳤을 때, 네트워크 상 어떤 일이 일어나는지 최대한 자세하게 설명해 주세요.


### 14. DNS에 대해 설명해 주세요.

### 15. SOP 정책에 대해 설명해 주세요.

### 16. Stateless와 Connectionless에 대해 설명해 주세요.

### 17. 라우터 내의 포워딩 과정에 대해 설명해 주세요.


### 18. 로드밸런서가 무엇인가요?


### 19. 서브넷 마스크와, 게이트웨이에 대해 설명해 주세요.


### 20. 멀티플렉싱과 디멀티플렉싱에 대해 설명해 주세요.


### 21. XSS에 대해서 설명해 주세요.


