### 1. 시스템 콜이 무엇인지 설명해 주세요.
##### 설명
💡 시스템 콜(System Call)이란?

시스템 콜(System Call)은 사용자 프로그램이 **운영체제 커널의 기능을 요청**하기 위해 사용하는 **인터페이스**입니다.

운영체제는 **사용자 프로그램이 직접 하드웨어나 중요 자원(CPU, 메모리, 디스크 등)에 접근하지 못하게 제한**하고 있습니다. 따라서 파일 입출력, 프로세스 생성, 네트워크 통신 같은 작업을 하려면 **운영체제에 요청**을 해야 하는데, 이때 사용하는 것이 **시스템 콜**입니다.

##### 우리가 사용하는 시스템 콜의 예시를 들어주세요.
✅ 1. **파일 시스템 관련 시스템 콜**

|시스템 콜|설명|
|---|---|
|`open()`|파일을 열고 파일 디스크립터 반환|
|`read()`|파일에서 데이터를 읽음|
|`write()`|파일에 데이터를 씀|
|`close()`|파일을 닫고 자원 반환|
|`lseek()`|파일 포인터 위치를 이동|
 ✅ 2. **프로세스 제어 관련 시스템 콜**

|시스템 콜|설명|
|---|---|
|`fork()`|현재 프로세스를 복제 (자식 프로세스 생성)|
|`exec()`|다른 프로그램 실행|
|`wait()`|자식 프로세스 종료 대기|
|`exit()`|현재 프로세스 종료|
|`getpid()`|현재 프로세스의 PID 반환|
 ✅ 3. **메모리 관리 시스템 콜**

| 시스템 콜              | 설명                 |
| ------------------ | ------------------ |
| `mmap()`           | 파일이나 디바이스를 메모리에 매핑 |
| `brk()` / `sbrk()` | 힙 영역 크기 조절         |
 ✅ 4. **디바이스/입출력 제어**

|시스템 콜|설명|
|---|---|
|`ioctl()`|장치 제어 명령 수행 (예: 터미널 설정)|
 ✅ 5. **네트워크 관련 시스템 콜 (소켓)**

|시스템 콜|설명|
|---|---|
|`socket()`|소켓 생성|
|`bind()`|소켓에 주소 지정|
|`connect()`|서버에 연결|
|`send()`, `recv()`|데이터 송수신|
|`close()`|소켓 닫기|
 ✅ 6. **시간/시스템 정보**

|시스템 콜|설명|
|---|---|
|`gettimeofday()`|현재 시간 가져오기|
|`uname()`|커널 이름, 버전 등 시스템 정보 조회|

🧠 정리

- 시스템 콜은 **운영체제 자원을 요청할 때마다 사용**됨
    
- 우리가 파일을 열거나, 데이터를 읽거나, 프로세스를 생성하거나, 네트워크 통신을 할 때마다 **시스템 콜이 백그라운드에서 수행**
##### 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
✅ 시스템 콜 실행 과정 (단계별 설명)

1️. **사용자 프로그램에서 시스템 콜 호출**

사용자는 C 언어로 다음과 같이 `read()` 같은 시스템 콜을 호출합니다.

`read(fd, buffer, 100);`

 2️.**소프트웨어 인터럽트(trap) 발생 → 커널 모드 전환**

라이브러리 함수 내부에서는 시스템 콜 번호를 특정 레지스터에 담고, **특별한 CPU 명령어**를 사용하여 커널로 진입합니다.

- x86 (32-bit): `int 0x80`
    
- x86_64: `syscall` 명령어
    
- ARM: `svc` 명령어
    

➡️ 이 명령은 **트랩(trap)**을 발생시켜 현재 실행을 **커널 모드로 전환**합니다.

---
3. 커널 모드로 전환 및 시스템 콜 처리

인터럽트가 발생하면 CPU는 커널 모드로 전환되고, 운영체제는 인터럽트 벡터 테이블을 참조하여 적절한 시스템 콜 핸들러를 호출합니다. 예를 들어, `sys_write()` 함수가 호출되어 파일에 데이터를 씁니다.
    

➡️ 이 과정에서 **직접 하드웨어나 커널 데이터 구조에 접근 가능**

5. **처리 완료 후 결과값 반환**

- 커널은 작업 결과(읽은 바이트 수, 에러 코드 등)를 특정 레지스터에 저장
    
- 트랩 리턴 명령 (`iret`, `sysret` 등)을 통해 **유저 모드로 복귀**
    

6️⃣ **사용자 프로그램은 결과값 확인 후 다음 작업 진행**

사용자 프로그램은 시스템 콜의 반환값을 사용하여 다음 작업을 수행합니다.
`ssize_t bytesRead = read(fd, buffer, 100); if (bytesRead == -1) perror("read failed");`

---

 ✅ 요약 플로우 (한 줄 정리)

> 사용자 코드 → 라이브러리 함수 → 시스템 콜 번호 설정 → trap → 커널 진입 → 핸들러 실행 → 결과 반환 → 유저 모드 복귀

---

🧠 보안과 안정성을 위한 이유

- 사용자 프로그램이 직접 커널 데이터/하드웨어를 다루지 못하게 막기 위해 반드시 **제어된 인터페이스(= 시스템 콜)**를 통해야 함.
    
- 시스템 콜을 거치면 커널이 **검증/제어/로그**를 수행할 수 있어 **안정성과 보안성 확보**
##### 시스템 콜의 유형에 대해 설명해 주세요.
✅ 1. **프로세스 제어(Process Control)**

프로세스 생성, 종료, 실행 중지, 정보 요청 등 **프로세스의 생명주기 관리**에 필요한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`fork()`|현재 프로세스를 복제 (자식 프로세스 생성)|
|`exec()`|새로운 프로그램을 현재 프로세스 공간에 적재|
|`exit()`|프로세스 종료|
|`wait()`|자식 프로세스 종료까지 대기|
|`getpid()`|현재 프로세스의 PID 반환|

---

✅ 2. **파일 시스템 조작(File Manipulation)**

파일 및 디렉터리의 생성, 읽기/쓰기, 삭제 등을 위한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`open()`|파일 열기|
|`read()`|파일 읽기|
|`write()`|파일 쓰기|
|`close()`|파일 닫기|
|`unlink()`|파일 삭제|
|`lseek()`|파일 포인터 이동|

---

✅ 3. **디바이스 제어(Device Manipulation)**

파일 시스템과 유사하지만, **특수한 입출력 장치**와의 상호작용을 위한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`ioctl()`|디바이스 제어 명령 수행|
|`read()`|디바이스로부터 읽기|
|`write()`|디바이스에 쓰기|

---

✅ 4. **정보 유지(Information Maintenance)**

프로세스, 시간, 시스템 설정 등 운영체제에 관련된 정보를 가져오거나 설정하는 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`getpid()`|현재 프로세스 ID 가져오기|
|`alarm()`|시간 기반 알림 설정|
|`gettimeofday()`|시스템 시각 조회|
|`uname()`|커널/시스템 정보 가져오기|

---
✅ 5. **통신(Communication)**

프로세스 간 통신(IPC)을 위한 시스템 콜입니다. 주로 **소켓 기반 통신**이나 **파이프, 공유 메모리** 등을 다룹니다.

|시스템 콜|설명|
|---|---|
|`pipe()`|익명 파이프 생성 (단방향)|
|`socket()`|네트워크 소켓 생성|
|`connect()`|서버에 연결|
|`send()`, `recv()`|데이터 송수신|
|`shmget()`|공유 메모리 생성|

##### 운영체제의 Dual Mode 에 대해 설명해 주세요.
✅ 운영체제의 Dual Mode란?

**Dual Mode**는 컴퓨터 시스템이 **두 가지 실행 모드**—  
👉 **User Mode(사용자 모드)**와  
👉 **Kernel Mode(커널 모드)**를 갖는 구조를 말합니다.

이는 **보안과 안정성**을 위해 운영체제가 **실행 권한을 구분**하는 중요한 메커니즘입니다.

---
🔍 각 모드의 특징

| 구분    | 사용자 모드 (User Mode)          | 커널 모드 (Kernel Mode)              |
| ----- | --------------------------- | -------------------------------- |
| 실행 주체 | 일반 사용자 프로그램                 | 운영체제 커널                          |
| 접근 권한 | 제한됨 (I/O, 메모리 등 직접 접근 불가)   | 시스템 자원 전체 접근 가능 (하드웨어, 메모리 등)    |
| 위험도   | 낮음 (잘못된 명령은 운영체제가 감지/차단 가능) | 높음 (커널 오류는 시스템 전체 다운으로 이어질 수 있음) |
| 전환 방법 | 시스템 콜, 인터럽트 등을 통해 커널 진입     | 작업 완료 후 사용자 모드로 복귀               |
|       |                             |                                  |

---
##### 왜 유저모드와 커널모드를 구분해야 하나요?
왜 Dual Mode가 필요한가?

1. **보안(Security)**
    
    - 사용자 프로그램이 **디스크, 네트워크, 메모리** 같은 자원을 **마음대로 건드리지 못하게** 막습니다.
        
2. **안정성(Stability)**
    
    - 사용자 코드의 오류나 악의적인 행동이 시스템 전체에 영향을 주지 않도록 격리합니다.
        
3. **운영체제 통제 유지**
    - 운영체제는 시스템 자원의 **공정한 분배, 보호, 관리**를 책임집니다.
	- 이를 위해 사용자 프로그램은 반드시 **운영체제를 통해 자원을 요청**하게 설계되어야 하며, 그 통로가 **시스템 콜**입니다.
        
---
##### 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
✅ 결론부터

> 운영체제는 **각 시스템 콜에 고유한 번호(시스템 콜 번호)**를 부여하고,  
> 유저 모드에서 커널 모드로 전환될 때 **이 번호를 통해 어떤 시스템 콜인지 구분**합니다.

---
 ✅ 시스템 콜 구분 과정 (예: Linux 기준)

 1. **사용자 프로그램이 시스템 콜 호출**
 2. **라이브러리(glibc)가 내부적으로 `syscall` 어셈블리 호출**
 3. **CPU가 커널 모드로 전환하며 시스템 콜 번호 전달**

    
- 커널은 시스템 콜 테이블(system call table)에서 해당 번호에 매핑된 함수를 호출
    

 ✅ 시스템 콜 벡터 테이블 (System Call Vector Table)

 ✅ 요약

|단계|내용|
|---|---|
|1. 사용자 호출|`write()` 같은 함수 호출|
|2. 번호 전달|시스템 콜 번호 → `syscall` 명령어|
|3. 커널 구분|시스템 콜 테이블을 통해 번호에 맞는 함수 실행|
 ✅ 한 줄 요약

> 운영체제는 **시스템 콜 번호를 통해 서로 다른 시스템 콜을 구분**하며,  
> 이 번호는 **시스템 콜 테이블에 매핑되어 적절한 커널 함수가 호출**됩니다.
- 시스템 콜을 구분하는 기준은 **시스템 콜 번호**
- 운영체제는 **시스템 콜 벡터 테이블**을 통해 번호 → 함수 매핑
- 이 구조 덕분에 운영체제가 **안전하게 수많은 시스템 콜을 빠르게 구분**할 수 있음
### 2. 인터럽트가 무엇인지 설명해 주세요.
##### 설명
✅ 인터럽트란?

**인터럽트(Interrupt)**는 **현재 실행 중인 작업을 잠시 멈추고**,  
운영체제가 **긴급하거나 중요한 작업을 먼저 처리할 수 있도록 제어 흐름을 전환하는 메커니즘**입니다.

즉, **CPU의 흐름을 외부/내부 이벤트가 "가로채는" 것**입니다.

✅ 왜 필요한가?

- CPU는 기본적으로 **순차적으로 명령어를 처리**합니다.
    
- 하지만 주변 장치나 프로그램이 언제 어떤 요청을 보낼지 예측할 수 없습니다.
    
- 따라서 CPU가 **일일이 기다리지 않고**, 이벤트가 발생하면 **즉시 응답**할 수 있도록 **인터럽트가 필요**합니다.
    
✅ 인터럽트의 종류

| 유형                 | 설명                                               | 예시                 |
| ------------------ | ------------------------------------------------ | ------------------ |
| **하드웨어(외부) 인터럽트**  | 외부 장치가 CPU에게 이벤트 발생을 알리는 경우                      | 키보드 입력, 디스크 입출력 완료 |
| **소프트웨어(내부) 인터럽트** | 프로그램이 의도적으로 커널 기능을 요청하기 위해 발생시키는 인터럽트 (**Trap**) | 시스템 콜, 예외 처리       |
| **예외(Exception)**  | 프로그램 실행 중 오류가 발생한 경우                             | 0으로 나누기, 페이지 폴트    |

---

##### 인터럽트는 어떻게 처리하나요?
🔁 인터럽트 처리 과정 (6단계 요약)

1️⃣ 인터럽트 발생

- **외부 장치**(예: 키보드, 디스크)가 요청하거나
    
- **CPU 내부에서 예외나 시스템 콜**이 발생하면 인터럽트가 발생합니다.
    
 2️⃣ 현재 작업 상태 저장

- CPU는 현재 실행 중인 프로그램의 **Program Counter(PC), 레지스터** 등의 정보를 **스택에 저장**합니다.
    
- 이는 나중에 **원래 작업으로 복귀하기 위해 필수적인 단계**입니다.
    

3️⃣ 커널 모드로 전환

- 인터럽트가 발생하면 **하드웨어가 자동으로 CPU를 커널 모드로 전환**합니다.
    
- 유저 모드에서는 시스템 자원에 접근할 수 없기 때문에, **인터럽트 처리는 반드시 커널 모드에서 이루어집니다.**
    
 4️⃣ 인터럽트 벡터 테이블 참조

- CPU는 **인터럽트 번호(ID)**를 기반으로  
    **인터럽트 벡터 테이블**에서 해당 **인터럽트 핸들러 함수의 주소**를 조회합니다.
    
5️⃣ 인터럽트 핸들러 실행

- 해당 핸들러 함수가 실행되어, 요청된 작업(I/O 완료 처리, 데이터 수신 등)을 수행합니다.
    
6️⃣ 저장된 상태 복원 후 복귀

- 인터럽트 처리가 끝나면, **스택에 저장해둔 상태를 복원**하고  
    **중단된 작업으로 복귀**하여 프로그램 실행을 이어갑니다.
    

📌 예시: 키보드 인터럽트

1. 사용자가 키보드를 누름
    
2. **키보드 컨트롤러가 인터럽트(IRQ1)**를 발생시킴
    
3. CPU는 해당 인터럽트의 핸들러(0x21)를 호출
    
4. 키보드 입력을 OS 버퍼에 저장
    
5. 사용자 프로그램으로 복귀
    ✅ 정리

|단계|설명|
|---|---|
|1. 인터럽트 발생|외부 장치나 내부 예외 발생|
|2. 상태 저장|현재 CPU 상태 저장 (문맥 보존)|
|3. 모드 전환|유저 모드 → 커널 모드|
|4. 핸들러 조회|인터럽트 벡터 테이블에서 함수 찾기|
|5. 핸들러 실행|이벤트 처리|
|6. 복귀|저장된 상태 복원 후 사용자 프로그램 계속 실행|

---
##### Polling 방식에 대해 설명해 주세요.
Polling 방식이란?

**Polling(폴링)**은 **CPU가 주기적으로 장치 상태를 직접 확인(poll)**하여  
작업이 가능한지를 판단하는 **능동적 감시 방식**입니다.

> 즉, "지금 됐나?", "이제 됐나?" 하고 **계속 물어보는 방식**입니다.

---
 ✅ Polling의 동작 방식

1. CPU는 장치 레지스터나 상태 비트를 **반복적으로 읽음**
    
2. 장치가 작업을 완료하거나 준비되었는지를 확인
    
3. 준비가 되었으면 필요한 작업을 수행 (ex: 데이터 읽기)
    
4. 아니면 일정 시간 대기하거나 다시 확인
    
✅ Polling vs Interrupt

| 항목     | Polling 방식                 | 인터럽트 방식                        |
| ------ | -------------------------- | ------------------------------ |
| 감지 방법  | CPU가 직접 상태를 반복 확인          | 장치가 이벤트 발생 시 CPU에 알림           |
| 자원 효율성 | 비효율적 (CPU가 바쁘게 기다림)        | 효율적 (CPU는 다른 일 하다가 필요할 때만 반응)  |
| 반응 속도  | 빠를 수 있음 (항상 감시 중)          | 약간 지연 가능 (인터럽트 발생 후 처리)        |
| 구현 복잡도 | 간단함                        | 복잡함 (인터럽트 핸들러, 문맥 전환 등 필요)     |
| 용도 예시  | 디스플레이 등 **지속적 감시가 필요한 경우** | 네트워크 수신, 키보드 입력 등 **비정기적 이벤트** |

✅ Polling의 장점과 단점

장점

- 구현이 단순함
    
- 예측 가능한 처리 시점 (실시간성이 필요한 경우 사용 가능)
    
단점

- **CPU 낭비**: 응답이 올 때까지 계속 확인해야 함
    
- **다른 작업을 병행하기 어려움**
    
✅ 언제 Polling을 사용하는가?
- **하드 리얼타임 시스템** (항상 일정 주기로 상태 점검이 필요한 경우)
    
- **간단한 임베디드 시스템** (인터럽트 컨트롤러가 없는 경우)
    
- **I/O가 아주 빠르거나 빈번한 경우**
    

 ✅ 요약

|핵심 정리|
|---|
|Polling은 CPU가 주기적으로 장치 상태를 직접 확인하는 방식|
|구현은 간단하지만, CPU 자원을 비효율적으로 사용함|
|인터럽트 방식과는 자원 활용 방식에서 뚜렷한 차이가 있음|
##### HW / SW 인터럽트에 대해 설명해 주세요.
✅ 1. 하드웨어 인터럽트 (Hardware Interrupt)
 📌 정의

> **CPU 외부의 하드웨어 장치(디바이스)**가 CPU에 **신호를 보내 실행 흐름을 가로채는 것**입니다.

🔧 예시

- **키보드 입력**: 사용자가 키를 누르면 키보드 컨트롤러가 인터럽트를 발생시킴
    
- **디스크 입출력 완료**: 데이터 읽기/쓰기 완료 시 디스크 컨트롤러가 인터럽트 발생
    
- **네트워크 수신**: NIC(네트워크 인터페이스 카드)가 패킷 수신 완료 후 알림
    
 📌 특징

- **비동기적**으로 발생함 (CPU가 예측할 수 없음)    
- 주로 **I/O 처리에 사용**
- CPU는 장치 상태를 polling하지 않고도 효율적으로 응답 가능
    
✅ 2. 소프트웨어 인터럽트 (Software Interrupt)
 📌 정의

> **프로그램(소프트웨어)**이 **명시적으로 인터럽트를 발생시켜** 커널 기능을 요청하는 것  
> 주로 **시스템 콜 호출 시 사용**

 🔧 예시

- 리눅스 32bit: `int 0x80` 명령어로 시스템 콜 진입
    
- 리눅스 64bit: `syscall` 명령어로 시스템 콜 진입
    
- 예외(Exception): 0으로 나누기 → Division by Zero Exception 발생
    
 📌 특징
- **동기적**으로 발생함 (명령어 실행 시 발생)
- 주로 **시스템 콜, 예외 처리**에 사용
- 프로세스가 커널 기능을 요청할 때 쓰임
    
✅ 하드웨어 vs 소프트웨어 인터럽트 비교표

| 항목    | 하드웨어 인터럽트          | 소프트웨어 인터럽트                            |
| ----- | ------------------ | ------------------------------------- |
| 발생 주체 | 외부 장치 (키보드, 디스크 등) | 사용자 프로그램 또는 CPU 내부 명령                 |
| 발생 시점 | 비동기적 (예측 불가능한 시점)  | 동기적 (명령어 실행 시점)                       |
| 사용 목적 | I/O 알림, 장치 이벤트 처리  | 시스템 콜, 예외 처리                          |
| 예시    | 키보드 입력, 네트워크 수신    | `int 0x80`, `syscall`, Divide-by-zero |
| 처리 주체 | 인터럽트 핸들러           | 시스템 콜 핸들러 또는 예외 처리기                   |

✅ 정리

| 구분          | 설명                           |
| ----------- | ---------------------------- |
| **HW 인터럽트** | 외부 장치 → CPU에게 신호 (입출력 처리 등)  |
| **SW 인터럽트** | 프로그램이 명령어로 직접 발생 (시스템 콜, 예외) |
##### 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
✅ 동시에 여러 인터럽트가 발생하면 어떻게 처리할까?

1. **우선순위에 따라 처리**
- 대부분의 CPU와 인터럽트 컨트롤러는 **인터럽트마다 우선순위(Priority)**를 부여합니다.
- **우선순위가 높은 인터럽트부터 먼저 처리**하고,  
    우선순위가 낮은 인터럽트는 **나중에 처리하거나 대기시킵니다.**
    
 📌 예시

| 인터럽트 종류 | 우선순위 (예시) |
| ------- | --------- |
| 타이머     | 가장 높음     |
| 디스크 I/O | 중간        |
| 키보드 입력  | 낮음        |
 2. **중첩 인터럽트(Nested Interrupts)** 처리

- 인터럽트를 처리 중일 때 **더 높은 우선순위의 인터럽트가 발생**하면,  
    **현재 인터럽트를 일시 중단**하고, **새 인터럽트를 먼저 처리**합니다.
    
- 이후 **중단된 인터럽트 처리로 복귀**하여 이어서 실행합니다.
    

📌 이를 위해 CPU는 **인터럽트 중첩을 허용하는 구조(예: 스택 저장, 플래그 비트)**를 갖고 있어야 합니다.

---
 ✅ 인터럽트 마스킹(Interrupt Masking)

운영체제는 때로는 **일부 인터럽트를 임시적으로 무시(차단)**하기도 합니다. 이를 **마스킹(masking)**이라고 합니다.

- 중요한 작업 중일 때, **하위 우선순위 인터럽트가 들어오는 것을 막기 위해 사용**
    
- 예: 커널 크리티컬 섹션 실행 중 인터럽트 일시 마스킹
    
 ✅ 하드웨어 지원: 인터럽트 컨트롤러 (예: PIC, APIC)

- 여러 인터럽트를 관리하는 **전용 하드웨어 장치**
    
- **우선순위 조정**, **마스킹 처리**, **중첩 허용 여부** 등을 하드웨어 수준에서 제어
    
- x86 시스템에서는 **APIC (Advanced Programmable Interrupt Controller)**가 사용됨
    

 ✅ 요약

| 상황                   | 처리 방식                                |
| -------------------- | ------------------------------------ |
| 여러 인터럽트가 동시에 발생      | **우선순위**에 따라 처리                      |
| 낮은 우선순위 인터럽트 먼저 처리 중 | **중첩 인터럽트** 발생 시 높은 우선순위 인터럽트를 먼저 처리 |
| 예외 상황 또는 중요 작업 중     | **인터럽트 마스킹**으로 임시 차단 가능              |

---
🔁 예시 시나리오

1. CPU가 디스크 I/O 인터럽트 처리 중
    
2. 그 순간 타이머 인터럽트 발생 (우선순위 더 높음)
    
3. → 디스크 처리 잠시 중단 → 타이머 인터럽트 처리
    
4. → 이후 디스크 인터럽트 핸들러로 복귀하여 마저 처리
    

### 3. 프로세스가 무엇인가요?
##### 설명
✅ 프로세스란?

> **프로세스**는 **실행 중인 프로그램(Program in Execution)**입니다.

정적인 **프로그램 코드**(예: `a.out`, `chrome.exe`)가 메모리에 올라가 **CPU에 의해 실행되면서**,  
운영체제가 그 프로그램에 대해 **독립적인 실행 환경(메모리, 레지스터, PID 등)을 부여**한 것이 바로 **프로세스**입니다.

##### 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
✅ 1. 프로그램 (Program)
📌 정의

> **프로그램은 실행되지 않은 정적인 코드**입니다.

- 하드디스크에 저장된 실행 파일 (`a.exe`, `vim`, `chrome`) 등이 여기에 해당합니다.
    
- 아직 실행되지 않았기 때문에 **메모리, PID, 자원**을 가지지 않습니다.
    
✅ 2. 프로세스 (Process)
📌 정의

> **프로세스는 실행 중인 프로그램(Program in Execution)**입니다.

- 운영체제가 프로그램을 실행하면 **메모리에 올리고, PID를 부여하며, 독립된 실행 환경**을 만듭니다.
    
- 하나의 프로그램을 여러 번 실행하면 **서로 다른 프로세스**가 생성됩니다.
    
📦 프로세스가 가지는 자원

- 고유한 **메모리 공간** (코드, 데이터, 힙, 스택)
    
- 고유한 **파일 디스크립터 테이블**
    
- 고유한 **프로세스 제어 블록(PCB)**
    

✅ 3. 스레드 (Thread)
 📌 정의

> **스레드는 프로세스 내에서 실행되는 작업의 최소 단위**입니다.  
> 프로세스 안에서 **실제 코드 실행을 담당**하는 주체입니다.

- 한 프로세스는 **하나 이상의 스레드(멀티스레드)**를 가질 수 있습니다.
    
- **모든 스레드는 같은 프로세스의 메모리 공간(코드, 힙, 전역변수 등)을 공유**합니다.
    
- 하지만 **스택, 레지스터 등은 개별적으로 유지**합니다.
##### PCB가 무엇인가요?
✅ PCB란?

> **PCB(Process Control Block)**는 운영체제가 **하나의 프로세스에 대한 모든 상태 정보를 저장하는 구조체**입니다.  
> 쉽게 말하면, **"프로세스의 주민등록증 + 실행 이력 + 자원 목록"을 담은 표**입니다.

운영체제는 수많은 프로세스를 동시에 다루기 때문에, **각 프로세스를 식별하고 관리**할 필요가 있습니다. 이때 사용하는 게 바로 PCB입니다.

 ✅ PCB에 저장되는 정보

| 분류          | 정보                         | 설명                             |
| ----------- | -------------------------- | ------------------------------ |
| 📌 식별 정보    | **PID**                    | 프로세스 고유 번호                     |
| 📌 상태 정보    | **프로세스 상태**                | Running, Ready, Waiting 등      |
| 📌 문맥 정보    | **레지스터 값**, **PC**, **SP** | CPU 문맥 저장 (context switching용) |
| 📌 스케줄링 정보  | **우선순위**, **CPU 점유 시간**    | 스케줄러 참고 정보                     |
| 📌 메모리 정보   | **코드/데이터/스택/힙의 위치 정보**     | 프로세스의 주소 공간 관리                 |
| 📌 파일 정보    | **파일 디스크립터 테이블 포인터**       | 열린 파일 목록 관리                    |
| 📌 입출력 정보   | **I/O 장치 상태**              | 사용 중인 장치에 대한 정보                |
| 📌 부모/자식 정보 | **PPID, Child List**       | 프로세스 계층 관리 (ps 트리 구조 등)        |

 ✅ PCB는 어디에 저장되나요?
- **운영체제 커널 공간**에 저장됩니다.
- 프로세스마다 **1개씩 존재**합니다.
- 리눅스에서는 `task_struct` 구조체가 PCB 역할을 합니다.
    
✅ 왜 중요한가?

| 이유        | 설명                                                   |
| --------- | ---------------------------------------------------- |
| **문맥 전환** | PCB에 저장된 CPU 상태 정보로, 실행 중인 프로세스를 중단하고 다른 프로세스로 전환 가능 |
| **스케줄링**  | 스케줄러는 PCB 정보를 기반으로 어떤 프로세스를 실행할지 판단                  |
| **자원 회수** | 프로세스 종료 시 PCB를 참조하여 모든 자원 정리 가능                      |

✅ 예시 흐름: 문맥 전환 시 PCB 역할

1. 현재 프로세스 A 실행 중
    
2. 인터럽트 발생 → 커널 진입
    
3. **A의 현재 상태(레지스터 등)를 PCB A에 저장**
    
4. **PCB B에서 상태를 복원 → 프로세스 B 실행**
    
5. 운영체제는 이렇게 PCB를 통해 여러 프로세스를 스위칭하며 실행
    
✅ 요약

| 항목    | 내용                          |
| ----- | --------------------------- |
| 정의    | 프로세스 상태 정보를 담은 운영체제의 자료구조   |
| 저장 위치 | 커널 공간 (각 프로세스마다 1개)         |
| 주요 내용 | PID, 상태, 레지스터, 메모리, FD 등    |
| 핵심 역할 | 프로세스 추적, 문맥 전환, 자원 관리, 스케줄링 |
|       |                             |
##### 그렇다면, 스레드는 PCB를 갖고 있을까요?
> ✅ **스레드는 독립된 PCB를 갖지 않습니다.**  
> 대신, **스레드는 “프로세스의 PCB를 공유”하면서, 자신만의 실행 컨텍스트(스택, 레지스터 등)를 따로 가집니다.**

---
 ✅ 정리해서 답변하자면
 🧵 **스레드(Thread)**:
- 하나의 **프로세스 내부에서 실행되는 흐름 단위**
- **메모리 공간, 열린 파일, 코드 영역 등을 프로세스와 공유**
- 하지만 **자신만의 스택, 레지스터 상태, 스레드 ID(TID)** 등은 따로 가짐
    
 📄 **PCB(Process Control Block)**:
- **프로세스 전체에 대한 정보를 담은 운영체제 구조체**
- 메모리 공간, 파일 디스크립터 테이블, 우선순위 등 **프로세스 공통 정보**를 포함
    

 ✅ 그럼 스레드는 뭘 갖고 있나요?

스레드는 PCB 대신 **스레드 제어 블록(TCB, Thread Control Block)**이라는 **간단한 구조체**를 가집니다.

| 항목       | TCB (스레드 제어 블록)           |
| -------- | ------------------------- |
| TID      | 고유한 스레드 ID                |
| 스택 포인터   | 스레드별 스택 저장                |
| 프로그램 카운터 | 현재 실행 중인 명령어 위치           |
| 레지스터 상태  | 레지스터 값 저장                 |
| 스레드 상태   | Running, Ready, Blocked 등 |
| 우선순위     | 스케줄링 참고 정보 등              |

➡ 운영체제는 이 **TCB를 이용해 스레드를 문맥 전환(context switching)**합니다.

✅ 프로세스와 스레드 관계 정리

|항목|프로세스|스레드|
|---|---|---|
|제어 블록|PCB|TCB|
|주소 공간|각자 독립|프로세스와 공유|
|스택|각자 가짐|각자 가짐|
|코드/데이터|독립적|공유|
|파일 디스크립터|독립적|공유|
##### 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
✅ 리눅스에서 **프로세스 생성** 방식

 📌 사용 시스템 콜: `fork()` → `exec()`

1. `fork()`:    
    - 부모 프로세스를 **복사**하여 **자식 프로세스를 생성**
    - PCB(task_struct), 메모리 공간, 파일 디스크립터 테이블 등이 **복사됨 (copy-on-write)**
        
2. `exec()`:
    - 자식 프로세스가 **새로운 프로그램으로 자기 자신을 덮어쓰기**
    - 실행 파일을 적재하여 독립적인 새 프로그램으로 바뀜
        

✅ 리눅스에서 **스레드 생성** 방식
 📌 사용 시스템 콜: `clone()`, 혹은 `pthread_create()`

- 리눅스에서 스레드는 `clone()` 시스템 콜을 통해 생성되며,    
- `clone()`은 **어떤 자원을 부모와 공유할지 플래그로 지정**합니다.
    
 주요 플래그

|플래그|의미|
|---|---|
|`CLONE_VM`|부모와 **주소 공간(메모리)** 공유|
|`CLONE_FILES`|**파일 디스크립터 테이블** 공유|
|`CLONE_FS`|현재 작업 디렉토리 공유|
|`CLONE_THREAD`|**같은 스레드 그룹으로 생성** (TID 공유)|

이런 플래그를 조합하면 → **하나의 프로세스 안에서 새로운 스레드 생성**

 ✅ 정리: 리눅스에서 프로세스 vs 스레드 생성 비교

| 구분       | 프로세스                | 스레드                             |
| -------- | ------------------- | ------------------------------- |
| 시스템 콜    | `fork()` + `exec()` | `clone()` 또는 `pthread_create()` |
| 메모리 공간   | 별도 (복사됨)            | 공유 (CLONE_VM)                   |
| 파일 디스크립터 | 복사(copy-on-write)   | 공유 (CLONE_FILES)                |
| PID      | 독립적인 PID            | **TID는 다르지만, 같은 PID (스레드 그룹)**  |
| 자원 격리    | 강함                  | 약함 (공유된 상태)                     |

 ✅ 리눅스 내부적으로는?

- 리눅스는 **프로세스와 스레드를 구분하지 않고**, 모두 `task_struct`로 표현합니다.
    
- 단지 **어떤 자원을 공유하느냐**에 따라 **“프로세스처럼” 혹은 “스레드처럼” 동작**할 뿐입니다.
    
 🔔 핵심 요약

| 질문                      | 대답                                                 |
| ----------------------- | -------------------------------------------------- |
| 리눅스에서 프로세스는 어떻게 만들어지나요? | `fork()`로 복제 후, `exec()`로 새로운 프로그램 실행              |
| 리눅스에서 스레드는 어떻게 만들어지나요?  | `clone()` 또는 `pthread_create()`로, 자원을 공유하는 task 생성 |
| 내부적으로 둘은 어떻게 다른가요?      | 둘 다 `task_struct`로 표현되며, 공유 자원의 범위에 따라 역할이 다름      |
##### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
✅ 1. 자식 프로세스가 상태를 알리지 않고 죽을 경우
 📌 개념: 좀비 프로세스(Zombie Process)

> 자식 프로세스가 `exit()`으로 종료되었지만,  
> 부모가 아직 `wait()`으로 **종료 상태를 수거하지 않은 상태**면 → **좀비 프로세스가 됩니다.**

 🧠 이유

- 운영체제는 자식 프로세스가 종료되면, 그 **종료 코드와 PID를 부모가 확인할 수 있도록 PCB 일부를 남겨둡니다.**
    
- 부모가 `wait()` 또는 `waitpid()`를 호출하면 이 정보를 받아가고, 그 후 **운영체제가 자식의 PCB를 정리**합니다.
    
🔁 해결 방법

- 부모는 반드시 자식이 종료되면 `wait()` 호출로 **종료 상태를 수거(collect)**해야 함
    
- 부모가 수거하지 않으면 **좀비 프로세스가 쌓여서 PID 테이블 고갈 가능**
    
 ✅ 2. 부모 프로세스가 먼저 죽는 경우
 📌 개념: 고아 프로세스(Orphan Process)

> 부모 프로세스가 먼저 종료되면, **자식 프로세스는 “고아” 상태**가 됩니다.

 🔧 리눅스 처리 방식

- **고아가 된 자식 프로세스는 자동으로 `init`(PID 1) 또는 `systemd`가 부모가 됩니다.**
    
- 이 과정을 **re-parenting**이라고 합니다.
    


➡️ 이렇게 해서 고아 프로세스도 종료 시 **정상적으로 정리될 수 있도록 운영체제가 보장**합니다.

✅ 요약표

| 상황                       | 처리 방식                               |
| ------------------------ | ----------------------------------- |
| 자식이 먼저 죽고 부모가 wait() 안 함 | 좀비 프로세스 발생 → 부모가 wait()해야 정리        |
| 부모가 먼저 죽음                | 자식은 고아 프로세스가 되고, init(1)이 부모 역할을 맡음 |
| 부모와 자식이 거의 동시에 종료        | 커널이 자동으로 좀비/고아 정리 처리 (init에게 넘김)    |

---
✅ 관련 시스템 콜

|함수|설명|
|---|---|
|`exit()`|프로세스 종료 (상태코드 남김)|
|`wait()`|자식의 종료 상태 수거|
|`waitpid()`|특정 자식만 기다리기 가능|
|`kill(pid, sig)`|프로세스 강제 종료|

---

🔔 정리 한 줄 요약

> **자식이 먼저 종료되면 → 부모가 반드시 `wait()`로 수거해야 하고,  
> 부모가 먼저 죽으면 → 자식은 `init(1)`에게 위탁되어 정리됩니다.**

운영체제는 이 과정을 통해 **프로세스 테이블과 PID를 누수 없이 관리**합니다.
##### 리눅스에서, 데몬프로세스에 대해 설명해 주세요.
✅ 데몬 프로세스란?

> **데몬 프로세스**는 **백그라운드에서 독립적으로 동작하는 프로세스**로,  
> 보통 **시스템 서비스를 제공하거나, 이벤트를 지속적으로 감시**합니다.

- 일반적으로 **터미널(표준 입출력)과 분리되어 실행**
    
- **사용자의 로그인/로그아웃과 관계없이 계속 동작**
    
- 시스템 부팅 시 자동으로 시작되거나, 수동으로 시작되기도 함
    
 ✅ 데몬 프로세스의 주요 특징

| 특징            | 설명                                        |
| ------------- | ----------------------------------------- |
| **백그라운드 실행**  | 터미널과 분리되어 사용자와 직접 상호작용하지 않음               |
| **표준 입출력 없음** | stdin, stdout, stderr를 `/dev/null`로 리다이렉트 |
| **고아 프로세스화**  | 부모가 종료된 후 `init` 또는 `systemd`에게 위탁됨       |
| **무한 루프 구조**  | 보통 이벤트 감시/반복 수행을 위해 while 루프를 가짐          |
| **서비스 역할**    | 로그 기록, 네트워크 요청 수신, 스케줄링 등 시스템 서비스 수행      |

✅ 데몬 프로세스의 예시

|데몬 이름|역할|
|---|---|
|`sshd`|SSH 원격 접속 서비스|
|`crond`|주기적인 작업 스케줄링 (cron job 실행)|
|`httpd`, `nginx`|웹 서버 데몬|
|`systemd`|시스템 서비스 관리자 (init 역할 포함)|
|`journald`|시스템 로그 관리|

✅ 데몬 프로세스 만드는 방법 (일반 구조)

``` c
void daemonize() {     
	pid_t pid = fork();     
	if (pid > 0) exit(0); // 부모 종료 → 고아화   
	setsid();             // 세션 리더 분리 → 터미널과 분리     
	chdir("/");           // 작업 디렉터리 변경     
	umask(0);             // 파일 권한 마스크 해제     
	close(0); close(1); close(2); // stdin, stdout, stderr 닫기
}
```
주요 단계 설명
1. `fork()` 후 부모 종료 → 자식이 고아가 되어 init에게 위탁됨
2. `setsid()`로 세션 리더가 되어 터미널로부터 완전히 분리
3. 현재 디렉터리를 `/`로 변경하여 디렉터리 잠금 방지
4. 파일 모드 마스크 제거 (`umask(0)`)로 예측 가능한 파일 권한 설정
5. 표준 입력/출력을 `/dev/null`로 리다이렉트하거나 닫음

---
✅ 데몬은 왜 필요한가?
- **서비스 제공**: 시스템 수준에서 항상 응답할 준비를 하고 있어야 하는 경우
- **비동기 감시**: 이벤트(네트워크, 파일 변화 등)를 지속적으로 모니터링해야 할 때
- **자동화 작업**: 백업, 로그 수집, 보안 감시 등 반복 작업 실행
    
 ✅ 정리

| 항목    | 설명                                     |
| ----- | -------------------------------------- |
| 정의    | 백그라운드에서 독립적으로 실행되는 시스템 서비스 프로세스        |
| 주요 특징 | 터미널 없음, init/systemd에 위탁, 지속 실행        |
| 대표 예시 | sshd, crond, nginx, systemd            |
| 생성 방식 | fork → setsid → chdir → umask → I/O 분리 |
##### 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
✅ 리눅스 프로세스 트리의 루트: `init` 또는 `systemd` 프로세스

 📌 기본 정보

| 항목    | 설명                                                     |
| ----- | ------------------------------------------------------ |
| 이름    | `init` (전통적) / `systemd` (현대 리눅스)                      |
| PID   | 항상 **1번(PID 1)**                                       |
| 역할    | **시스템에서 최초로 실행되는 사용자 공간 프로세스**                         |
| 실행 시점 | **커널 부팅 직후**, 사용자 공간 진입 시                              |
| 실행 위치 | `/sbin/init`, `/lib/systemd/systemd`, `/bin/systemd` 등 |
 ✅ 어떤 역할을 하나요?

 🔧 시스템 전체 프로세스 트리의 "루트 노드"
- 커널이 부팅을 마치고 사용자 공간으로 넘어갈 때 **가장 먼저 실행되는 프로세스**
- 이후 모든 **서비스, 데몬, 셸, 사용자 프로세스**는 **직접 또는 간접적으로 init/systemd의 자식 또는 후손**
    
 🧼 고아 프로세스 수거

- 부모가 먼저 죽은 **고아 프로세스**는 자동으로 `PID 1`의 자식으로 재귀속(re-parenting)
- 해당 프로세스가 죽을 때 **`init`이 대신 `wait()` 호출로 좀비 정리**
    
 🛠 시스템 서비스 초기화 및 관리
- 전통적 `init`: `/etc/inittab` 기반 단계적 실행
- 현대 `systemd`: `.service`, `.target` 단위로 병렬 처리 및 의존성 관리
    

---
 ✅ 트리 구조 예시 (`pstree` 명령어)

bash

복사편집

`systemd─┬─sshd───bash───vim         ├─cron         ├─NetworkManager         └─nginx───nginx`

➡ 위 트리에서 `systemd`가 루트이며, 모든 프로세스는 직간접적으로 그 하위에 존재

---

 ✅ PID 1이 가지는 특별한 속성

| 기능            | 설명                                           |
| ------------- | -------------------------------------------- |
| 좀비 수거         | 고아 자식의 상태를 수거하여 자원 해제                        |
| signal 무시/필터링 | SIGKILL을 포함한 대부분의 신호 무시 가능                   |
| 재부팅/셧다운 트리거   | 시스템 종료는 PID 1을 통해 수행됨 (`reboot`, `shutdown`) |

---

✅ 정리

|항목|내용|
|---|---|
|루트 프로세스|`init` 또는 `systemd`|
|PID|항상 1번|
|주요 역할|사용자 공간 최초 실행, 프로세스 트리의 뿌리, 서비스 초기화 및 고아 프로세스 정리|
|실행 시점|커널 부팅 직후 사용자 공간 진입 시|
|사용자 정의 가능 여부|일부 리눅스에서는 대체 가능 (`runit`, `upstart`, 등)|

---

### 4. 프로세스 주소공간에 대해 설명해 주세요.
##### 설명
✅ 프로세스 주소 공간이란?

> 운영체제가 **각 프로세스에게 독립적인 가상 메모리 공간을 할당**한 것.  
> 각 프로세스는 자신만의 **4GB(32bit) 또는 128TB(64bit)** 주소 공간을 가지며,  
> 다른 프로세스와 **메모리를 공유하지 않습니다** (보안, 안정성 보장).

 ✅ 프로세스 주소 공간의 주요 영역 (일반적인 구성 순서)


```text
(상위 주소) 
+--------------------+ 
| 커널 영역 (유저 접근 불가) | 
+--------------------+  ← 커널 전용 (공유 영역) 
| Stack              | 
| ↓                  | 
| 함수 호출/지역 변수 |
+--------------------+ 
| Heap               | 
| ↑ malloc/new       | 
+--------------------+ 
| BSS                | 
| 초기화되지 않은 전역/static 변수 |
+--------------------+
| Data               | 
| 초기화된 전역/static 변수 |
+--------------------+ 
| Text (Code)        |
| 프로그램 명령어/코드 |
+--------------------+ 
(하위 주소)
```
🔍 각 영역 설명

| 영역             | 설명                                                     |
| -------------- | ------------------------------------------------------ |
| **Text**(Code) | 프로그램의 실행 코드 (명령어) 저장, 보통 읽기 전용                         |
| **Data**       | 초기화된 전역변수 및 static 변수                                  |
| **BSS**        | 초기화되지 않은 전역/static 변수 (메모리는 0으로 초기화됨)                  |
| **Heap**       | 동적 메모리(`malloc`, `new`)가 할당되는 공간. 런타임 중 확장됨            |
| **Stack**      | 함수 호출 시 사용되는 공간 (지역 변수, 리턴 주소 등). 호출마다 쌓이고 호출 종료 시 사라짐 |
✅ 왜 이렇게 나눌까?

- **보안**: 코드 영역은 읽기 전용으로 두어 악성 코드 삽입을 막음
- **유연성**: 힙과 스택은 동적으로 커질 수 있도록 **반대 방향**으로 확장
- **관리 용이**: 운영체제는 영역별로 접근 권한, 크기 제한 등을 설정 가능
    
✅ 커널과 유저 영역 분리
- 유저 프로세스는 **자기 주소 공간의 윗부분(높은 주소)**에 있는 **커널 영역에 접근 불가**
- 커널 모드일 때만 접근 가능 → 시스템 콜을 통해 간접적으로만 커널 기능 사용 가능
    
---
 ✅ 요약

| 구분    | 설명                                   |
| ----- | ------------------------------------ |
| 정의    | 프로세스가 실행될 때 운영체제가 제공하는 독립된 가상 메모리 공간 |
| 주요 구성 | Text, Data, BSS, Heap, Stack, 커널 영역  |
| 목적    | 보안 격리, 자원 보호, 프로세스 간 독립성 유지          |
| 관리 방법 | `MMU`, 페이지 테이블, `/proc/<pid>/maps` 등 |

##### 초기화 하지 않은 변수들은 어디에 저장될까요?
✅ 초기화하지 않은 변수들은 어디에 저장될까?

> **초기화하지 않은 전역 변수와 static 변수는 `BSS (Block Started by Symbol)` 영역에 저장됩니다.**

 📌 BSS 영역이란?
- **초기값이 없는 전역/정적 변수**들이 저장되는 프로세스 주소 공간의 **정적 메모리 영역**
- 프로그램이 시작될 때 **운영체제가 자동으로 0으로 초기화**해 줍니다.
- 즉, 코드에선 초기화하지 않았지만 **실제로는 0값을 갖고 시작합니다.**
    
 ## ✅ 왜 BSS를 따로 두는가? (정확한 이유)
1️⃣ 실행 파일 크기 감소 (디스크 공간 절약)

- `Data` 영역은 **초기값을 포함하므로, 실행 파일 내에 실제 바이너리 데이터로 저장**됩니다.  
    예: `int x = 100;` → 실행 파일 안에 0x64 저장됨
    
- 반면 `BSS`는 **초기값이 없고 0으로만 초기화되므로**,  
    **실행 파일 안에 데이터가 포함되지 않음**  
    → 단순히 “이 변수 크기만큼 공간이 필요해요”라고 **기록만 함**
    

`$ size a.out    text	   data	    bss	    dec	    hex	filename    1024	   100	    400	    1524	  5f4	a.out`

➡ `bss`는 **RAM에서만 400바이트 잡히고, 실행 파일 용량에는 포함되지 않음**

---
2️⃣ 로딩 속도 및 메모리 사용 최적화

- `Data`는 파일에서 읽어야 하므로 **디스크 I/O가 발생**
    
- `BSS`는 **메모리에서 바로 0으로만 초기화**되므로 **로딩 시 빠름**
    
- 운영체제는 `BSS` 영역을 **익명 페이지로 할당하고 memset(0) 처리**만 하면 됨
    

---
3️⃣ 메모리 보호 및 구분성 확보

- BSS와 Data를 구분함으로써:
    
    - **읽기 전용 섹션 (코드)**,
        
    - **읽기/쓰기 가능 영역 (data/bss)**,
        
    - **동적 힙, 스택 영역** 등을 **명확하게 분리 가능**
        
- 이는 **링커, 로더, 디버거, 보안 도구들이 영역별 권한을 다르게 설정**할 수 있게 해줌
        

✅ 메모리 영역별 정리

| 변수 종류                 | 저장 영역   |
| --------------------- | ------- |
| 초기화된 전역/static 변수     | Data 영역 |
| 초기화되지 않은 전역/static 변수 | BSS 영역  |
| 지역 변수 (함수 안)          | Stack   |
| 동적 할당 변수 (`malloc`)   | Heap    |

 🔔 요약

> **초기화하지 않은 전역변수와 static 변수는 BSS 영역에 저장되며,  
> 실행 시점에 운영체제가 자동으로 0으로 초기화해 줍니다.**

초기화하지 않은 지역 변수는 어디에 저장될까?

> ✅ **초기화하지 않은 지역 변수는 `Stack` 영역에 저장됩니다.**

- 함수 내에서 선언된 변수는 무조건 **Stack에 위치**
    
- 초기화하지 않으면, 해당 변수의 메모리는 **초기값 없이 할당**되며,  
    → **쓰레기 값(Garbage Value)**가 들어 있습니다.
##### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
✅ 결론 먼저

> ❌ Stack과 Heap은 **처음부터 크게 할당되지 않습니다.**  
> ✅ 대신, **필요에 따라 점진적으로 커지며**,  
> 운영체제는 **미리 정해진 최대 크기 제한**도 둡니다.

✅ Heap의 크기: 동적, `brk()`와 `mmap()`에 의해 증가

🔹 생성 방식

- `malloc()`, `new` 등이 호출되면 내부적으로 **`brk()` 또는 `mmap()`** 시스템 콜을 통해 힙을 확장합니다.
    
- 힙은 **아래에서 위 방향으로 증가**합니다.
    
🔹 최대 크기 제한

- 힙의 최대 크기는 다음으로 제한됩니다:
    - **시스템 가상 메모리 한도**
    - **프로세스 별 리소스 제한 (`ulimit`)**
    - **사용 가능한 물리/스왑 메모리**
        
✅ Stack의 크기: 작게 시작, 제한 있음
 🔹 생성 방식
- 스택은 **함수 호출 시 자동으로 할당되는 지역 변수와 리턴 주소 등**을 담습니다.
- **위에서 아래 방향으로 내려오며 확장**합니다.
- 운영체제는 **스택 오버플로우 방지를 위해 고정된 최대 크기를 설정**합니다.
    
🔹 기본 제한 예시 (리눅스 기준)
- 보통 8MB (스레드마다 다름)
    

➡ 너무 많은 재귀나 대형 배열은 스택 오버플로우를 유발

--- ✅ Stack과 Heap의 실제 동작 그림 (개념도)

```text
`높은 주소  
+------------------+  ← Stack 시작 (높은 주소)   
|   함수 호출      | ← 점점 내려감   
|   지역 변수      |  
+------------------+      
...  
|                  | ← 아직 쓰이지 않은 공간 (Stack ↕ Heap 사이 gap)       ... 
+------------------+  
|   동적 메모리     | ← Heap (malloc 등)   
|   구조체/배열     |  
+------------------+  ← Heap 시작 (낮은 주소)  
낮은 주소`
```

- 이 사이 영역은 **가상 주소 공간만 존재**하고 실제 물리 메모리는 할당되지 않을 수 있음
- Heap과 Stack이 서로를 향해 자라기 때문에, 너무 커지면 **충돌(segfault)** 가능
     ✅ 요약

| 항목  | Heap                    | Stack                         |
| --- | ----------------------- | ----------------------------- |
| 방향  | 아래 → 위                  | 위 → 아래                        |
| 크기  | 동적으로 증가 (`brk`, `mmap`) | 고정된 최대치 있음 (`ulimit -s`)      |
| 초깃값 | 작음 (필요 시 확장)            | 작음 (보통 수 MB 수준)               |
| 제한  | 가상 메모리/ulimit에 의해 제한됨   | 기본 8MB (스레드마다 다름)             |
| 위험  | 과도한 malloc → OOM        | 과도한 재귀/대형 배열 → Stack overflow |

🔔 핵심 한 줄 요약

> Stack과 Heap은 주소 공간 그림에선 넓게 보이지만,  
> 실제로는 **작게 시작해서 필요할 때 동적으로 늘어나며**,  
> **운영체제가 명확한 최대 크기를 제한하고 관리**합니다.
##### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
✅ 결론 먼저

> **Stack이 Heap보다 일반적으로 더 빠릅니다.**

---
✅ 왜 Stack이 더 빠른가?

1️⃣ **메모리 할당/해제 방식의 차이**

| 항목    | Stack                                 | Heap                             |
| ----- | ------------------------------------- | -------------------------------- |
| 할당 방식 | **컴파일 타임 or 함수 호출 시** 자동 할당           | 런타임 시 `malloc`, `free` 등으로 동적 할당 |
| 해제 방식 | 함수 종료 시 자동 해제                         | 명시적으로 `free()` 해야 함              |
| 구조    | 선입후출(Last-In-First-Out, LIFO) → 매우 단순 | 자유로운 크기/위치로 할당 → 관리 복잡           |

- 스택은 단순한 포인터 연산만으로 **몇 사이클 이내에 메모리 할당/해제**가 가능합니다.
- 반면 힙은 메모리 풀에서 **적절한 블록을 찾고, 병합, 분할, 프래그멘테이션 관리** 등 오버헤드가 큽니다.
    
2️⃣ **캐시 적중률(Locality)의 차이**

- 스택은 지역 변수 위주로 사용되며, **주소가 연속적**이라 **CPU 캐시(Locality of Reference)**에 잘 맞습니다.
    
- 힙은 할당 위치가 **분산되고 불규칙**하여 캐시 효율이 떨어질 수 있습니다.
    

 3️⃣ **함수 호출 최적화의 효과**

- 스택은 컴파일러 최적화 대상입니다 (e.g., 레지스터 할당, 스택 프레임 미사용 등)
    
- 반면, 힙 접근은 컴파일러가 더 조심스럽게 접근하며 일반적으로 비용이 큽니다.
    
📌 접근 자체는 같지만 **“주소 계산 및 접근 방식”**에서 오버헤드 차이가 납니다:

|항목|Stack|Heap|
|---|---|---|
|주소 계산 방식|컴파일 타임에 결정됨 (`rbp - 4` 등)|런타임에 포인터 간접 참조 (`ptr + offset`)|
|간접 접근|❌ 없음|✅ 객체 참조 필요 (`ref.field`)|


 ✅ 요약

|비교 항목|Stack|Heap|
|---|---|---|
|접근 속도|✅ 빠름|❌ 상대적으로 느림|
|할당/해제 비용|매우 낮음|상대적으로 높음|
|캐시 적중률|높음 (연속성 좋음)|낮음 (주소 불규칙)|
|사용 용도|지역 변수, 빠른 처리|동적 크기, 수명 긴 객체|

---

🔔 핵심 한 줄 요약

> **Stack은 구조가 단순하고 연속적이기 때문에 Heap보다 빠른 접근 속도를 보입니다.**  
> 하지만 용도와 상황에 따라 **Heap도 필수적인 메모리 영역**입니다.

필요하시면 실제 캐시 히트율, glibc `malloc` 알고리즘(`ptmalloc`), 스택 프레임 구조 등도 설명드릴 수 있습니다.
##### 다음과 같이 공간을 분할하는 이유가 있을까요?
운영체제가 **프로세스 주소 공간을 Text / Data / BSS / Heap / Stack 등으로 명확히 분할하는 이유는**, 단순한 구조적 나눔이 아니라 **성능, 보안, 안정성, 효율성**을 모두 고려한 **합리적 설계 결정**입니다.
 ✅ 1. **보안 (Security)**

🔐 서로 다른 권한 적용

- **Text 영역**: 읽기만 가능 (`r--`) → 코드 변조 방지    
- **Data / BSS / Heap / Stack**: 읽기-쓰기 가능 (`rw-`)
- **Stack 실행 금지 (NX/XD 비트)**: 버퍼 오버플로우로부터 보호
    
 예시:

- 스택에 코드 삽입 후 실행 시도 → `Segmentation Fault` 발생  
    (스택은 실행 권한 없음)
    
✅ 2. **안정성 (Stability)**

🔄 서로 독립적으로 확장 가능

- **Heap**은 아래 방향으로, **Stack**은 위 방향으로 확장  
    → 충돌 위험을 막기 위해 **중간에 여유 공간(gap)** 설정
    
 📉 예외 상황 관리

- **Stack Overflow**, **Heap Overflow** 시 별도 에러 처리 가능  
    → 메모리 구조가 구분되어 있어 **오류 위치 파악이 쉬움**
    
 ✅ 3. **성능 최적화 (Performance)**
 💡 캐시 지역성(Locality)

- Stack은 연속된 함수 호출 → 지역성 좋음 → 캐시 효율 높음
    
- Heap은 동적이지만, 영역 분리 덕분에 캐시 성능 최적화 가능
    
🧠 MMU/페이지 테이블 관리 최적화
- 서로 다른 영역에 **다른 페이지 속성** 적용 가능 (예: 공유 여부, 권한)
    

✅ 4. **유지보수/디버깅 편의성**

- 디버깅 시 `BSS`, `Heap`, `Stack` 등 메모리 영역이 구분되어 있으면  
    **오류 추적, 변수 추적, 영역별 할당 문제 확인이 쉬움**
    
 ✅ 5. **시스템 호출/링커/로더 지원을 위한 표준화**

- `ELF`(Executable and Linkable Format) 파일 포맷에서는  
    `.text`, `.data`, `.bss`, `.rodata` 등 섹션이 표준화되어 있음
    
- 커널은 이를 기반으로 **정확한 메모리 맵을 생성하고, 페이지 테이블을 설정**함
    

✅ 한눈에 보는 영역별 목적

|영역|목적|
|---|---|
|**Text**|코드 저장, 읽기 전용, 보안 강화|
|**Data**|초기화된 전역/static 변수 저장|
|**BSS**|0으로 초기화될 전역/static 변수 (공간만 필요)|
|**Heap**|런타임 동적 메모리 할당 (유연성 중심)|
|**Stack**|함수 호출, 지역 변수 저장 (속도 중심)|

🔔 핵심 요약

> **프로세스 주소 공간을 나누는 이유는 단순한 관습이 아니라**,  
> **보안, 성능, 에러 처리, 디버깅, 시스템 효율까지 고려한 운영체제의 설계 최적화 결과**입니다.
##### 스레드의 주소공간은 어떻게 구성되어 있을까요?
✅ 핵심 결론

> **스레드는 같은 프로세스 내에서 실행되므로, 주소 공간을 프로세스와 공유합니다.**  
> 다만, **스레드마다 고유한 Stack이 존재하며**, 나머지 메모리 영역은 전부 공유됩니다.

✅ 스레드의 주소 공간 구성 요약

|메모리 영역|스레드 간 공유 여부|설명|
|---|---|---|
|**Text (Code)**|✅ 공유|실행 코드|
|**Data**|✅ 공유|초기화된 전역/static 변수|
|**BSS**|✅ 공유|초기화되지 않은 전역/static 변수|
|**Heap**|✅ 공유|`new`, `malloc` 등 동적 할당 메모리|
|**Stack**|❌ **비공유**|**스레드마다 고유** (지역 변수 등 저장)|
|**Thread-Local Storage (TLS)**|❌ 비공유|`__thread` 또는 `ThreadLocal<T>`와 같은 스레드 전용 데이터|

✅ 그림으로 이해하는 구조
```
공유된 프로세스 주소 공간
──────────────────────────── 
|       Text (Code)        | ← 모든 스레드 공유
|       Data / BSS         | ← 전역 변수 공유 
|       Heap               | ← new, malloc 등 공유 ────────────────────────────
|       Stack (Thread 1)   | ← 고유
──────────────────────────── 
|       Stack (Thread 2)   | ← 고유
──────────────────────────── 
|       Stack (Thread N)   | ← 고유
────────────────────────────

```


- 각 스레드는 **자신만의 스택**을 갖고, 함수 호출/지역 변수 등을 그 위에 올림
- 그 외 메모리 공간은 **전부 공유**됨 → 자원 공유, 동기화 문제 발생 가능
    
✅ 그럼 스택은 어디에 생기나요?

- 스레드 생성 시 커널이 별도 **스택 메모리 영역**을 할당
    
- 보통 `pthread_create()`나 Java `Thread` 생성 시 내부적으로 호출
    
- Linux에서는 스레드 스택 크기 기본값은 `ulimit -s`로 확인 가능 (보통 8MB)
##### "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.
✅ 결론부터 말씀드리면:

> **네, 스택 영역은 자료구조의 스택(LIFO)과 매우 밀접하게 관련이 있고**,  
> **힙 영역은 자료구조의 힙(priority queue 구조)와는 직접적인 관련은 없습니다.**  
> 단지 **"자유롭게 메모리를 할당하는 공간"**이라는 의미에서 **Heap이라는 이름이 붙은 것**입니다.

---
 ✅ 1. 스택(Stack) 영역 ≒ 자료구조 스택(LIFO)

|관점|설명|
|---|---|
|이름 유래|자료구조의 **스택 (Last-In-First-Out)** 구조에서 유래|
|저장 내용|**함수 호출 시의 지역 변수, 리턴 주소, 매개변수 등**|
|할당/해제 방식|**컴파일러/CPU가 자동으로 스택 프레임을 push/pop**함|
|동작 구조|함수 호출 시 스택 프레임 push → 리턴 시 pop → **완벽한 LIFO**|

➡ 이 구조는 자료구조 스택과 거의 동일한 **LIFO 방식**으로 메모리를 할당/회수합니다.

 ✅ 2. 힙(Heap) 영역 ≠ 자료구조 힙(Binary Heap, Priority Queue)

| 관점       | 설명                                                             |
| -------- | -------------------------------------------------------------- |
| 이름 유래    | "무질서하게, 자유롭게 흩어진 공간"이라는 **비유적 의미**의 "Heap"에서 유래                |
| 저장 내용    | **런타임에 동적으로 할당된 객체/메모리 (`new`, `malloc`)**                     |
| 할당/해제 방식 | **프로그래머가 명시적으로 `free`, `delete`해야 함 (또는 GC가 정리)**              |
| 내부 동작    | 실제 구현은 다양한 메모리 풀/알고리즘 (`ptmalloc`, `dlmalloc`, `jemalloc`)로 관리 |

➡ 운영체제의 힙은 **자료구조의 힙(우선순위 큐)**과는 전혀 무관하며,  
**"구조화되지 않은, 동적 할당 메모리 풀"이라는 뜻에서의 heap**입니다.

 ✅ 정리

|항목|자료구조와의 관계|
|---|---|
|**Stack 영역**|✅ 자료구조 스택(LIFO)과 **거의 동일한 방식**으로 동작|
|**Heap 영역**|❌ 자료구조 힙과는 무관, 단지 **동적으로 메모리를 관리하는 영역**|

##### IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
✅ 결론부터

> **Shared Memory는 일반적으로 각 프로세스의 주소 공간 중 “Heap 근처” 또는 “mmap 영역”에 매핑됩니다.**  
> **고정된 위치는 아니며**, OS가 가상 주소 공간의 여유 영역에 매핑합니다.  
> **Heap, Stack과 별도로 존재하지만 가상 메모리 상에 들어갑니다.**

 ✅ 왜 Heap 근처(mmap 영역)에 들어가는가?

1. **동적으로 크기를 지정하기 때문에**
    
    - 공유 메모리는 `malloc`처럼 크기를 지정해서 요청
        
    - Stack처럼 컴파일 타임에 위치/크기가 정해지는 것이 아님
        
2. **`mmap()` 시스템 콜로 할당되기 때문에**
    
    - 공유 메모리는 내부적으로 `mmap()` 또는 `shmat()`을 통해 **특정 가상 주소에 매핑**
        
    - `mmap()`으로 할당된 메모리는 보통 **Heap과 Stack 사이의 mmap 영역**에 들어감
        
3. **주소 공간 격리를 유지하면서도 메모리 공유가 가능**
    
    - 실제 메모리는 공유되지만, **각 프로세스의 가상 주소 공간에 독립적으로 매핑**됨
        
✅ 왜 이런 방식으로 구현하는가?

| 이유                    | 설명                                              |
| --------------------- | ----------------------------------------------- |
| 주소 공간 격리 유지           | 실제 물리 메모리는 공유하되, 각 프로세스의 **가상 주소 공간은 독립적으로 구성** |
| 유연한 매핑 지원             | `mmap()`은 원하는 주소에 매핑하거나 OS에 위임할 수 있어 유연함        |
| 보안 및 권한 제어 가능         | 매핑 시 `PROT_READ`, `PROT_WRITE` 등을 설정 가능         |
| 빠른 성능 (Zero-copy IPC) | 커널을 거치지 않고 **직접 메모리 접근으로 통신 가능**                |

---
 ✅ 요약

| 질문                        | 답변                                              |
| ------------------------- | ----------------------------------------------- |
| 공유 메모리는 주소 공간의 어디에 들어가나요? | 보통 **Heap과 Stack 사이의 mmap 영역**에 매핑됩니다           |
| 고정된 위치인가요?                | ❌ 아니며, `mmap()`으로 **동적으로 배정된 가상 주소**에 매핑됩니다     |
| 그 이유는 무엇인가요?              | 주소 공간의 유연성 확보, 격리 유지, 성능 최적화, 시스템 콜 동작 방식 때문입니다 |
#####  스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
✅ 1. 스택(Stack) 영역의 크기
 📌 크기 결정 시점

- **스레드 생성 시** 운영체제가 스택의 크기를 결정합니다.    
- 메인 스레드: 시스템 기본값 (보통 리눅스는 **8MB**)
- 서브 스레드: `pthread_attr_setstacksize()` 또는 JVM 설정 등으로 조정 가능
    

 📌 사용자 변경 가능 여부

| 변경 방식                         | 설명                                    |
| ----------------------------- | ------------------------------------- |
| `ulimit -s`                   | 현재 세션의 **스택 최대 크기(KB 단위)** 조정 가능      |
| `setrlimit()`                 | 프로그램 내부에서 **런타임 시 한도 설정** 가능 (C에서 사용) |
| `pthread_attr_setstacksize()` | POSIX 스레드 생성 시 스택 크기 지정 가능            |
| Java 옵션                       | `-Xss` → JVM 스레드 스택 크기 지정             |


➡ 일반 사용자도 가능. **로그인 쉘, 스크립트, 실행 시마다 적용** 가능

---
✅ 2. 힙(Heap) 영역의 크기

📌 크기 결정 시점

- **런타임에 필요할 때 동적으로 증가**
    
- `malloc()`, `new` 등으로 요청한 만큼 커짐
    
- 내부적으로는 `brk()` 또는 `mmap()`으로 힙을 확장
    
📌 최대 크기 제한

- 힙은 이론적으로 매우 크지만, 실제 한도는 다음에 의해 제한됩니다:
    

| 제한 요소       | 설명                                         |
| ----------- | ------------------------------------------ |
| `ulimit -v` | 가상 메모리 총량 제한 (heap + stack + code 등 포함)    |
| 시스템 메모리     | 실제 사용 가능한 물리 메모리 + 스왑                      |
| OS 설정       | 일부 시스템에서는 `overcommit`, `rlimit`에 따라 제한 가능 |
| JVM 옵션      | Java에서는 `-Xmx`로 최대 힙 크기 지정                 |
 ✅ 요약표

| 항목     | 크기 결정 시점    | 사용자 조정 가능?    | 조정 방법 예시                                           |
| ------ | ----------- | ------------- | -------------------------------------------------- |
| **스택** | 스레드 생성 시    | ✅ 가능          | `ulimit -s`, `-Xss`, `pthread_attr_setstacksize()` |
| **힙**  | 런타임 중 동적 확장 | ✅ 가능 (상한선 설정) | `ulimit -v`, `-Xmx`, `setrlimit()` 등               |

 🔔 핵심 요약

> **스택은 스레드 생성 시 크기가 설정되며, 힙은 런타임 중 점진적으로 커지지만 상한은 운영체제나 사용자 설정으로 제한됩니다.**  
> 일반 사용자도 `ulimit`, 실행 옵션 등을 통해 **크기 조정이 가능합니다.**

### 5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.
##### 설명
✅ 1. 장기 스케줄러 (Long-Term Scheduler, Job Scheduler)
 📌 역할

> **디스크에 있는 "대기 중인 작업(프로그램)" 중 어떤 것을 메모리에 올릴지 결정**
- **"새로운 프로세스"를 생성할지 말지를 결정**
- → 즉, **프로세스를 메모리에 "입장시킬지 말지"를 정함**
    
 📌 특징
- 실행 빈도: **낮음** (시스템이 한가할 때만 실행)
- 목적: **Ready Queue에 있는 프로세스 수를 조절**
- 부하 조절을 위해 **프로세스 생성 속도를 제어**
    
 📌 예시

- 사용자 100명이 동시에 프로그램 실행 → **장기 스케줄러가 일부만 메모리에 올림**
    

 ✅ 2. 중기 스케줄러 (Medium-Term Scheduler, Swapper)

 📌 역할

> **메모리에 올라온 프로세스 중 일부를 "메모리에서 내보낼지(Swapping out)"를 결정**

- **프로세스를 잠시 메모리에서 제거**(Swap Out)하여 메모리 자원을 확보
    
- 이후 다시 실행해야 할 때 **다시 메모리에 올림**(Swap In)
    
 📌 특징

- 실행 빈도: 중간
    
- 목적: **메모리 부족 시 프로세스 일부를 일시 정지**
    
- “Ready → Suspend”, “Suspend → Ready” 상태 전환 담당
    
 📌 예시

- RAM 부족 시 오랫동안 대기 중인 프로세스를 디스크로 스왑
    

 ✅ 3. 단기 스케줄러 (Short-Term Scheduler, CPU Scheduler)

 📌 역할

> **Ready Queue에 있는 프로세스 중에서 어떤 것을 CPU에 할당할지 결정**

- **매우 자주 실행**
    
- 타임슬라이스 만료, I/O 완료, 인터럽트 발생 등 **매 CPU 스위칭마다 호출**
    
 📌 특징

- 실행 빈도: **매우 높음 (밀리초 단위)**
    
- 목적: **CPU 효율적으로 배분**
    
- 다양한 스케줄링 알고리즘 적용 가능 (RR, SJF, Priority 등)
    
 📌 예시

- CPU가 놀고 있을 때 Ready Queue에서 다음 프로세스 선택
    

 ✅ 정리: 스케줄러 비교표

| 항목    | 장기 스케줄러        | 중기 스케줄러        | 단기 스케줄러             |
| ----- | -------------- | -------------- | ------------------- |
| 별칭    | Job Scheduler  | Swapper        | CPU Scheduler       |
| 선택 대상 | 디스크 상의 작업들     | 메모리에 있는 프로세스   | Ready 상태 프로세스       |
| 결정 사항 | 메모리에 올릴지 여부    | 메모리에서 내릴지 여부   | CPU에 할당할지 여부        |
| 실행 빈도 | 낮음             | 중간             | 높음                  |
| 예시    | 새 사용자 작업 입장 제한 | RAM 부족 시 스왑 아웃 | 타임슬라이스 만료 시 프로세스 교체 |

 🔔 핵심 요약

> **장기 스케줄러**: "어떤 작업을 메모리에 들일까?"  
> **중기 스케줄러**: "메모리 부족하니 누구를 잠시 내보낼까?"  
> **단기 스케줄러**: "지금 CPU를 누구한테 줄까?"
##### 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
현대 운영체제에서는 **세 가지 스케줄러(장기, 중기, 단기)를 모두 개념적으로는 유지하고 있지만**,  **실제로는 “단기 스케줄러 중심”으로 동작**하며,  
**장기 스케줄러와 중기 스케줄러는 특정 상황에서만 사용하거나 완전히 생략되기도 합니다.**

 ✅ 1. 단기 스케줄러 (Short-Term Scheduler)

- **현대 OS에서 반드시 존재하며 항상 사용됩니다.**
    
- 커널 스케줄러는 매 타임슬라이스마다 실행되어 **CPU를 할당할 프로세스를 선택**합니다.
    
- 다양한 스케줄링 알고리즘이 적용됩니다 (CFS in Linux, MLFQ, 등)
    
✅ **현대 운영체제에서 "주력" 스케줄러입니다.**

 ✅ 2. 중기 스케줄러 (Medium-Term Scheduler)
- **현대 데스크탑 OS (Linux, Windows 등)에서는 일반적으로 생략되거나 자동화됨.**
- 중기 스케줄러의 역할인 **"Swapping"**은 예전에는 메모리 부족 시 자주 쓰였지만,  
    오늘날은 **물리 메모리가 충분하고**, 대신 **가상 메모리 + 페이지 교체 + 캐시 관리**로 해결합니다.
    

📌 즉, **"중기 스케줄러라는 이름의 별도 정책"은 존재하지 않지만**,  
→ 그 역할은 **페이지 교체 알고리즘**(LRU, CLOCK) + **Swap Daemon**이 수행함

✅ **현대 OS에서는 "명시적인 중기 스케줄러는 거의 없고, 커널 메모리 관리자와 통합"된 형태**


 ✅ 3. 장기 스케줄러 (Long-Term Scheduler)

- **배치 처리 시스템(예: 고성능 클러스터, 메인프레임, Job Queue 기반 시스템)**에서는 여전히 사용됩니다.
    
- 하지만 **일반적인 현대 데스크탑/서버 OS에서는 사용하지 않거나 매우 제한적으로만 존재**합니다.
    

📌 대신 다음이 그 역할을 합니다:

- **Login 제한, cgroup, nice 값 조정** 등으로 프로세스 입장을 간접 제어
    
- **Job Scheduler (ex: SLURM, Kubernetes)** 같은 외부 시스템이 이 역할을 수행하기도 함
    

✅ **현대 데스크탑 OS에서는 생략되거나 사용자 공간 서비스로 대체**

---
✅ 한 줄 요약

|스케줄러|현대 데스크탑 OS에서 사용 여부|설명|
|---|---|---|
|단기 스케줄러|✅ 항상 사용|CPU 할당의 핵심|
|중기 스케줄러|⚠️ 명시적 사용 드묾 / 역할은 남음|페이지 교체, swap으로 대체|
|장기 스케줄러|❌ 일반 OS는 생략, 일부 시스템만|Job Queue 시스템 등에서만 사용|
✅ 결론

> **현대 운영체제는 실질적으로 단기 스케줄러에 집중하며**,  
> 중기·장기 스케줄러는 **개념적으로 존재하지만, 실무에서는 대부분 커널 내부 또는 외부 도구가 그 역할을 대신합니다.**
##### 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
✅ 대표적인 프로세스 상태 (5-State 모델 기준)

| 상태                    | 설명                                       |
| --------------------- | ---------------------------------------- |
| **New**               | 프로세스가 생성 중인 상태 (`fork()`, `exec()` 호출 등) |
| **Ready**             | **CPU 할당만 기다리는 상태**, 실행 가능한 상태           |
| **Running**           | CPU를 할당받아 명령어를 실행 중인 상태                  |
| **Waiting / Blocked** | **I/O 등 외부 이벤트 대기 중**이라 CPU를 쓸 수 없는 상태   |
| **Terminated**        | 실행이 끝난 상태 (exit 호출 등), PCB 정리 대기         |
![[Pasted image 20250525000107.png]]
✅ 각 상태 설명 (자세히)
 1. **New**
- 프로세스 생성 요청이 들어왔으나 아직 메모리 할당, PCB 생성이 완료되지 않은 상태    
- 완전히 생성되면 → Ready 상태로 이동


2. **Ready**

- 실행 가능한 상태이지만 CPU를 아직 배정받지 못함
- 여러 프로세스가 **Ready Queue**에 쌓여 있음
- 단기 스케줄러가 여기서 하나 선택 → Running 상태로 이동
    
 3. **Running**
- CPU를 점유하여 실제 명령어 실행 중
- 인터럽트, 타임슬라이스 종료, I/O 요청 등에 의해 상태가 변할 수 있음
    
4. **Waiting / Blocked**
- 디스크 I/O, 네트워크, 사용자 입력 등 **외부 자원을 기다리는 상태**
- CPU 자원을 쓸 수 없기 때문에 Ready Queue에선 빠져 있음
    
5. **Terminated**
- `exit()`, `return`, `SIGTERM` 등으로 프로세스 종료
- 커널이 프로세스 정보를 정리할 때까지 이 상태에 머무름
- **부모 프로세스가 `wait()` 호출하지 않으면 좀비(Zombie) 상태로 잠시 남음**
    
✅ 확장 상태 (현대 OS)

| 상태                            | 설명                                                        |
| ----------------------------- | --------------------------------------------------------- |
| **Sleeping (interruptible)**  | `Waiting` 상태 중에서 인터럽트로 깨울 수 있는 상태 (`select()`, `sleep()`) |
| **Uninterruptible Sleep (D)** | 디스크 I/O처럼 **인터럽트로 깰 수 없는** 기다림 (커널 내부에서만 발생)              |
| **Zombie (Z)**                | 자식 프로세스가 종료되었으나 부모가 `wait()`하지 않아 PCB가 남아 있는 상태           |
##### preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
**Preemptive(선점형) vs Non-Preemptive(비선점형) 스케줄링 방식**은 **프로세스 상태 자체를 없애거나 새로 만들지는 않습니다.**  
하지만, **일부 상태 전이가 특정 방식에서는 발생하지 않거나 제한됩니다.**

---

✅ 결론 요약

> ❌ **두 방식 모두 공통된 프로세스 상태(Ready, Running, Waiting 등)는 유지됩니다.**  
> ✅ **하지만, 상태 간 "전이 방식"이 달라집니다.**

즉, **상태가 “존재할 수 없”는 건 아니고**,  
**어떤 상태로 “자동으로 전이되느냐”가 달라지는 것입니다.**

---
✅ 상태 전이 비교

| 상태 전이                           | 선점형 (Preemptive)                                       | 비선점형 (Non-Preemptive)        |
| ------------------------------- | ------------------------------------------------------ | ---------------------------- |
| **Running → Ready**             | ✅ 가능 (타임슬라이스 만료, 더 높은 우선순위 프로세스 등장 등으로 **OS가 강제로 중단**) | ❌ 불가능 (**스스로 양보할 때만** 전이 가능) |
| **Ready → Running**             | ✅ OS가 스케줄링 정책에 따라 즉시 전환                                | ✅ 동일                         |
| **Running → Waiting (Blocked)** | ✅ 시스템 콜 등으로 자발적으로 차단됨                                  | ✅ 동일                         |
| **Waiting → Ready**             | ✅ I/O 완료 등으로 다시 준비됨                                    | ✅ 동일                         |

---
✅ 핵심 차이: **Running → Ready 전이가 가능한가?**

- **Preemptive OS**:
    
    - 커널이 언제든지 **강제로 실행 중인 프로세스를 중단**
        
    - → 다른 Ready 프로세스에게 CPU를 넘길 수 있음
        
    - → **Running → Ready 전이 가능**
        
- **Non-Preemptive OS**:
    
    - **실행 중인 프로세스가 스스로 양보할 때만** CPU를 넘김
        
    - → 강제로 Ready로 돌릴 수 없음
        
    - → **Running → Ready 전이는 시스템이 강제로 하지 않음**
        

---
✅ 요약 정리

|질문|답변|
|---|---|
|Preemptive/Non-Preemptive에서 사라지는 상태가 있는가?|❌ 없음. 모든 상태는 존재|
|어떤 점이 다르냐?|✅ 상태 **전이 방식**이 다름. 특히 **Running → Ready** 전이의 여부|
|실질적 영향은?|비선점형에서는 CPU 독점 가능성이 있어 **응답성, 공정성**이 낮아질 수 있음|
##### Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
**시스템 메모리가 부족할 경우**, 프로세스는 **즉시 죽거나 정지되는 것이 아니라**,  
운영체제가 상황에 따라 **적절한 상태로 전이시킵니다.**

 ✅ 기본 전제

> 운영체제는 **프로세스를 종료시키기 전에**,  
> 먼저 **스케줄링 상태(Waiting, Suspended 등)로 전환하거나, 페이지 스와핑 등으로 메모리를 확보하려 시도**합니다.

 ✅ 메모리 부족 상황에서의 전이 가능성

| 상황                      | 상태 전이 예                | 설명                                              |
| ----------------------- | ---------------------- | ----------------------------------------------- |
| **페이지 폴트** 발생           | `Running → Waiting`    | 필요한 페이지가 메모리에 없으면 → 디스크에서 가져올 때까지 **Block**     |
| **스왑 아웃**               | `Ready → Suspended`    | 메모리가 부족할 경우, 사용하지 않는 프로세스를 디스크로 내림 (`swap out`) |
| **OOM (Out-Of-Memory)** | `Running → Terminated` | 운영체제가 더 이상 확보할 메모리가 없으면 **강제 종료**               |
| **파일 시스템 캐시 축소**        | 상태 변화 없음               | 커널은 우선적으로 **페이지 캐시**를 줄이려 시도함 (상태 변화 없이 처리)     |

✅ 상세 흐름

 📌 1. 페이지 폴트 (Soft Memory Pressure)

- 프로세스가 아직 메모리에 올라오지 않은 페이지에 접근할 경우
    
- OS는 해당 페이지를 디스크에서 가져오며 프로세스는 **잠시 Blocked(WAITING)** 상태로 전환
    
📌 2. Swap-out by Medium-Term Scheduler (Moderate Pressure)

- **중기 스케줄러 역할**: 메모리가 부족하면 일부 프로세스를 **Swap 영역으로 내림**
    
- 해당 프로세스는 `Ready → Suspended`로 전이
    
 📌 3. OOM: Out-Of-Memory (Severe Pressure)

- 커널이 물리 메모리 + 스왑 공간을 다 써서 할당 불가능한 경우
    
- **OOM Killer**가 실행되어 프로세스 강제 종료
    
 ✅ 요약 정리

| 메모리 상황              | 프로세스 상태 변화                        | 설명                     |
| ------------------- | --------------------------------- | ---------------------- |
| 페이지 없음 (page fault) | `Running → Waiting → Ready`       | 디스크에서 페이지 가져올 때까지 대기   |
| 메모리 부족 (스왑 필요)      | `Ready → Suspended`               | 일부 프로세스 스왑아웃 (중기 스케줄러) |
| 메모리 완전 고갈           | `Running → Terminated (OOM Kill)` | 커널이 강제 종료시킴            |

---
🔔 핵심 요약

> 메모리가 부족할 경우, 프로세스는 우선 **Waiting 또는 Suspended 상태로 전이**되며,  
> 극단적인 상황에서는 **OOM Killer에 의해 종료(Terminated)**됩니다.

### 6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
##### 설명
**컨텍스트 스위칭(Context Switching)**은 운영체제가 **CPU를 하나의 프로세스(또는 스레드)에서 다른 프로세스로 전환할 때 수행하는 작업**입니다.

> 🧠 요약하면:  
> “**이전 프로세스의 상태(문맥)를 저장하고, 새 프로세스의 상태를 복원하는 일**”

아래에서 컨텍스트 스위칭의 정확한 **의미, 내부 동작, 발생 시점, 비용** 등을 단계별로 설명드리겠습니다.

✅ 1. 컨텍스트(Context)란?

> 한 프로세스(또는 스레드)의 **실행에 필요한 모든 CPU 상태 정보**

포함되는 정보:

| 종류                  | 설명                                      |
| ------------------- | --------------------------------------- |
| **레지스터 값**          | `PC`, `SP`, `RAX`, `RBX` 등 일반 및 특수 레지스터 |
| **프로세스 상태**         | Running, Ready 등                        |
| **메모리 맵**           | 페이지 테이블, 스택/힙 포인터 등                     |
| **커널 상태**           | 시스템 콜 중이라면 커널 모드 정보 등                   |
| **FPU/Vector 레지스터** | 부동소수점 연산 및 SIMD 연산용 레지스터 (필요 시)         |

➡ 이 정보들을 통틀어 "문맥(Context)"라고 부릅니다.

---
✅ 2. 컨텍스트 스위칭이 발생하는 시점

|발생 시점|예시|
|---|---|
|**타임슬라이스 만료**|선점형 스케줄러에서 할당 시간 초과 시|
|**I/O 요청**|I/O 대기 위해 CPU 양보|
|**우선순위 높은 프로세스 등장**|Ready Queue에 높은 우선순위 프로세스 등장|
|**시스템 콜, 인터럽트, 시그널 처리 등**|커널 개입 필요 시|

---
✅ 3. 컨텍스트 스위칭 단계별 동작
```
[1] 현재 실행 중인 프로세스의 상태 저장 (Save Context) ↓
[2] 스케줄러가 다음 실행할 프로세스를 결정 (Select Next) ↓
[3] 새 프로세스의 상태를 복원 (Load Context) ↓ 
[4] 새 프로세스 실행 시작
```
 📌 자세히
 [1] Save Context (기존 프로세스 상태 저장)

- CPU 레지스터, PC(Program Counter), SP(Stack Pointer) 등 → **PCB(Process Control Block)**에 저장
    
- `task_struct`에 저장됨 (Linux 기준)
    
[2] Scheduler 호출

- Ready Queue를 기반으로 다음 프로세스를 선택
    
 [3] Load Context (새 프로세스 상태 복원)

- 새 프로세스의 PCB에서 레지스터 값 등 읽어와 복원
    
- 페이지 테이블 교체 (TLB flush 포함)
    
 [4] 실행 재개

- 이전에 멈춘 지점부터 다시 실행됨
    

---
✅ 4. 컨텍스트 스위칭 비용

|항목|설명|
|---|---|
|**오버헤드 존재**|사용자 코드 실행과 직접 관련 없는 작업이므로 시스템 자원 낭비 발생|
|**TLB Flush**|프로세스 간 페이지 테이블이 다르면 TLB 초기화 필요 (성능 저하)|
|**캐시 미스 증가**|CPU 캐시가 전환된 프로세스와 관련 없어져 **캐시 히트율 감소**|

📌 **컨텍스트 스위칭이 많을수록 → CPU 효율 ↓**

✅ 정리 요약

| 항목    | 내용                             |
| ----- | ------------------------------ |
| 정의    | CPU를 한 프로세스에서 다른 프로세스로 전환하는 작업 |
| 수행 시점 | 타임슬라이스 종료, I/O 대기, 인터럽트 등      |
| 주요 작업 | 이전 프로세스 상태 저장 + 다음 프로세스 상태 복원  |
| 포함 정보 | 레지스터, PC, 스택 포인터, 메모리 상태 등     |
| 비용    | 시간/캐시 손실, TLB flush 등          |

🔔 핵심 한 줄 요약

> **컨텍스트 스위칭은 CPU가 다른 프로세스로 전환하기 위해 "실행 문맥을 저장하고 복원"하는 작업이며,  
> 과도하게 발생하면 성능 저하의 원인이 됩니다.**
> 
##### 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
✅ 핵심 결론

> **스레드 간 컨텍스트 스위칭이 프로세스 간 컨텍스트 스위칭보다 훨씬 가볍고 빠릅니다.**  
> 그 이유는 **스레드는 주소 공간을 공유**하고, **프로세스는 주소 공간이 완전히 분리되어 있기 때문**입니다.

---
✅ 비교 표: 프로세스 vs 스레드 컨텍스트 스위칭

|항목|**프로세스 간 스위칭**|**스레드 간 스위칭 (동일 프로세스 내)**|
|---|---|---|
|주소 공간|✅ 전환 필요 (페이지 테이블 교체)|❌ 전환 없음 (같은 주소 공간 공유)|
|TLB Flush|✅ 발생함|❌ 보통 불필요|
|캐시 히트율|낮아질 수 있음|높게 유지됨|
|PCB 변경|✅ 전체 PCB 교체|✅ 일부만 교체|
|스택/레지스터 교체|✅ 필요|✅ 필요|
|오버헤드|⛔ 높음|✅ 낮음|
|속도|느림 (~수 μs 이상)|빠름 (~~수백 ns~~수 μs)|
|비용|커널이 페이지 테이블, 권한, I/O 등 모두 관리 필요|스택과 레지스터 정보만 스위칭|
 ✅ 이유 설명

📌 1. 프로세스 컨텍스트 스위칭

- 주소 공간 자체가 완전히 다르기 때문에:
    
    - **페이지 테이블 교체**
        
    - **TLB(Translation Lookaside Buffer) 초기화**
        
    - **CPU 캐시 유효성 감소**
        

➡ 이 모든 작업은 무겁고 느림

📌 2. 스레드 컨텍스트 스위칭

- **같은 프로세스 내부의 실행 흐름 전환**일 뿐
    
- 주소 공간, 커널 리소스는 그대로 유지
    
- **스택, 레지스터 정보만 교체하면 됨**
    

➡ 매우 빠르고 가벼움  
➡ 그래서 스레드는 **경량(Lightweight) 프로세스**라고도 부름

---
✅ 예시: 리눅스에서의 스케줄링

- `task_struct`는 프로세스/스레드 모두에게 존재
    
- 프로세스 전환 시:
    
    - 메모리 디스크립터(`mm_struct`)까지 바뀜
        
- 스레드 전환 시:
    
    - **공유된 `mm_struct` 유지**
        
    - **레지스터, 스택 포인터만 교체**
        

---
✅ 한 줄 정리

> **프로세스 간 컨텍스트 스위칭은 주소 공간까지 바꿔야 해서 무겁고**,  
> **스레드 간 스위칭은 레지스터와 스택만 바꾸면 되므로 훨씬 가볍고 빠릅니다.**
##### 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
✅ 먼저 요약 결론

> **컨텍스트 스위칭 시, 현재 실행 중인 프로세스의 레지스터와 스택 포인터 등의 CPU 상태 정보는 커널 스택에 저장되며,**  
> 이 정보는 `task_struct` 안의 `thread_struct`에 연결되어 저장됩니다.

---
 ✅ 리눅스에서 프로세스의 실행 정보 저장 구조

리눅스에서 각 프로세스는 다음 정보를 가집니다:

| 구조체             | 역할                                      |
| --------------- | --------------------------------------- |
| `task_struct`   | PCB, 프로세스 전체 정보 보관 (PID, 상태, 우선순위 등)    |
| `thread_struct` | CPU 레지스터 상태, 스택 포인터 등 스레드 레벨 컨텍스트 저장    |
| **커널 스택**       | **스위칭 시 레지스터 저장**, 커널 함수 호출 시 스택 프레임 저장 |

---
✅ 컨텍스트 스위칭 과정에서 커널 스택의 역할

 📌 컨텍스트 스위칭 전: 현재 프로세스 저장

1. **인터럽트 발생 또는 스케줄러 호출**
    
2. 현재 프로세스의 레지스터 값들(`%rip`, `%rsp`, `%rbp`, `%rax`, ...)을 **커널 스택에 push**
    
3. 이 커널 스택의 상태를 **`task_struct.thread_struct.sp`에 기록**
    
 📌 컨텍스트 스위칭 후: 새 프로세스 상태 복원

1. 커널은 스케줄러에서 새 프로세스의 `task_struct` 선택
    
2. 해당 프로세스의 `thread_struct.sp`를 읽어서 **이전 커널 스택 포인터 복원**
    
3. `pop`을 통해 레지스터 원상복구 → 새 프로세스 실행 재개
    
 ✅ 저장되는 레지스터 정보 종류 (x86-64 기준)

- 제너럴 레지스터: `rax`, `rbx`, `rcx`, `rdx`, ...
    
- 스택 포인터: `rsp`
    
- 프로그램 카운터: `rip`
    
- 상태 레지스터: `eflags`
    
- 세그먼트 레지스터 (필요 시): `cs`, `ss`, `fs`, `gs`
    

💡 이 정보는 일반적으로 어셈블리 수준에서 `save_context`, `restore_context` 매크로나 inline asm으로 처리됩니다.

---
✅ 정리 요약

| 항목            | 저장 위치              | 설명               |
| ------------- | ------------------ | ---------------- |
| 레지스터 값        | 커널 스택에 `push`      | CPU 상태 백업용       |
| 커널 스택 포인터     | `thread_struct.sp` | 이후 복구용           |
| 전체 PCB/스레드 정보 | `task_struct`      | PID, 상태, 시간 등 포함 |
| 스위칭 후 복원 과정   | `pop` + `iret` 등   | CPU 상태 복구, 실행 재개 |

---
 🔔 한 줄 요약

> 컨텍스트 스위칭 시, **CPU 레지스터와 스택 포인터 등은 커널 스택에 저장되고**,  
> 그 포인터는 `task_struct` 안의 `thread_struct`에 기록되어 나중에 복구됩니다.
##### 컨텍스트 스위칭은 언제 일어날까요?
**컨텍스트 스위칭(Context Switching)**은 운영체제가 **CPU를 현재 실행 중인 프로세스(또는 스레드)에서 다른 것으로 전환할 필요가 있을 때** 발생합니다.  
아래에 **구체적인 발생 시점**을 상황별로 정리해 드리겠습니다.

 ✅ 컨텍스트 스위칭이 발생하는 주요 시점

 1. **타임슬라이스 만료 (Time Slice Expiration)**

- 선점형(Preemptive) 스케줄러에서는 각 프로세스에 주어진 CPU 사용 시간이 끝나면 강제로 다른 프로세스에게 CPU를 넘김
    
- ⏱️ 예: Round Robin 스케줄링에서 10ms마다 스위칭
    

> ⟶ `Running → Ready` → 다른 프로세스 `Ready → Running`


2. **I/O 요청 또는 대기 상태 진입**

- 프로세스가 디스크, 네트워크, 사용자 입력 등 **I/O 요청**을 하면 더 이상 CPU를 사용할 수 없으므로 대기 상태로 전환
    
- 운영체제는 다른 Ready 프로세스를 CPU에 할당
    

> ⟶ `Running → Waiting` → 다른 프로세스 `Ready → Running`

---
 3. **더 높은 우선순위 프로세스가 준비됨**

- 우선순위 기반 스케줄링에서 더 높은 우선순위를 가진 프로세스가 Ready 상태로 전환되면, 현재 프로세스를 중단하고 교체
    

> ⟶ `Running → Ready`, 고우선 프로세스 `Ready → Running`

---
 4. **프로세스 종료**

- 현재 실행 중인 프로세스가 `exit()` 등을 호출해 종료되면, 커널은 다음 실행할 프로세스를 선택
    

> ⟶ `Running → Terminated`, 다음 프로세스 `Ready → Running`

---
 5. **시스템 콜 또는 인터럽트 처리 중**

- 사용자 모드에서 커널 모드로 전환되는 시스템 콜 처리 중,  
    스케줄링 판단이 필요하면 컨텍스트 스위칭 발생
    
- 하드웨어 인터럽트(예: 타이머, 디바이스 완료) 도중에도 다른 프로세스로 전환 가능
    

> ⟶ 커널이 중간에 개입하여 스위칭을 유도

 6. **멀티코어 환경에서의 로드 밸런싱**

- CPU 코어 간 작업 분산을 위해, 특정 프로세스를 다른 코어로 옮기는 경우
    
- 이 때도 컨텍스트 저장과 복원이 필요함
    

✅ 정리 표

|상황|설명|상태 전이 예시|
|---|---|---|
|타임슬라이스 만료|CPU 사용 시간 끝남|`Running → Ready`|
|I/O 요청|대기 상태로 전환|`Running → Waiting`|
|고우선 프로세스 등장|스케줄러가 교체 결정|`Running → Ready`|
|프로세스 종료|다음 프로세스 선택|`Running → Terminated`|
|인터럽트|커널 개입 가능|상태에 따라 다양|
|로드 밸런싱|CPU 간 마이그레이션|내부적으로 저장/복원 발생|

 🔔 핵심 요약

> **컨텍스트 스위칭은 CPU를 다른 프로세스에게 넘겨줘야 할 필요가 있을 때마다 일어납니다.**  
> **선점, I/O, 종료, 인터럽트, 우선순위 등 다양한 상황에서 발생**하며,  
> 이 과정에서 커널은 기존 상태를 저장하고 새 상태를 복원합니다.

### 7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
##### 설명
✅ 핵심 요약

- **비선점형**:
    
    - `FCFS`, `SJF`, `Priority(정적)`
        
    - 단순하지만 **응답 시간 예측이 어려움**, 비공정 가능성 있음
        
- **선점형**:
    
    - `SRTF`, `RR`, `MLFQ`, `CFS`, `Priority(동적)`
        
    - **응답성 우수**, **멀티태스킹 적합**, 하지만 **컨텍스트 스위칭 오버헤드** 있음
✅ 각 알고리즘 간단 설명
Scheduling algorithm

✅ FCFS

**선입선출**

평균 대기 시간이 길어지고, IO 사용량이 줄어든다.

**Convoy effect**가 발생할 수 있다.

✅ SJF: Shortest Job First

**CPU Burst가 짧은 프로세스**에게 CPU를 할당한다. 선점형과 비선점형으로 구현할 수 있다.

이때 프로세스의 CPU Burst 시간을 미리 알 수 없으므로, 예측을 통해 CPU 버스트 시간을 구한다.

평균 대기 시간을 낮추는 데 효과적이지만, 모든 프로세스가 동시에 CPU를 요청하지 않으면 **기아 현상**이 발생할 수 있다.

✅ STCF: Shortest Time-to-Completion First

**남은 CPU Burst가 가장 짧은 프로세스**에게 CPU를 할당한다.

새로운 프로세스의 CPU 요청이 오거나 현재 프로세스의 작업이 모두 끝났을 때, 남은 작업 시간이 가장 짧은 프로세스에게 CPU를 할당한다. 따라서 선점형 SJF라고도 하고, 현재 프로세스가 CPU 제어권을 뺏길 수도 있어다.

평균 대기 시간을 낮추는 최적 스케줄링이다.

CPU Burst가 긴 프로세스에게 **기아 현상**이 발생할 수 있다.

 ✅Priority scheduling

**우선순위가 높은 프로세스**에게 CPU를 할당한다. 선점형과 비선점형으로 구현할 수 있다.

우선순위가 낮은 프로세스에게 **기아 현상**이 발생할 수 있다.

→ **Aiging 기법**을 통해 기다리는 시간이 길 수록 우선순위를 높여, 언젠가는 CPU를 할당받을 수 있게 돕는다.

✅ RR: Round Robin

**Time slice** 혹은 **Time quantum**을 설정해 모든 프로세스에게 CPU를 연속적으로 사용할 수 있는 시간을 제한하는 스케줄링으로, 시분할 시스템의 성질을 가장 잘 활용한다.

Time slice의 길이가 너무 길면 FCFS와 비슷한 결과를 내고, 너무 짧으면 Context switch의 오버헤드가 커진다.

→ 수십 밀리초가 일반적이다. 적어도 프로세스개수-1 * time slice 에 한 번은 내 차례가 오기 때문에, 수백밀리초~1초 정도의 응답 시간이 보장된다.

프로세스의 CPU 사용량에 비례해 Turnaround time이 늘어나고, 평균 Response time이 짧아진다.

✅ MLFQ: Multi Level Feedback Queue

**Ready queue를 여러 개**로 분할해 관리한다.

일반적으로 성격이 다른 프로세스를 서로 다른 큐에 두고, 각각의 성격에 맞추어 스케줄링을 제공한다.
![[Pasted image 20250525122945.png]]
MLFQ의 구현을 위해 아래의 사항을 고려해야 한다.

- 큐의 개수
- 각 큐의 스케줄링 알고리즘
- 도착한 프로세스를 어떤 큐에 넣을지 결정하는 기준
- 큐를 상위/하위로 승격/강등시키는 기준

운체 강의에서 배운 내용
- 작업 수행은 RR 스케줄링 적용
- 상위 레벨의 큐에서 선택해 작업 시작
- 프로세스가 CPU를 요청하면, 높은 레벨의 큐에 진입시킨다.
    - 한 Time slice가 끝나면, 레벨이 낮은 큐로 강등시킨다.
    - 한 Time slice가 끝나기 전에 CPU를 포기하면, 같은 레벨를 유지한다.
- 한 프로세스에 오래 있을 경우 최상위 큐로 올린다. - Priority Boost
    ![[Pasted image 20250525123054.png]]
    
 ✅ Multi-processor system scheduling

CPU가 여러 개인 시스템의 CPU 스케줄링

프로세스를 큐에 줄 세워 각 CPU마다 하나씩 꺼내갈 수도 있고, 특정 CPU에서 작업을 수행해야 하는 프로세스가 있는 경우 CPU마다 줄을 세울 수 있다.

이때 CPU 간 로드 밸런싱 메커니즘이 필요하다.

- 대칭형 다중처리 - CPU마다 알아서 스케줄링한다.
- 비대칭형 다중처리 - 한 CPU가 모든 CPU의 스케줄링을 결정한다.

✅ Realtime scheduling

시분할 환경이 아닌 실시간 환경에서는 데드라인의 개념이 존재하며, 데드라인을 맞추는 스케줄링이 필요하다.
##### RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
✅ Time Slice란?

> **각 프로세스가 CPU를 연속해서 사용할 수 있는 최대 시간**  
> RR은 이 시간을 기준으로 **모든 프로세스에 CPU를 순환할당**합니다.

 ✅ Time Slice 크기에 따른 Trade-off

| Time Slice | 장점                           | 단점                               |
| ---------- | ---------------------------- | -------------------------------- |
| **짧을 때**   | 🔹 응답성 향상 (대기 시간이 짧음)        | ❌ 문맥 전환(Context Switching) 빈도 증가 |
|            | 🔹 사용자 체감 반응 빠름 (특히 인터랙티브 앱) | ❌ CPU 낭비 (오버헤드 증가)               |
|            |                              |                                  |
| **길 때**    | 🔹 문맥 전환 횟수 감소 → 오버헤드 감소     | ❌ 응답성 저하 (대기 시간 증가)              |
|            | 🔹 배치/연산 집중형 작업 효율적          | ❌ 짧은 작업이 오래 기다림 (공정성 저하)         |
|            |                              |                                  |
|            |                              |                                  |
✅ 예시 시나리오

📌 타임슬라이스 5ms (짧음)

- 100개의 프로세스 → 500ms마다 한 바퀴 순환
    
- 인터랙티브 앱은 빠르게 응답하지만,
    
- 매 5ms마다 컨텍스트 스위칭 → 성능 저하
    
📌 타임슬라이스 100ms (김)

- 응답 지연은 커지지만 CPU 사용률 향상
    
- 짧은 작업이 긴 작업 뒤에 대기할 경우 → **SJF 대비 손해**
    
✅ 적절한 타임슬라이스 기준

|기준|설명|
|---|---|
|**짧은 작업 많음 (인터랙티브 시스템)**|10~20ms 권장|
|**CPU 집중형 작업 위주**|100ms 이상|
|**리눅스 CFS**|고정 슬라이스 대신 `vruntime` 기반으로 가상 시간 조절|

✅ 핵심 정리

|항목|짧은 타임슬라이스|긴 타임슬라이스|
|---|---|---|
|응답성|✅ 좋음|❌ 나쁨|
|처리량|❌ 낮음 (오버헤드)|✅ 높음 (적은 전환)|
|문맥 전환 오버헤드|❌ 큼|✅ 작음|
|공정성|✅ 높음 (자주 바뀜)|❌ 낮음 (짧은 작업 손해)|

---
🔔 한 줄 요약

> **짧은 Time Slice는 응답성이 뛰어나지만 오버헤드가 크고**,  
> **긴 Time Slice는 CPU 효율은 높지만 응답성이 떨어집니다.**  
> **따라서 사용 환경에 따라 균형 잡힌 타임슬라이스 선택이 중요합니다.**
##### 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
✅ 요점 정리

> **상시로 돌아가야 하는 프로세스가 있다면**,  
> ✅ **우선순위 기반 + 선점형 스케줄링 알고리즘**이 적합합니다.  
> 예: **Priority Scheduling (선점형)** 또는 **Rate Monotonic, Earliest Deadline First (실시간 OS)**

---
 ✅ 이유
 1. **상시 동작 프로세스**는 즉각적인 CPU 확보가 중요

- 다른 작업이 CPU를 점유 중일 때도 **즉시 CPU를 뺏어야 함**
    
- 즉, **선점형(Preemptive)** 스케줄링이 필수
    
 2. **우선순위 기반 스케줄링이 필요**

- 해당 프로세스를 **항상 가장 높은 우선순위로 설정**
    
- 다른 작업보다 항상 먼저 CPU를 받을 수 있음
    
 ✅ 권장 스케줄링 알고리즘

 📌 1. **Preemptive Priority Scheduling**

- 상시 프로세스는 **최상위 우선순위로 설정**
    
- 어떤 작업이 실행 중이든, 해당 프로세스가 Ready가 되면 즉시 CPU 선점
    
- 단순 OS에서도 구현 가능
    
 📌 2. **Real-Time Scheduling (실시간 OS 환경)**

> 만약 진짜 실시간성이 중요하다면 RTOS의 스케줄링 사용도 고려

- **Rate Monotonic Scheduling (RMS)**: 주기 짧은 작업이 더 높은 우선순위
    
- **Earliest Deadline First (EDF)**: 마감 시간이 빠를수록 우선순위 높음
    
- RTOS (예: FreeRTOS, RTLinux 등)에서 자주 사용
    

---
 ✅ 비적절한 예시

| 알고리즘        | 문제점                                     |
| ----------- | --------------------------------------- |
| FCFS        | 작업이 길면 상시 프로세스가 응답 못 함 (Non-preemptive) |
| SJF         | 예측 불가 + 선점 불가                           |
| Round Robin | 모든 프로세스에 CPU를 공평하게 나눔 → 상시 프로세스도 기다려야 함 |

 ✅ 현실적인 예: 리눅스에서 구현한다면?

- `nice` 값을 -20으로 설정해 우선순위 가장 높게 만들 수 있음
    
- `chrt` 명령어로 `SCHED_FIFO` (실시간 스케줄링 정책) 사용 가능
    
 ✅ 결론

> 🔹 **상시로 돌아가야 하는 프로세스가 있다면**,  
> 🔹 **우선순위 기반 + 선점형 스케줄링 알고리즘**이 필수입니다.  
> 🔹 일반 환경에서는 Preemptive Priority, 실시간 환경에서는 RMS/EDF를 사용하면 됩니다.
##### 동시성과 병렬성의 차이에 대해 설명해 주세요.
✅ 핵심 정의 비교

|개념|정의|
|---|---|
|**동시성 (Concurrency)**|**여러 작업을 "논리적으로" 동시에 처리하는 것**|
|(실제로는 순차적으로 번갈아 처리할 수도 있음)||
|**병렬성 (Parallelism)**|**여러 작업을 "물리적으로" 동시에 처리하는 것**|
|(여러 CPU 코어에서 동시에 실행)||

---
 ✅ 예시로 이해하기

📌 동시성 (Concurrency)

> 싱글코어 CPU에서 **스레드 A와 B가 번갈아 CPU를 사용**하여  
> 마치 동시에 돌아가는 것처럼 보이는 상태

- 실제로는 **작업을 쪼개서 빠르게 번갈아 처리**
    
- **문맥 전환(Context Switching)**을 통해 구현
    
 📌 병렬성 (Parallelism)

> 멀티코어 CPU에서 **스레드 A는 CPU 1, 스레드 B는 CPU 2에서 동시에 실행**

✅ 핵심 차이 요약

|항목|**동시성 (Concurrency)**|**병렬성 (Parallelism)**|
|---|---|---|
|실행 환경|싱글코어 또는 멀티코어 가능|멀티코어 필수|
|목적|**복수 작업 처리 흐름** 구성|**작업 처리 속도 향상**|
|구현 방식|**작업을 쪼개서 interleaving**|**작업을 나눠서 병렬 실행**|
|예|Thread, Coroutine, Async|OpenMP, 멀티프로세스, GPU 병렬 연산 등|
|상호 관계|병렬성 없이 동시성 구현 가능|병렬성은 동시성 개념을 포함함|

---
✅ 그림 요약 (비유)

> 🍝 **동시성**: 요리사 1명이 스파게티와 피자를 번갈아가며 요리  
> 🧑‍🍳 **병렬성**: 요리사 2명이 각자 스파게티와 피자를 동시에 요리

✅ 정리

|질문|답변|
|---|---|
|둘의 관계는?|병렬성은 동시성의 **하위 개념이 아니라 별개의 속성**, 단 **병렬성은 동시성을 포함**함|
|함께 사용할 수 있나?|✅ 가능. 동시성을 병렬적으로 구현하면 효율 극대화|
|예시|Node.js는 동시성 O, 병렬성 X (이벤트 루프 기반) / CUDA는 병렬성 O|
🔔 한 줄 요약

> **동시성**은 "여러 작업을 함께 처리하는 구조",  
> **병렬성**은 "여러 작업을 동시에 실제 실행"하는 것.  
> 병렬성은 하드웨어 기반, 동시성은 설계/논리 기반입니다.
##### 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
✅ MLFQ가 해결하는 대표적인 문제들

| 기존 스케줄러의 문제                       | MLFQ의 해결 방식                                   |
| --------------------------------- | --------------------------------------------- |
| ❌ **우선순위 고정으로 인한 Starvation**     | ⛳ **피드백을 통해 우선순위 조절** (aging)                 |
| ❌ **CPU-bound 프로세스가 RR에서 시스템 독점** | ⛳ **긴 작업은 아래 큐로 내려 보내 분리 처리**                 |
| ❌ **SJF: 실행 시간 예측 불가**            | ⛳ **실행 시간 대신 행동 패턴 기반 분류 (예: 짧게 자주 쓰는가?)**    |
| ❌ **I/O-bound 프로세스가 대기 큐에서 손해**   | ⛳ **자주 대기 상태에 빠지는 프로세스는 상위 큐에 유지 (빠른 응답)**    |
| ❌ **고정 타임슬라이스의 한계**               | ⛳ **레벨마다 타임슬라이스를 다르게 설정 가능** (상위는 짧게, 하위는 길게) |

✅ 각 문제에 대한 구체적 설명

📌 1. **Priority Scheduling의 Starvation 문제**

- 낮은 우선순위 프로세스는 **영원히 실행 기회를 얻지 못할 수 있음**
    

🔧 **MLFQ 해결책**:  
→ 오래 기다린 프로세스는 **큐를 상승시켜 우선순위 자동 상승** (aging)

 📌 2. **SJF의 실행 시간 예측 불가**

- SJF는 이론적으로 최적이지만, 실제로는 **프로세스의 실행 시간을 정확히 알 수 없음**
    
🔧 **MLFQ 해결책**:  
→ 실행 시간 예측 대신, **과거의 CPU 사용 패턴을 기반으로 분류**  
→ CPU를 많이 쓰는 프로세스는 하위 큐로 내려감

 📌 3. **RR의 응답성 저하**

- RR은 공정하지만, **CPU-bound 작업이 많아지면 인터랙티브 작업도 지연됨**
    

🔧 **MLFQ 해결책**:  
→ **인터랙티브(I/O-bound) 작업은 상위 큐에 유지**,  
→ CPU-bound 작업은 하위로 밀려남 → 빠른 응답성 유지

---
 📌 4. **고정된 스케줄링 정책의 비효율**

- FCFS, SJF, RR 등은 **단일 정책**이므로 모든 상황에 최적화될 수 없음
    

🔧 **MLFQ 해결책**:  
→ **큐마다 서로 다른 스케줄링 정책 적용 가능**  
→ 예: 상위 큐는 RR, 하위 큐는 FCFS

---
 ✅ 요약: MLFQ의 핵심 전략

|전략|설명|
|---|---|
|**다단계 큐**|우선순위별로 큐를 나누어 프로세스를 분류|
|**피드백 기반 큐 이동**|CPU 사용 시간/행동에 따라 큐 상하 이동|
|**타임 슬라이스 차등 적용**|상위 큐일수록 타임 슬라이스 짧게 설정|
|**Starvation 방지 (aging)**|오랫동안 대기한 프로세스는 자동으로 상위 큐로 승격|

✅ 한 줄 요약

> **MLFQ는 고정 우선순위, 실행 시간 예측, 공정성/응답성 문제 등 기존 스케줄러의 한계를 다단계 적응형 구조로 해결**하는 고급 스케줄링 알고리즘입니다.
##### FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?
✅ 먼저 결론부터

> ❌ **FIFO는 “모든 상황에서 비효율적인 스케줄러”는 아니며**,  
> ✅ **단순한 작업 흐름, 우선순위 필요 없음, 예측 가능한 처리 흐름이 중요한 환경**에서는 **오히려 적절하고 효과적**입니다.

---
 ✅ FIFO 스케줄러의 특징 다시 보기

| 특성          | 설명                                     |
| ----------- | -------------------------------------- |
| **비선점형**    | 한 번 CPU를 잡으면 끝날 때까지 실행됨                |
| **간단함**     | 스케줄링 로직이 거의 없음 (큐에서 pop)               |
| **공정하지 않음** | 짧은 작업이 긴 작업 뒤에 묶일 수 있음 (Convoy Effect) |
| **예측 가능**   | 도착 순서대로 처리 → 흐름 추적 쉬움                  |
 ✅ FIFO가 유리한 시나리오

📌 1. **배치 처리 시스템 (Batch Processing)**

- 예: 야간 데이터 집계, 보고서 생성, 백업 작업 등
    
- 모든 작업이 비슷한 크기이고 순서대로 처리되어야 할 때
    
- **처리량(Throughput)이 중요**, 응답성은 중요하지 않음
    
 📌 2. **프린터 큐, 디스크 요청 큐 (간단 장치 스케줄링)**
- 프린터: 먼저 온 인쇄 요청부터 순차 처리
- 디스크/테이프 작업: 간단한 순차 처리 → **선점이나 우선순위 부여가 불필요한 상황**
    

 📌 3. **시뮬레이션, 교육용 시스템**

- 알고리즘의 이해 및 비교를 위한 **기초적인 시뮬레이션**
    
- 다른 스케줄러와 비교할 때 기준점으로 활용
    

 📌 4. **실시간성이 불필요한 단일 사용자 시스템**

- ex: **임베디드 시스템**에서 **단순한 요청 큐** 처리    
- 요청의 순서가 논리적으로 중요할 때 (순차적 로깅, 저장)
    

 ✅ FIFO가 적합하지 않은 경우 (보완이 필요한 환경)

| 상황           | 대안 스케줄러                      |
| ------------ | ---------------------------- |
| 사용자 반응 속도 중요 | Round Robin, MLFQ            |
| 작업 크기 차이 큼   | SJF, SRTF                    |
| 실시간 작업 존재    | Priority Scheduling, RTOS 정책 |

 ✅ 예시 정리

| 시나리오           | FIFO 적합 여부 | 이유                 |
| -------------- | ---------- | ------------------ |
| 프린터 인쇄 요청      | ✅ 적합       | 순서대로 출력해야 함        |
| 웹 서버의 요청 처리    | ❌ 부적합      | 짧은 요청이 묶일 수 있음     |
| 야간 배치 로그 분석 작업 | ✅ 적합       | 순서대로 실행, 반응성 필요 없음 |
| 게임 UI 이벤트 처리   | ❌ 부적합      | 응답 속도 중요           |
| 단순 데이터 저장 요청 큐 | ✅ 적합       | 순서대로 처리하는 것이 안전    |
 ✅ 한 줄 요약

> FIFO는 단순하지만 **작업이 동등하고 순차성이 중요한 환경**에서는 오히려 **효율적이고 신뢰성 있는 선택**입니다.  
> 단, **다양한 우선순위·실시간성 요구가 있는 경우에는 부적합**하므로 상황에 맞는 전략이 중요합니다.
##### 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?
✅ 결론부터

> **현대 운영체제(예: Linux, Windows)는 “커널 수준 스레드”를 “독립적인 스케줄링 단위”로 취급**합니다.  
> 즉, **스레드는 프로세스와 동일한 방식으로 스케줄링되며**,  
> 운영체제는 **스레드 단위로 스케줄링 알고리즘(RR, CFS 등)을 적용**합니다.

 ✅ 스레드는 왜 독립적으로 스케줄링될 수 있는가?

- 스레드는 같은 주소 공간을 공유하지만, **각자 고유한 컨텍스트(레지스터, 스택 등)**를 갖습니다.
    
- 커널은 각 스레드를 **독립적인 실행 단위(thread of execution)**로 간주하며,
    
- `task_struct` 같은 **커널 내부 자료구조에서 스레드와 프로세스를 구분 없이 관리**합니다.
    
 ✅ 프로세스 vs 스레드 스케줄링의 실질적 차이

|항목|프로세스|스레드|
|---|---|---|
|주소 공간|독립|같은 프로세스 내에서 공유|
|스케줄링 단위|✅ task_struct|✅ task_struct (스레드도 동일 구조)|
|컨텍스트 전환|주소 공간, 레지스터 등 전부 교체|주소 공간 유지, 레지스터만 교체|
|비용|높음|낮음 (경량 스위칭)|
|사용자 인식 관점|프로그램 실행 단위|실행 흐름 단위|

🔎 즉, **운영체제 입장에서는 “프로세스와 스레드를 똑같이 스케줄링”하되**,  
**컨텍스트 전환 비용과 주소 공간 공유 여부만 다를 뿐입니다.**

---
 ✅ 사용자 수준 스레드(User-Level Thread) 예외
- 만약 스레드가 **사용자 공간에서 관리되는 경우 (예: green thread)**라면,
- 커널은 해당 스레드를 **단일 프로세스처럼만 인식**하고 스케줄링은 사용자 라이브러리가 처리함
    
- ex: Python의 asyncio, JavaScript의 이벤트 루프, Go의 goroutine
    

➡ 이 경우는 **스레드 자체가 커널에 알려지지 않으므로 커널 스케줄링 대상이 아님**

---

| 질문                    | 답변                                      |
| --------------------- | --------------------------------------- |
| 스레드는 다른 방식으로 스케줄링되는가? | ❌ 아니요. 커널 수준에서는 **프로세스와 동일하게 스케줄링됩니다.** |
| 차이점이 있다면?             | 컨텍스트 전환 시 주소 공간 교체 여부, 비용 차이 정도         |
| 사용자 수준 스레드는 예외인가요?    | ✅ 네, 사용자 수준 스레드는 커널이 스케줄링하지 않습니다.       |

---
🔔 한 줄 요약

> **커널 수준 스레드는 프로세스와 똑같이 스케줄링 대상이 되며,  
> 운영체제는 이를 별개의 실행 단위로 취급합니다.**  
> 다만, 사용자 수준 스레드는 운영체제가 인식하지 않기 때문에 별도 스케줄링 방식이 적용됩니다.
##### 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?
✅ 결론

> **아니요. 유저 스레드와 커널 스레드는 동일한 스케줄링 알고리즘을 사용하지 않습니다.**

- **커널 스레드**는 운영체제가 직접 관리하고, **운영체제의 스케줄러(CFS 등)**가 스케줄링합니다.
    
- **유저 스레드**는 사용자 라이브러리/런타임이 관리하며, **전혀 다른 자체적인 스케줄링 로직**을 가집니다.
    

---
✅ 개념 정리

|항목|유저 스레드 (User-Level Thread, Green Thread)|커널 스레드 (Kernel-Level Thread)|
|---|---|---|
|관리 주체|사용자 공간 라이브러리 (예: libpthread, goroutine runtime)|커널|
|커널 인식|❌ 인식 못 함|✅ 인식함|
|스케줄링|사용자 공간에서 **자체 알고리즘** 사용|운영체제의 **CPU 스케줄러** 사용|
|컨텍스트 스위칭|사용자 공간에서만 발생 (빠름)|커널을 통해 발생 (비용 큼)|
|예시|Go의 goroutine, Java green thread|POSIX Thread (pthreads), Java Thread|

---
✅ 스케줄링 알고리즘의 차이
 📌 커널 스레드 스케줄링

- Linux → **CFS(Completely Fair Scheduler)** 등 커널 수준 알고리즘 사용
    
- 우선순위, 타임슬라이스, `nice`, 실시간 정책 등 반영
    
- **Ready Queue 전체를 운영체제가 관리**
    

📌 유저 스레드 스케줄링

- Go → **M:N 스케줄링**, GOMAXPROCS, work stealing
    
- JavaScript → 이벤트 루프 기반 (사실상 협력적 스케줄링)
    
- Python (asyncio) → 단일 스레드에서 **태스크 큐 + 이벤트 드리븐 방식**
    

➡ 유저 스레드는 **비선점형(cooperative)** 방식인 경우도 많음

---

✅ 예시: Go의 M:N 스케줄링

- Go runtime은 사용자 스레드(G)를 **논리 CPU(M)에 동적으로 배분**
    
- 내부적으로 **우선순위 기반이 아닌 work-stealing 알고리즘**을 사용
    
- 커널은 Go 런타임이 띄운 **OS 쓰레드(M)**만 인식함
    

---
✅ 실제 차이 발생 예

|상황|유저 스레드|커널 스레드|
|---|---|---|
|한 스레드가 블로킹 I/O 수행|전체 스레드 멈춤 (1:1 매핑 없으면)|다른 스레드는 계속 실행 가능|
|스레드가 많아짐|성능 좋음 (경량 스레드 많음)|오버헤드 증가 가능성 있음|
|우선순위 조절|사용자 코드에서 직접 제어|운영체제의 스케줄러가 제어|
✅ 한 줄 요약

> **유저 스레드는 사용자 공간에서 자체 스케줄링 알고리즘을 사용하며**,  
> **커널 스레드는 운영체제의 CPU 스케줄러에 의해 스케줄링됩니다.**  
> 따라서 **사용하는 스케줄링 알고리즘은 전혀 다릅니다.**

### 8. 뮤텍스와 세마포어의 차이점은 무엇인가요?
##### 설명
✅ 요약 정리: 뮤텍스 vs 세마포어

| 항목      | **뮤텍스 (Mutex)**                 | **세마포어 (Semaphore)**                     |
| ------- | ------------------------------- | ---------------------------------------- |
| 기본 의미   | **Mutual Exclusion (상호 배제)**    | **Signal/Wait 기반 동기화 카운터**               |
| 값의 범위   | 0 또는 1 (Binary Lock)            | 0 이상인 정수 (Counting 가능)                   |
| 목적      | **임계 영역 보호 (Lock/Unlock)**      | **리소스 개수 관리 or 시그널링**                    |
| 소유권     | ✅ 소유권 있음 (Lock한 스레드만 Unlock 가능) | ❌ 소유권 없음 (다른 스레드가 Post 가능)               |
| 쓰는 방식   | `lock()` / `unlock()`           | `wait()` / `signal()` (또는 `P()` / `V()`) |
| 사용 예시   | 한 번에 하나만 접근해야 하는 공유 자원          | 리소스 제한 큐, 연결된 작업 흐름 제어                   |
| 데드락 가능성 | 있음                              | 있음                                       |

---
 ✅ 동작 개념 비교

 📌 뮤텍스 (Mutex)

- **임계 구역(critical section)**을 보호하기 위해 사용
    
- 하나의 스레드만 **lock**을 얻을 수 있음 → 다른 스레드는 대기
    
- **unlock은 lock한 스레드만 가능**
    
 📌 세마포어 (Semaphore)
- **정수값 기반의 리소스 카운터** 개념
- `wait()` → 값 감소 (0이면 블로킹)  
    `signal()` → 값 증가 (대기 중인 스레드 깨움)
    


➡ **Binary Semaphore**는 값이 0 또는 1 → Mutex처럼 사용 가능  
➡ **Counting Semaphore**는 값이 N → N개의 동시 접근 허용

---
 ✅ 실전 예시 비교

| 시나리오                          | 추천 도구                | 이유             |
| ----------------------------- | -------------------- | -------------- |
| 한 개의 파일에 하나의 스레드만 접근          | ✅ Mutex              | 1명만 접근해야 함     |
| 프린터가 3대 있는 경우, 스레드가 사용 요청     | ✅ Counting Semaphore | 동시에 3명까지 접근 가능 |
| Thread A가 Thread B에게 작업 완료 알림 | ✅ Binary Semaphore   | 시그널 전달 용도      |

 ✅ 소유권 차이 설명

- **Mutex**: 누가 `lock()`했는지를 기억 → **lock한 스레드만 unlock 가능**
    
- **Semaphore**: 누가 `wait()`했는지 상관없이 **다른 스레드가 `signal()` 가능**
    

 ✅ 한 줄 요약

> 🔹 **Mutex는 “하나만 들어올 수 있는 문”**,  
> 🔹 **Semaphore는 “입장 인원 수를 세는 정원 제한자”**입니다.  
> Mutex는 소유권이 있고 상호배제에, Semaphore는 자원 관리나 시그널링에 적합합니다.

##### 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
**이진 세마포어(Binary Semaphore)**와 **뮤텍스(Mutex)**는 모두 **동시에 하나의 스레드만 공유 자원에 접근하도록 제어하는 동기화 도구**입니다.  
겉보기엔 유사하지만, **개념적 목적, 소유권, 사용 방식**에서 중요한 차이점이 있습니다.

---
 ✅ 핵심 요약

| 항목        | **이진 세마포어 (Binary Semaphore)** | **뮤텍스 (Mutex)**              |
| --------- | ------------------------------ | ---------------------------- |
| 값의 범위     | 0 또는 1                         | 0 또는 1                       |
| 목적        | **시그널 전달 또는 리소스 제한**           | **상호 배제 (Mutual Exclusion)** |
| 소유권       | ❌ 없음 (누구나 `signal` 가능)         | ✅ 있음 (lock한 스레드만 unlock 가능)  |
| 사용 예      | **스레드 간 이벤트 알림**, 리소스 관리       | **임계 영역 보호**                 |
| 구현 방식     | OS 커널 or 사용자 공간 라이브러리          | 일반적으로 커널 수준                  |
| 데드락 감지 지원 | ❌ 없음                           | ✅ 일부 OS에서 가능                 |
| 성능        | 약간 더 빠를 수 있음 (구조 단순)           | 약간의 커널 비용 있음                 |

---
✅ 차이점 자세히 설명

 📌 1. **소유권 (Ownership)**

- **뮤텍스**
    
    - `lock()`한 **스레드만** `unlock()` 가능
        
    - 잘못된 스레드가 unlock 시 **예외 또는 undefined behavior**
        
- **이진 세마포어**
    
    - **어떤 스레드든** `signal()` 가능
        
    - `wait()`한 스레드가 아닌 다른 스레드가 `signal()` 가능 → **시그널링 용도로 사용 가능**
        

---
📌 2. **주 사용 목적의 차이**

| 상황                               | 적절한 도구        |
| -------------------------------- | ------------- |
| 하나의 공유 자원을 여러 스레드가 사용 → 상호 배제 필요 | ✅ **뮤텍스**     |
| 스레드 간 작업 순서 조정, 알림 전달            | ✅ **이진 세마포어** |

 📌 3. **에러 감지와 안전성**

- 뮤텍스는 잘못된 unlock에 대해 **오류를 감지하거나 디버깅 기능을 제공**하는 경우가 많음
    
- 세마포어는 단순 카운터 → 실수로 `signal()`을 여러 번 호출해도 감지 어렵고 **버그 유발 가능성 높음**
    
 ✅ 한 줄 요약

> 🔹 **이진 세마포어는 시그널링 또는 리소스 제어 용도**,  
> 🔹 **뮤텍스는 임계 영역 보호용이며, 소유권이 있어 더 안전하고 엄격한 제어가 가능합니다.**
##### Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
✅ Spin Lock이란?

> **락이 풀릴 때까지 루프를 돌며(lock이 열릴지 계속 검사) 기다리는 기법**  
> → 락을 얻을 수 없으면 **그 자리에서 계속 "바쁘게" 기다림 (Busy Waiting)**

 ✅ 장점 (👍)

| 항목                          | 설명                                                    |
| --------------------------- | ----------------------------------------------------- |
| ✅ **컨텍스트 스위칭 없음**           | 락이 곧 풀릴 것으로 예상될 때 스레드를 Block 시키지 않고 기다림 → 문맥 전환 비용 없음 |
| ✅ **락 대기 시간이 매우 짧은 경우에 빠름** | 임계 구역이 짧고 락을 금방 얻는 경우 → 빠른 반응                         |
| ✅ **멀티코어 환경에 적합**           | 다른 CPU가 락을 곧 풀 수 있으므로 기다리는 것이 더 효율적일 수 있음             |
 ✅ 단점 (👎)

| 항목                             | 설명                                                                           |
| ------------------------------ | ---------------------------------------------------------------------------- |
| ❌ **CPU 자원 낭비 (Busy Waiting)** | 락이 오래 유지되면, 그 시간 동안 CPU를 그냥 소비함                                              |
| ❌ **락 보유자와 동일 코어 경쟁 시 역효과**    | 락을 가진 쓰레드가 실행되어야 락을 풀 수 있는데, 락을 기다리는 스레드가 CPU를 차지하면 오히려 락 보유자가 실행되지 못함       |
| ❌ **싱글코어 환경에서 최악**             | 락을 기다리는 스레드가 CPU를 점유하면, 락을 가진 스레드는 실행 기회조차 없음 → **무한 대기 (Live Lock)** 가능성 있음 |

---
 ✅ Spin Lock 단점 해결 방법 (🔧)

📌 1. **Hybrid Lock (Spin + Sleep)**

> 일정 시간까지는 Spin, 그 이후에는 Sleep 또는 Block

- 일정 시간 동안만 바쁘게 대기하고, 이후에는 CPU 양보
    
- Go의 runtime이나 Java의 일부 락 구현에 사용됨
    

---
 📌 2. **Yielding (CPU 양보)**

> 일정 루프마다 `sched_yield()` 호출하여 **다른 스레드에게 CPU 양보**

📌 3. **Backoff 기법**

> 매 반복마다 기다리는 시간 점진적으로 증가 → **경쟁 줄이기**

 ✅ Spin Lock 사용이 적절한 경우

| 상황                         | 이유                                   |
| -------------------------- | ------------------------------------ |
| 임계 구역이 **매우 짧고 자주 락이 해제됨** | Busy Waiting 비용보다 문맥 전환 비용이 더 큼      |
| **멀티코어 환경**                | 락 보유자와 락 대기자가 다른 CPU에서 실행 가능         |
| OS 커널 내부의 짧은 락             | 컨텍스트 스위칭이 부담되므로 사용됨 (Linux spinlock) |
|                            |                                      |

---
✅ 한 줄 요약

> **Spin Lock은 락 대기 시간이 짧을 때 매우 빠르지만, 오래 기다리면 CPU를 낭비합니다.**  
> 이를 해결하기 위해 Hybrid Lock, Backoff, Yielding 기법 등이 사용됩니다.
##### 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?
✅ 커널 기반 락 + 시스템 콜의 장단점
 👍 장점

| 항목                      | 설명                                                                               |
| ----------------------- | -------------------------------------------------------------------------------- |
| ✅ **신뢰성과 안정성 보장**       | 커널이 락의 상태와 대기 큐를 정확하게 관리함                                                        |
| ✅ **정확한 스케줄링 연동**       | 락 대기 중인 스레드를 블로킹 상태로 전환 → CPU 낭비 없음                                              |
| ✅ **다중 프로세스 간 공유 가능**   | 커널 자원이므로, 프로세스 간 락 동기화에도 사용 가능 (`pthread_mutex_t` with `PTHREAD_PROCESS_SHARED`) |
| ✅ **데드락/우선순위 역전 감지 가능** | 일부 OS에서 대응 로직 제공 (`priority inheritance` 등)                                      |
 👎 단점

| 항목                   | 설명                                  |
| -------------------- | ----------------------------------- |
| ❌ **시스템 콜 오버헤드**     | 유저 → 커널 모드 전환에 따른 비용 발생             |
| ❌ **컨텍스트 스위칭 발생 가능** | 락이 안 잡히면 스레드는 블로킹되고, 커널은 다른 스레드로 전환 |
| ❌ **짧은 임계 구역에 비효율적** | 아주 짧은 락일 경우 시스템 콜이 오히려 병목이 됨        |

---
✅ 단점 해결 방법 (대안)

📌 1. **유저 공간 락 (User-space Lock)**

- 시스템 콜 없이 유저 공간에서만 동작하는 락
    
- 예: **Spin Lock**, `std::atomic_flag` 등
    

- **장점**: 매우 빠름 (시스템 콜 없음)
    
- **단점**: Busy waiting → CPU 낭비
    

➡ 짧은 임계 구역에서는 오히려 유리

---

📌 2. **Hybrid Lock (Fast Path + Slow Path)**

> 유저 공간에서 먼저 시도 → 실패 시에만 시스템 콜 (커널 락 호출)

- 예: **futex (Fast Userspace Mutex)** in Linux

- **Fast path**: 유저 공간에서 락을 얻음 → 매우 빠름
    
- **Slow path**: 실패했을 때만 커널에 요청 → 시스템 콜 줄이기
    

➡ **현대 POSIX `pthread_mutex_t`도 내부적으로 futex 기반**

---
📌 3. **Lock-Free / Wait-Free 기법**

- 락 없이 CAS(Compare-And-Swap) 등 원자 연산으로 동기화
    
- 예: concurrent queue, lock-free stack
    
- 장점: 컨텍스트 스위칭, 시스템 콜 전혀 없음
    
- 단점: 구현 복잡, 일부 문제(ABA 문제 등) 존재
    

 ✅ 예시 요약: `pthread_mutex_lock()`

- 내부 구조:
    
    1. **유저 공간에서 atomic 연산 시도**
        
    2. 실패 시 → `futex_wait()` (시스템 콜)
        
    3. 락 해제 → `futex_wake()`로 대기 스레드 깨움
        

---
 ✅ 한 줄 요약

> **커널 락은 안정성과 멀티 프로세스 지원 면에서 뛰어나지만, 시스템 콜 비용과 컨텍스트 스위칭이 단점입니다.**  
> 이를 해결하기 위해 **유저 공간 락**, **futex 기반 Hybrid Lock**, **락프리 구조** 등의 대안이 널리 사용됩니다.

### 9. Deadlock 에 대해 설명해 주세요.
##### 설명
**Deadlock(교착 상태)**은 **둘 이상의 프로세스 또는 스레드가 서로 상대방의 자원을 기다리느라 영원히 진행되지 못하는 상태**를 말합니다.  
즉, **서로 락을 쥐고 기다리기만 하고, 아무도 작업을 끝내지 못하는 상황**입니다.

 ✅ 정의

> **Deadlock은** 여러 프로세스가 **서로 필요한 자원을 점유한 채**,  
> 서로 **상대가 자원을 놓아줄 때까지 기다리면서 무한 대기에 빠지는 현상**입니다.

---
 ✅ 데드락 발생 조건 (Coffman의 4가지 조건)

> 이 네 가지 조건이 **동시에 만족될 때** 데드락이 발생합니다:

| 조건                             | 설명                          |
| ------------------------------ | --------------------------- |
| ① **상호 배제 (Mutual Exclusion)** | 자원은 한 번에 하나의 프로세스만 사용할 수 있다 |
| ② **점유 대기 (Hold and Wait)**    | 자원을 점유한 채, 다른 자원을 기다린다      |
| ③ **비선점 (No Preemption)**      | 할당된 자원은 강제로 빼앗을 수 없다        |
| ④ **순환 대기 (Circular Wait)**    | 자원이 서로 순환적으로 기다리는 형태를 이룬다   |

 ✅ 데드락 방지 방법

| 전략                                  | 설명                             |
| ----------------------------------- | ------------------------------ |
| ❌ **조건 자체를 깨뜨리기**                   | 위 4가지 중 하나라도 제거하면 데드락 방지 가능    |
| ✅ **순서 보장 (Lock Ordering)**         | 락을 항상 **같은 순서**로 요청 → 순환 대기 방지 |
| ✅ **타임아웃/재시도**                      | 일정 시간 내 락을 못 얻으면 **포기하고 되돌아감** |
| ✅ **자원 요청 전부 한 번에**                 | `Hold and Wait` 방지             |
| ✅ **Deadlock Detection + Recovery** | 발생을 허용하되, **탐지 후 프로세스 종료/롤백**  |

 ✅ 실전에서의 예

| 예시            | 설명                                |
| ------------- | --------------------------------- |
| **은행 이체 시스템** | 계좌 A 락 + B 락 요청 순서가 다르면 데드락 발생 가능 |
| **DB 트랜잭션**   | 두 트랜잭션이 서로의 Row를 락 걸고 기다릴 때       |
| **멀티스레드 락**   | 두 락을 서로 다른 순서로 걸면 데드락 발생 가능       |
 ✅ 한 줄 요약

> 🔒 **Deadlock은 여러 프로세스가 서로 자원을 점유한 채, 서로의 해제를 기다리며 무한정 대기하는 상태**입니다.  
> 이를 막기 위해선 락 순서 고정, 타임아웃, 자원 선요청 등의 전략이 필요합니다.
##### Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
| 조건                             | 설명                          |
| ------------------------------ | --------------------------- |
| ① **상호 배제 (Mutual Exclusion)** | 자원은 한 번에 하나의 프로세스만 사용할 수 있다 |
| ② **점유 대기 (Hold and Wait)**    | 자원을 점유한 채, 다른 자원을 기다린다      |
| ③ **비선점 (No Preemption)**      | 할당된 자원은 강제로 빼앗을 수 없다        |
| ④ **순환 대기 (Circular Wait)**    | 자원이 서로 순환적으로 기다리는 형태를 이룬다   |
##### 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
✅ 각 조건이 빠질 때의 시나리오 예시

📌 ① **상호 배제가 없다**

- 여러 프로세스가 동시에 같은 자원에 접근 가능 (예: 읽기 전용 파일)
    
- 🔒 락 자체가 없으므로 **교착될 일이 없음**

---

📌 ② **점유 대기가 없다**

- 프로세스가 자원을 점유하기 전에 **항상 필요한 모든 자원을 한 번에 요청**
- 즉, **자원 하나만 들고 다른 자원을 기다리는 상황이 없음**
- ➡ 교착 상태로 갈 수 있는 경로 차단됨
    
 📌 ③ **비선점이 없다**
- 프로세스가 점유한 자원을 **운영체제가 강제로 회수 가능**
- 누가 오래 점유하고 있어도, OS가 자원을 뺏어버리고 다른 프로세스에 넘겨줌
- ➡ 무한 대기 불가능 → **교착 종료**
    
 📌 ④ **순환 대기가 없다**
- 자원을 항상 정해진 **순서대로 요청하도록 강제**
- 예: 모든 프로세스는 항상 자원을 A → B → C 순으로만 요청
- ➡ 사이클(순환) 발생 불가능 → Deadlock도 불가능
    
✅ 핵심 결론

> 💡 **Deadlock은 네 가지 조건이 "모두 만족"해야만 발생하며**,  
> 💡 그 중 **단 하나라도 깨지면**  
> → 교착 상태로 이어지는 논리적/구조적 경로 자체가 **차단되기 때문**입니다
##### 어떤 방식으로 예방할 수 있을까요?
1. **Deadlock 예방 (Prevention)**

> **4가지 발생 조건 중 하나라도 ‘사전에 깨뜨려서’**  
> **Deadlock이 절대 발생하지 않도록 만드는 방식**

 🔧 조건별 예방 방법

| Deadlock 조건 | 예방 방법 (조건 깨뜨리기)                                  |
| ----------- | ------------------------------------------------ |
| **상호 배제**   | 자원을 공유 가능하게 설계 (불가능한 경우도 많음)                     |
| **점유 대기**   | 자원 요청 전에 **모두 한꺼번에 요청**하도록 강제                    |
| **비선점**     | 자원을 기다리는 프로세스가 있다면, **점유 중인 자원을 강제로 회수** (선점 허용) |
| **순환 대기**   | 자원에 **고정된 요청 순서**를 정해두고, 항상 그 순서대로만 요청           |

> ✅ 예방의 핵심: **Deadlock이 생길 수 있는 상황 자체를 "미리 막는다"**

---
 ✅ 2. **Deadlock 회피 (Avoidance)**

> 시스템이 현재 상태와 요청을 분석해서  
> **Deadlock이 발생하지 않을 것 같을 때만 자원 할당**

 🔧 대표 방법: **은행가 알고리즘 (Banker's Algorithm)**

- 각 프로세스가 **최대 자원 사용량을 미리 알려줌**
    
- 자원 할당 시, Deadlock이 발생하지 않는 **안전 상태(Safe State)**로 유지되는 경우에만 할당
    
> ✅ 회피의 핵심: **발생 가능성은 허용하지만, 위험하면 차단**

---
✅ 3. **Deadlock 탐지 및 복구 (Detection & Recovery)**

> **Deadlock이 발생하는 것을 허용하되**,  
> 정기적으로 상태를 점검하고, **발생 시 해결**

 🔧 탐지 방법

- **자원 할당 그래프(Resource Allocation Graph)**에서 **사이클 존재 여부** 검사
    
- **대기-점유 그래프(Wait-for Graph)** 사용
    
🔧 복구 방법
- **Deadlock 프로세스 중단**
- **자원 강제 회수 (Rollback or Preemption)**
- 우선순위 기반으로 피해를 최소화
    

> ✅ 이 방식은 특히 **장기 실행 배치 시스템이나 OS 커널에서 현실적**

---
 ✅ 4.  **Deadlock 무시 (Ignore)**

> 운영체제가 Deadlock을 아예 **관리하지 않음**

- 대표적 예: **UNIX, Linux** – Deadlock 회피나 탐지 하지 않음
    
- 대신, **개발자가 직접 방지/처리**해야 함
    
 ✅ 정리 요약

|전략|설명|장점|단점|
|---|---|---|---|
|**예방 (Prevention)**|4조건 중 최소 1개를 제거|확실하게 방지|자원 활용률 낮아질 수 있음|
|**회피 (Avoidance)**|시스템 상태 분석 후 자원 할당|안전 상태 보장|사전 정보 필요, 계산 복잡|
|**탐지 + 복구**|발생 후 정리|자원 활용률 높음|복구가 복잡하고 위험 가능성|
|**무시**|그냥 무시하고 알아서 해결하게 함|구현 단순|위험도 있음, 개발자 책임|

---
🔔 한 줄 요약

> **Deadlock을 예방하려면 4가지 조건 중 하나를 깨뜨리는 전략을 쓰거나**,  
> **발생 가능성을 예측/탐지하여 회피 또는 복구하는 방식이 있습니다.**  
> 상황에 따라 성능/안정성/단순성 간의 **트레이드오프**가 존재합니다.
##### 왜 현대 OS는 Deadlock을 처리하지 않을까요?
✅ 결론부터

> **현대 운영체제가 Deadlock을 처리하지 않는 이유는 "비용 대비 실익이 작기 때문"입니다.**  
> Deadlock 회피/탐지/복구는 **복잡하고 비싸며**,  
> 대신 **개발자 수준에서 잘 설계하면 충분히 방지할 수 있기 때문입니다.**

---
 ✅ 주요 이유 정리

 📌 1. **Deadlock 탐지/회피는 시스템 비용이 큼**

| 이유          | 설명                                                  |
| ----------- | --------------------------------------------------- |
| 💥 상태 추적 필요 | 모든 자원/프로세스 상태를 실시간으로 분석해야 함 (그래프 관리, 상태 검사)         |
| 💥 성능 저하    | 탐지 알고리즘은 `O(n^2)` 이상인 경우도 있음 → 실시간 OS나 고성능 시스템에 치명적 |
| 💥 불확실성     | 자원의 점유/요청 순서를 예측하거나 선언하도록 강제해야 함 → **비현실적 전제** 필요   |

---
 📌 2. **Deadlock 발생 빈도가 낮음**

- 대부분의 시스템에서는 자원 점유 패턴이 잘 통제됨
    
- 개발자들이 **락 순서 고정(lock ordering)** 등으로 예방 가능
    
- 운영체제보다 **애플리케이션 설계 수준**에서 처리하는 게 더 현실적
    

 📌 3. **Deadlock 복구는 매우 어렵고 위험함**

| 문제점                    | 설명                                     |
| ---------------------- | -------------------------------------- |
| ❌ 어떤 프로세스를 죽일지 판단이 어려움 | 중요 프로세스일 경우 시스템 전체에 영향을 줄 수 있음         |
| ❌ 자원 강제 회수는 일관성 손상 가능  | 트랜잭션 중인 DB, 네트워크 세션 등은 **롤백 불가 or 위험** |

 📌 4. **책임의 분산: 커널이 아닌 개발자가 예방하도록 설계**

- `pthread_mutex`나 `Java synchronized` 등에서는 개발자가 락 순서를 설계해야 함
    
- 커널은 락 자체만 제공하고 **정책은 개발자가 설계**
    
- **Linux의 철학**: 단순하고 빠르게 → "Deadlock은 네 책임"
    

 📌 5. **실시간성·간결성 우선 정책**

- **RTOS(실시간 운영체제)**에서는 데드락 탐지로 인한 **타이밍 예측 불가능성**은 치명적
    
- 커널은 가능한 한 단순하고 결정론적으로 유지해야 함
    

---
 ✅ 그래서 어떻게 하느냐?

현대 운영체제는 대신 다음을 제공합니다:

| 대체 수단                        | 설명                                  |
| ---------------------------- | ----------------------------------- |
| `pthread_mutex_trylock()`    | 락을 기다리지 않고 즉시 실패 → 개발자가 대처          |
| `timeout` 기반 API             | 일정 시간 내 락 실패 시 직접 처리 가능             |
| lock ordering, no preemption | 개발자가 정해진 순서로 락 획득 → 순환 대기 방지        |
| 경량 락 (futex, spin lock)      | 빠른 락 획득 시도 후 재시도 → Busy waiting 최적화 |

 ✅ 한 줄 요약

> 현대 운영체제는 **성능, 단순성, 실시간성**을 이유로 Deadlock을 **탐지하거나 방지하지 않고**,  
> **락 사용은 개발자의 책임**으로 위임합니다.  
> 대신, 효율적인 락 API와 락-free 설계를 위한 도구들을 제공합니다.
##### Wait Free와 Lock Free를 비교해 주세요.
**Wait-Free**와 **Lock-Free**는 둘 다 **비동기(Non-blocking)** 동기화 기법입니다.  
즉, **락을 사용하지 않고 여러 스레드가 동시에 자원에 접근하는 경우에도 안전하게 동작하도록 보장하는 방식**입니다.  
하지만 두 개념은 **보장 수준**에서 명확한 차이가 있습니다.

 ✅ 요약 비교: Wait-Free vs Lock-Free

|항목|**Wait-Free**|**Lock-Free**|
|---|---|---|
|정의|**모든 스레드가 유한한 시간 안에 작업을 끝냄**|**전체 시스템은 진행되지만, 어떤 스레드는 굶을 수 있음**|
|공정성(Fairness)|✅ 매우 높음 (모든 스레드가 반드시 완료됨)|❌ 보장하지 않음 (특정 스레드는 계속 실패 가능)|
|진행 보장|개별 스레드의 진행 보장|전체 시스템의 진행만 보장|
|구현 난이도|⛔ 매우 어려움 (복잡한 알고리즘 필요)|⚠️ 상대적으로 쉬움|
|성능|중간 ~ 높음 (경우에 따라 오버헤드 존재)|일반적으로 빠름|
|활용도|실시간 시스템 등 절대 지연이 허용되지 않는 환경|일반적인 동시성 자료구조 구현에 많이 사용|
|예시|일부 lock-free 큐에서 per-thread 슬롯 구조|Java `ConcurrentLinkedQueue`, Go map 등|

---
✅ 그림으로 직관적으로 이해하기

- **Lock-Free**: 전체 줄은 앞으로 나아가지만, 나 하나는 계속 줄에서 밀릴 수 있음
    
- **Wait-Free**: 나 포함 **모든 사람**이 언젠가는 반드시 전진함
    
 ✅ 실전 예시

 📌 Lock-Free Stack (예: Treiber Stack)

- 다른 스레드가 먼저 성공할 수도 있음
    
- 내가 반복적으로 실패할 수 있음 (하지만 전체 시스템은 진행됨)
    

 📌 Wait-Free Stack (예: per-thread 슬롯 구조)

- 각 스레드가 자신의 슬롯을 갖고, 병렬로 작업을 수행한 뒤 합치는 방식
    
- 절대 굶지 않도록 설계됨 → **모든 스레드의 작업이 유한 시간 내 완료됨** 보장
    
✅ 정리 요약

|관점|Lock-Free|Wait-Free|
|---|---|---|
|누구는 실패할 수 있는가|✅ Yes|❌ No (모두 성공 보장)|
|시스템 전체 진행 보장|✅ Yes|✅ Yes|
|개별 스레드 진행 보장|❌ No|✅ Yes|
|구현 난이도|⚠️ 비교적 낮음|⛔ 매우 높음|

 ✅ 한 줄 요약

> **Lock-Free**는 "전체 시스템은 진행됨",  
> **Wait-Free**는 "모든 스레드가 반드시 진행됨"을 보장합니다.  
> Wait-Free가 더 강력하지만 그만큼 **복잡하고 구현 난이도도 높습니다.**

### 10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.
##### 설명
✅ 프로그램 실행 과정 요약
 1️⃣ **전처리 (Preprocessing)**

- `#include`, `#define` 등 **전처리 지시문 처리**
    
- 매크로 치환, 헤더 파일 포함
    
- 결과: **전처리된 소스 파일**
    
 2️⃣ **컴파일 (Compilation)**

- 전처리된 소스를 기계어 명령으로 번역 (하지만 완전한 실행 파일은 아님)
    
- 각 함수/변수의 주소는 아직 미정 (심볼로 남음)
    
- 결과: **어셈블리 코드 → 오브젝트 파일(.o)**
    
 3️⃣ **링크 (Linking)**

- 여러 오브젝트 파일(.o)과 라이브러리를 결합
    
- 심볼(함수/변수 이름 등)을 실제 주소로 연결
    
- 결과: **실행 파일(.exe, a.out 등)**
    
4️⃣ **로딩 (Loading) 및 실행**

- OS가 실행 파일을 **메모리에 적재**
    
    - 코드 영역, 데이터 영역, 스택, 힙 구성
        
- **프로세스를 생성**하고, **`main()` 함수부터 실행**
    
 ✅ 한 줄 요약

> 프로그램은 **전처리 → 컴파일 → 링크 → 로딩** 과정을 거쳐 실행되며,  
> 최종적으로 운영체제가 **프로세스를 생성하고 main()부터 실행**시킵니다.
> 
##### 링커와, 로더의 차이에 대해 설명해 주세요.
**링커(Linker)**와 **로더(Loader)**는 모두 실행 파일을 만들고 실행하는 데 필수적인 구성 요소지만,  
**역할과 동작 시점**에서 명확히 구분됩니다.

---
 ✅ 핵심 차이 요약

|항목|**링커 (Linker)**|**로더 (Loader)**|
|---|---|---|
|**동작 시점**|**컴파일 이후, 실행 전**|**프로그램 실행 직전 (운영체제가 실행)**|
|**역할**|여러 개의 **오브젝트 파일을 하나의 실행 파일로 생성**|실행 파일을 **메모리에 적재하고 실행 준비**|
|**결과물**|실행 파일 (`a.out`, `.exe`) 생성|프로세스 생성 및 `main()` 진입점 실행|
|**관리 대상**|함수 주소, 외부 심볼, 라이브러리 연결|메모리 주소 공간, 스택/힙/코드/데이터 배치|
|**예**|`gcc main.o util.o -o app` → 링커 호출|`./app` 실행 시 OS의 `execve()` → 로더 수행|

---
 ✅ 링커(Linker)란?

> 링커는 **오브젝트 파일(.o)**과 **라이브러리(.a, .so)**를  
> **하나의 실행 가능한 바이너리로 묶는 도구**입니다.

 📌 주요 기능

- 함수/변수 등의 **심볼(Symbol)**을 연결
    
- 참조된 외부 함수 주소를 채움
    
- 여러 개의 오브젝트 파일/라이브러리 결합
    

---
 ✅ 로더(Loader)란?

> 로더는 **운영체제의 일부**로, 실행 파일을 **메모리에 적재하고, 프로세스로 실행시키는 역할**을 합니다.

 📌 주요 기능

- 실행 파일 구조 해석 (예: ELF, PE)
    
- 코드/데이터/스택/힙 영역을 메모리에 배치
    
- `main()`의 주소로 점프하여 실행 시작
    

 ✅ 비유로 이해하기

|역할|설명|
|---|---|
|**링커**|**부품들을 조립해서 완성된 제품**을 만드는 사람 (제조 단계)|
|**로더**|제품을 **상자에서 꺼내 사용 준비**를 하고 **작동시키는 역할** (운영 단계)|

---
 ✅ 한 줄 요약

> 🔧 **링커는 실행 파일을 만드는 도구**,  
> 🚀 **로더는 실행 파일을 메모리에 적재하고 실행시키는 운영체제의 구성 요소**입니다.  
> 링커는 "조립", 로더는 "실행"이라고 생각하시면 됩니다.
##### 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
좋은 질문입니다.  
**컴파일 언어(Compiled Language)**와 **인터프리터 언어(Interpreted Language)**는  
**“어떻게 실행되는가”**, 즉 **소스 코드를 기계어로 바꾸는 방식**에 따라 구분됩니다.

---
 ✅ 핵심 차이 요약

|항목|**컴파일 언어**|**인터프리터 언어**|
|---|---|---|
|**실행 방식**|전체 소스 코드를 **기계어로 번역 후 실행**|소스 코드를 **한 줄씩 해석하며 실행**|
|**실행 속도**|✅ 빠름 (기계어 실행)|❌ 느림 (계속 해석하며 실행)|
|**번역 시점**|실행 **이전**에 번역 (컴파일 타임)|실행 **도중**에 번역 (런타임)|
|**결과물**|바이너리 실행 파일 생성 (`.exe`, `a.out`)|실행 파일 없음, 인터프리터가 직접 실행|
|**에러 처리**|컴파일 시 한꺼번에 검사|실행 도중 한 줄씩 검사|
|**대표 언어**|C, C++, Rust, Go|Python, JavaScript, Ruby, Bash|
 ✅ 중간 형태도 존재 (혼합형)

- **Java, C# 등은 컴파일 + 인터프리터 혼합형**
    
    - Java: 소스 → 바이트코드 → JVM이 해석/실행 (또는 JIT 컴파일)
        
    - Python도 내부적으로 바이트코드 컴파일 후 인터프리트
        

---
 ✅ 한 줄 요약

> **컴파일 언어는 실행 전 전체를 번역하여 빠르게 실행**,  
> **인터프리터 언어는 실행 중 해석하므로 느리지만 유연하고 빠르게 개발 가능**합니다.
##### JIT에 대해 설명해 주세요.
✅ JIT 컴파일이란?

> **JIT(Just-In-Time)** 컴파일은  
> 프로그램 실행 **도중에** 바이트코드나 중간 코드를 **기계어로 동적으로 변환**하는 방식입니다.

---
 ✅ 전통적인 실행 방식과 비교

|방식|특징|
|---|---|
|**컴파일 방식 (C 등)**|전체 코드를 **실행 전** 미리 기계어로 변환 → 빠르지만 유연성 낮음|
|**인터프리터 방식 (Python 등)**|한 줄씩 해석하며 실행 → 느리지만 유연|
|✅ **JIT 컴파일 (Java, C#)**|**실행 중에 필요한 부분만 컴파일하여 실행** → 빠르면서도 동적 특성 유지|

---
 ✅ JIT 컴파일 흐름 (예: Java)

1. Java 소스 코드 → `javac` → **바이트코드 (.class)**
    
2. 실행 시 JVM이 바이트코드를 해석 (인터프리트)
    
3. 자주 실행되는 코드 영역은 JIT이 **기계어로 변환 후 캐싱**
    
4. 다음부터는 **기계어로 실행 → 성능 향상**
    

---
✅ JIT의 장점 (👍)

|장점|설명|
|---|---|
|✅ **빠른 실행 속도**|자주 실행되는 부분을 컴파일 → 네이티브 코드처럼 빠름|
|✅ **동적 최적화**|런타임 정보 기반으로 **최적화된 코드 생성** 가능|
|✅ **유연성 유지**|리플렉션, 동적 로딩 등 인터프리팅의 유연함도 일부 유지|

✅ JIT의 단점 (👎)

|단점|설명|
|---|---|
|❌ 초기 실행 지연|처음 실행 시에는 인터프리팅 또는 컴파일로 시간이 걸림|
|❌ 메모리 소비 증가|변환된 기계어 코드가 메모리에 저장됨|
|❌ 구현 복잡성|JIT 엔진은 매우 복잡하고 정교한 설계 필요 (HotSpot 등)|

---
 ✅ 대표적인 JIT 엔진

|언어|JIT 엔진|
|---|---|
|Java|**HotSpot JVM**, GraalVM|
|C# (.NET)|**CLR JIT**, RyuJIT|
|JavaScript|V8 (Chrome), SpiderMonkey (Firefox)|
|Python|PyPy (JIT 기반 Python 구현)|

---
✅ 한 줄 요약

> **JIT 컴파일은 실행 중에 코드를 기계어로 컴파일하여 성능과 유연성을 모두 잡는 방식**입니다.  
> **자주 쓰는 코드는 빠르게, 한 번만 쓰는 코드는 간단히 처리**하는 똑똑한 실행 전략입니다.
##### 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
**Java는 “한 번 작성하면, 어디서나 실행된다(Write Once, Run Anywhere)”는 철학**을 위해,  
**컴파일 + 바이트코드 + JVM + JIT 컴파일러**를 조합한 독특한 실행 구조를 가지고 있습니다.

---
 ✅ Java의 컴파일 및 실행 흐름 요약
 ✅ 단계별 설명
 1️⃣ **컴파일 단계 (`javac`)**

- `.java` 파일을 **JVM이 이해할 수 있는 중간 언어**,  
    즉 **바이트코드(Bytecode)**로 변환 → `.class` 파일 생성
    
2️⃣ **실행 단계 (`java`)**

- `java Hello` 실행 시, **JVM(Java Virtual Machine)**이 `.class` 파일을 읽어 실행
    

JVM은 다음 두 가지 방식으로 바이트코드를 처리함:

---
 ✅ JVM 내부 처리 방식

|처리 방식|설명|
|---|---|
|**인터프리팅 (Interpretation)**|바이트코드를 **한 줄씩 해석하며 실행**  <br>→ 빠르게 시작할 수 있지만 느림|
|**JIT 컴파일 (Just-In-Time)**|**자주 실행되는 코드(HotSpot)를 네이티브 코드로 변환**  <br>→ 캐시하고 재사용 → 성능 향상|

➡ 처음에는 인터프리팅, **성능이 중요한 부분은 JIT로 최적화**

 ✅ 실행 예시

java

복사편집

`public class Hello {     public static void main(String[] args) {         System.out.println("Hello, Java");     } }`

실행 순서:

1. `javac Hello.java` → `Hello.class`
    
2. `java Hello` → JVM이 `main()` 메서드 실행
    
3. JVM이 `System.out.println()`을 해석하거나 컴파일하여 실행
    

 ✅ JVM 아키텍처 요약

|구성 요소|역할|
|---|---|
|**클래스 로더**|`.class` 파일 로딩|
|**바이트코드 검증기**|유효한 바이트코드인지 검사 (보안, 안정성 확보)|
|**인터프리터**|바이트코드를 한 줄씩 해석|
|**JIT 컴파일러**|자주 실행되는 코드 영역을 기계어로 변환|
|**GC (가비지 컬렉터)**|더 이상 쓰지 않는 객체를 자동으로 메모리에서 제거|

 ✅ 한 줄 요약

> Java는 `.java` 파일을 **바이트코드로 컴파일한 뒤**,  
> JVM이 이를 실행하면서 **인터프리트 + JIT 컴파일**을 통해  
> **플랫폼 독립성과 성능을 동시에 확보**합니다.
##### Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
아주 훌륭한 질문입니다.  
**Python**은 하나의 언어 사양(Python Language Specification)을 기반으로 여러 **"구현체(Implementation)"**가 존재합니다.  
그 중 가장 대표적인 것이 **CPython, PyPy, Jython**입니다.

이 구현체들은 **동일한 Python 문법을 지원**하지만,  
**실행 방식, 성능, 대상 플랫폼** 등이 다릅니다.

---
✅ 대표적인 Python 구현체 비교

|구현체|설명|실행 방식|특징|
|---|---|---|---|
|**CPython**|**기본/표준 구현체 (C 언어로 구현)**|바이트코드 + 인터프리터|가장 널리 사용됨, `python` 명령어가 실행하는 구현체|
|**PyPy**|성능 최적화된 Python (JIT 포함)|바이트코드 → **JIT 컴파일**|CPython보다 4~10배 빠름. 일부 C 확장 호환성 제한|
|**Jython**|Java 환경에서 실행되는 Python|Python → **Java 바이트코드 → JVM 실행**|Java와의 통합 강점 (Java 라이브러리 사용 가능)|
|**IronPython**|.NET용 Python 구현|Python → **.NET CLR에서 실행**|C#과 상호 운용 가능, 윈도우 친화적|
|**MicroPython**|임베디드용 경량 Python|바이트코드 → 인터프리트|리소스 제약 환경(Raspberry Pi Pico 등)에 적합|

✅ 실행 과정 차이

📌 CPython의 실행 흐름

text

복사편집

`.py 소스 코드   ↓ (컴파일) 바이트코드 (.pyc)   ↓ (인터프리터) CPython VM이 바이트코드 한 줄씩 실행`

📌 PyPy의 실행 흐름

text

복사편집

`.py 소스 코드   ↓ PyPy 인터프리터 + JIT 컴파일러   ↓ 자주 실행되는 코드를 기계어로 컴파일 후 캐시 → 매우 빠름`

📌 Jython의 실행 흐름

text

복사편집

`.py 소스 코드   ↓ Jython 컴파일러 → Java 바이트코드 (.class)   ↓ JVM이 실행 (Java 프로그램처럼 동작)`

✅ 선택 기준 (언제 뭘 쓰면 좋을까?)

|목적 / 상황|추천 구현체|이유|
|---|---|---|
|일반적인 Python 사용|✅ **CPython**|가장 안정적, 라이브러리 많음|
|성능 최적화 (연산 집중)|✅ **PyPy**|JIT 덕분에 속도 매우 빠름|
|Java와 연동 필요|✅ **Jython**|Java 클래스 직접 사용 가능|
|.NET 연동 필요|✅ **IronPython**|C#/F# 등과 연동 가능|
|IoT / 임베디드|✅ **MicroPython**|가벼운 환경에서도 실행 가능|

✅ 한 줄 요약

> **Python 구현체는 모두 같은 문법을 사용하지만**,  
> 실행 방식(JIT, JVM, 인터프리팅 등)과 대상 플랫폼에 따라 **성능과 특성이 크게 다릅니다.**  
> 용도에 따라 **CPython(기본), PyPy(속도), Jython(Java 통합)** 등을 선택하게 됩니다.
##### 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?
✅ 결론 요약

> **로더(Loader)는 exec() 시스템 콜 내부에서 동작하며**,  
> 우리가 흔히 사용하는 `fork()`와 `exec()` 시스템 콜은 **로더가 프로세스를 적재하도록 트리거하는 도구**입니다.  
> 즉, **exec()를 호출하면 커널의 로더가 동작하여 실행 파일을 메모리에 적재합니다.**

✅ fork()와 exec()의 관계

- `fork()`는 현재 프로세스를 **복제**합니다 → 부모와 동일한 코드, 데이터, 파일 디스크립터 등
    
- `exec()`는 현재 프로세스의 **주소 공간을 제거하고, 새로운 실행 파일로 덮어쓰기**합니다
    
- 이때 실행 파일을 메모리에 올리는 주체가 바로 **"로더(loader)"**입니다
    
 ✅ exec() 내부에서의 로더 역할

|순서|설명|
|---|---|
|1. exec() 호출|사용자가 새로운 실행 파일로 전환을 요청|
|2. 커널이 기존 주소 공간 제거|스택/힙/코드 모두 초기화|
|3. **로더가 실행 파일(ELF 등) 읽음**|헤더 파싱, 섹션(.text, .data 등) 로드|
|4. 메모리 배치|프로그램 코드, 데이터, 라이브러리 등 배치|
|5. 스택 초기화 및 `main()` 진입|실행 파일로 점프하여 실행 시작|

 ✅ 로더는 독립된 시스템 콜이 아니다

- **로더는 별도의 시스템 콜이 아니라**,  
    **exec 계열 시스템 콜 (execve, execl, execvp 등) 내부에서 커널이 수행하는 동작**입니다.
    
- 즉, 사용자가 직접 `loader()` 같은 시스템 콜을 호출하는 것이 아니라,  
    **`exec()` 호출이 로더의 역할을 트리거**합니다.
    

 ✅ 프로세스를 적재하는 "다른 방식"은 있는가?

- OS 수준에서는 `exec()`가 유일한 공식적인 적재 방식입니다.
    
- 일부 특수 상황 (예: 부트로더, 커널 내 프로세스 생성)은 **exec 없이도 적재가 이루어지지만**,  
    일반 사용자 공간에서는 **항상 fork + exec 패턴** 또는 **exec 단독 호출**이 사용됩니다.
    

 ✅ 한 줄 요약

> **로더는 `exec()` 시스템 콜 내부에서 동작하며**,  
> 우리가 실행 파일을 적재하는 모든 표준적인 방식은 결국 **로더를 통해 메모리에 프로그램을 올리는 구조**입니다.  
> `fork()`는 복제, `exec()`는 적재 → 로더는 `exec()` 안에서 실행됩니다.

### 11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
##### 설명
> **프로세스 간 데이터를 주고받기 위한 메커니즘**, 즉 **서로 다른 프로세스가 협력할 수 있도록 해주는 통신 수단**입니다.

운영체제는 **메모리 공간이 격리된 프로세스들 사이에서 안전하고 효율적인 통신을 보장하기 위해 다양한 IPC 방법을 제공합니다.**

---
✅ IPC가 필요한 이유

- 프로세스 간 **데이터 공유**
    
- **병렬 처리 결과 통합**
    
- **클라이언트–서버 통신** (예: 웹 브라우저 ↔ 백엔드 서버)
    
- **하드웨어 자원 공유**
    

---
 ✅ IPC의 주요 종류

|구분|이름|설명|특징|
|---|---|---|---|
|📬 메시지 기반|**Pipe (파이프)**|한 방향 통신, 부모-자식 간 주로 사용|단방향, 간단함|
||**Named Pipe (FIFO)**|이름 있는 파이프, 서로 무관한 프로세스 간 사용 가능|파일 시스템 경로로 식별|
||**Message Queue**|커널이 관리하는 메시지 큐에 메시지 저장|구조화된 메시지, 큐 형식|
|🧠 공유 메모리 기반|**Shared Memory**|**공유된 메모리 영역에 데이터를 직접 읽고 씀**|가장 빠름, 동기화 필요|
|🧵 동기화 기반|**Semaphore**|동기화/자원 관리용 → 자원 수량 제한|공유 자원 접근 제어|
||**Mutex**|상호배제를 위한 락|스레드 간에 주로 사용|
|📞 시그널 기반|**Signal**|간단한 알림 전달 (ex: `SIGKILL`)|단방향, 제어 용도|
|🌐 소켓 기반|**Socket**|네트워크를 통한 IPC, 로컬 or 원격 모두 가능|TCP/UDP 기반, 강력하고 범용적|

---
✅ 각 IPC 방식 간 비교 요약

|방식|속도|복잡도|특징|
|---|---|---|---|
|Shared Memory|✅ 매우 빠름|중간|동기화 필요|
|Pipe / FIFO|보통|낮음|순차적 스트림|
|Message Queue|보통|중간|구조적 메시지|
|Signal|느림|낮음|이벤트 알림|
|Socket|❌ 느림|높음|네트워크 기반, 확장성 높음|

✅ 한 줄 요약

> **IPC는 프로세스 간 통신을 위한 기술로**,  
> Pipe, Message Queue, Shared Memory, Semaphore, Socket 등 다양한 방식이 있으며,  
> 상황에 따라 **속도, 구조, 범용성, 동기화 방식**에 차이가 있습니다.
##### Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
**Shared Memory(공유 메모리)**는 **가장 빠른 IPC 방식 중 하나**로,  
서로 다른 프로세스가 **같은 물리 메모리 영역을 직접 공유**하여 데이터를 주고받는 기술입니다.

 ✅ Shared Memory란?

> **Shared Memory는 운영체제가 프로세스들 사이에 공유 가능한 메모리 영역을 생성해 주고**,  
> **해당 메모리 주소에 직접 접근하여 데이터를 읽고/쓸 수 있도록 허용하는 IPC 방식**입니다.

 ✅ 특징

|항목|설명|
|---|---|
|속도|✅ 매우 빠름 (커널 개입 최소화, 직접 메모리 접근)|
|방식|메모리 주소 기반 데이터 교환 (파일 I/O 필요 없음)|
|OS 지원|Linux: `shmget`, `shmat`, `shmdt`, `shmctl` / POSIX: `shm_open`, `mmap`|
|사용 구조|한 쪽 프로세스가 메모리 생성 → 다른 프로세스가 attach 해서 함께 사용|

---
 ✅ 사용할 때 유의해야 할 점
 📌 1. **동기화 필요**

- **공유 메모리는 동시 접근을 허용하므로**,  
    동시에 여러 프로세스가 쓰면 **경쟁 조건(Race Condition)**이 발생할 수 있음
    
- ➡ 반드시 **세마포어(Semaphore)**, **Mutex**, 또는 **Lock**으로 동기화 필요
    

 📌 2. **자원 해제 필수**

- 공유 메모리는 **프로세스 종료 시 자동 해제되지 않음**
    
- ➡ 사용이 끝난 후 `shmdt()`, `shmctl(..., IPC_RMID)` 등으로 **명시적 해제 필요**
    
- 해제 안 하면 **메모리 누수** 또는 **다음 실행 시 충돌** 발생
    

 📌 3. **보안 및 접근 권한**

- 메모리는 **모든 프로세스가 접근 가능한 리소스**가 될 수 있음
    
- ➡ `IPC_CREAT | 0666`과 같은 **퍼미션 설정 주의**
    
- 잘못된 설정은 **정보 노출 위험**
    

 📌 4. **프로세스 간 주소 공간은 다르다**

- 공유 메모리는 논리적으로 "공유된 메모리"지만,  
    각 프로세스는 **자신만의 주소 공간에 mapping**함  
    ➡ 같은 주소값을 공유하는 것이 아니라, **같은 물리 메모리를 참조하는 것**
    

 ✅ 언제 사용하면 좋은가?

- **대량의 데이터 전송**이 필요한 경우 (e.g. 영상 프레임, 센서 데이터)    
- **속도가 중요**하고, 통신 주기가 짧은 경우
- **멀티프로세싱 기반 서버 구성** (ex: `prefork` 모델 웹서버 등)
    
 ✅ 한 줄 요약

> **Shared Memory는 속도가 가장 빠른 IPC 방식이지만**,  
> **동기화**, **자원 해제**, **보안 설정**을 직접 신경 써야 하는 **저수준 고성능 기술**입니다.
##### 메시지 큐는 단방향이라고 할 수 있나요?
✅ 결론

> **네, 메시지 큐는 기본적으로 단방향입니다.**  
> 하나의 큐는 **한 쪽이 보내고(sender), 다른 한 쪽이 받는(receiver)** 구조로 설계되어 있습니다.

---
 ✅ 설명
 📌 왜 단방향인가요?

- 메시지 큐는 **송신자 → 수신자**로 메시지를 일방적으로 전달합니다.
    
- 메시지는 **FIFO(선입선출)** 방식으로 큐에 저장되고,
    
- 수신자는 큐에서 메시지를 **꺼내서 처리**만 합니다.
    

---
 ✅ 양방향 통신이 필요하면?

> **양방향 통신**이 필요한 경우는 **두 개의 메시지 큐를 따로 구성**해야 합니다:

각 큐는 **반대 방향 통신을 담당**합니다.

---
 ✅ 비교: 다른 IPC 방식과의 통신 방향성

|IPC 방식|방향성|설명|
|---|---|---|
|Pipe|단방향|기본 파이프는 한 방향만 통신|
|Named Pipe (FIFO)|단방향|명시적 읽기/쓰기 구성 필요|
|Message Queue|✅ 단방향|하나의 큐는 한 방향 통신만|
|Shared Memory|양방향|양쪽이 메모리를 함께 읽고 쓸 수 있음|
|Socket|✅ 양방향|기본적으로 full-duplex|
|Signal|단방향|알림만 전달 (응답 불가)|

---
 ✅ 한 줄 요약

> **메시지 큐는 단방향 통신이 기본이며**,  
> **양방향 통신이 필요할 경우, 큐를 두 개 구성하여 각각의 방향을 담당하게 해야 합니다.**

### 12. Thread Safe 하다는 것은 어떤 의미인가요?
##### 설명
✅ Thread-Safe의 정의

> 어떤 코드, 함수, 객체, 자료구조 등이  
> **여러 스레드가 동시에 호출하거나 접근하더라도 예상한 대로 정확히 동작**한다면,  
> 우리는 그것을 **Thread-Safe하다**고 말합니다.

✅ 왜 중요할까?

- 멀티스레드 환경에서는 **공유 자원에 동시에 접근**할 수 있음
- 동시성 문제(Race Condition, Deadlock 등)가 발생하지 않도록 하려면  
    → 코드가 **Thread-Safe**해야 함
    
 ✅ Thread-Safe를 보장하는 방법

|방법|설명|
|---|---|
|**Lock (Mutex, Semaphore)**|공유 자원에 대한 접근을 **직렬화**하여 보호|
|**Atomic 연산**|`std::atomic`, `__sync_*()` 등의 원자 연산 사용|
|**불변성 유지 (Immutable)**|데이터를 변경 불가능하게 설계 (Java의 `String` 등)|
|**Thread-local Storage**|각 스레드마다 독립적인 데이터 사용 (`__thread`, `ThreadLocal`)|
|**Lock-free / Wait-free 알고리즘**|고급 기법으로 성능과 안정성을 동시에 추구|
 ✅ 한 줄 요약

> **Thread-Safe**란, **멀티스레드 환경에서도 예상한 대로 정확히 작동하는 코드/구조를 의미**하며,  
> 보통 락, 원자 연산, 불변성 유지 등의 방식으로 이를 보장합니다.

##### Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
✅ Thread-Safe 보장을 위한 주요 방법

|방법|설명|장점|단점|
|---|---|---|---|
|1️⃣ **Mutual Exclusion (Mutex)**|락을 걸어 **한 번에 한 스레드만 자원 접근 허용**|구현 간단, 안전함|락 경합 발생 시 성능 저하, 데드락 위험|
|2️⃣ **Atomic 연산**|`std::atomic`, `__sync_*` 등 **하드웨어 수준 원자 연산** 사용|빠름, 락 없음|복잡한 로직엔 부적합|
|3️⃣ **불변성 유지 (Immutable 객체)**|데이터 수정 불가로 **동기화 필요 자체 제거**|안전성 극대화|메모리 사용 증가 가능|
|4️⃣ **Thread-Local Storage**|**각 스레드마다 독립적인 변수 공간** 제공|공유 자원 자체를 없앰|자원 중복 증가, 쓰레드 간 공유 불가|
|5️⃣ **Lock-Free / Wait-Free 알고리즘**|CAS 기반으로 **락 없이 동기화 구현**|성능 뛰어남, 데드락 없음|구현 매우 복잡, 검증 어려움|
|6️⃣ **메시지 기반 통신**|공유 자원 없이 **큐 등을 통해 메시지로 통신** (ex: Actor Model)|Race condition 없음|코드 구조 재설계 필요|
✅ 사용 시 주의할 점

| 주의점                         | 설명                    |
| --------------------------- | --------------------- |
| ❗ 데드락 방지                    | 락은 순서 보장 or 타임아웃 필요   |
| ❗ 과도한 락 사용 지양               | 락 경합은 성능 저하 유발        |
| ❗ 원자성만으론 충분하지 않음            | 원자 연산 + 메모리 일관성 고려 필요 |
| ❗ 병렬성/응답성/자원 효율 간 트레이드오프 고려 |                       |

---
✅ 한 줄 요약

> **Thread-Safe를 보장하기 위한 방법은 락(Mutex), 원자 연산(Atomic), 불변성, Thread-Local 등 다양하며**,  
> **문제의 성격에 따라 안전성과 성능을 균형 있게 고려해야 합니다.**
##### Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
✅ Peterson’s Algorithm이란?

> **두 개의 프로세스가 공유 자원에 동시에 접근하지 않도록 보장**하는 소프트웨어 동기화 알고리즘입니다.  
> 다음 두 가지 핵심 아이디어로 동작합니다:

1. 각 프로세스는 **진입 의도(`flag[i]`)를 명시**
    
2. 마지막에 진입 요청한 프로세스를 **기억(`turn`)**해서 **양보** 여부를 결정
    

---
 ✅ 핵심 변수

- `flag[2]`: 각 프로세스가 Critical Section에 들어가고 싶은지 나타냄 (`true` 또는 `false`)
    
- `turn`: 누가 양보할 차례인지 나타냄 (`0` 또는 `1`)
    
 ✅ Peterson Algorithm의 장점

|항목|설명|
|---|---|
|✅ 상호 배제 보장|한 번에 한 프로세스만 CS(Critical Section)에 진입|
|✅ 데드락 없음|두 프로세스가 서로 진입 의도만 표현하면 대기|
|✅ 공정성 보장|양쪽이 계속 시도할 경우 번갈아 진입 가능|
 ❌ 한계점 (실제로는 거의 쓰이지 않는 이유)

 📌 1. **2개 프로세스에만 적용 가능**

- 기본 Peterson 알고리즘은 **2개의 프로세스만 동기화 가능**
    
- N개 프로세스 확장은 복잡 (→ Dekker’s, Lamport’s Bakery 등 다른 알고리즘 필요)
    

 📌 2. **CPU 명령 순서 재배치 문제**

- Peterson 알고리즘은 **메모리 접근 순서에 의존**
    
- 하지만 **현대 CPU는 최적화를 위해 명령 순서를 재배치**할 수 있음
    
- ➡ **메모리 배리어(memory barrier)** 없이 구현 시 **동작 실패 가능**
    

 📌 3. **하드웨어 멀티코어 캐시 일관성 문제**

- Peterson은 공유 메모리 값(`flag`, `turn`)을 **정확히 읽고 쓸 수 있어야 함**
    
- 하지만 멀티코어 환경에서는 캐시 불일치 등으로 **Race Condition 발생 가능**
    
- ➡ 실용 환경에서는 적합하지 않음
    

 📌 4. **현대 OS에서는 제공 API 사용 권장**

- pthread, std::mutex, Java `synchronized` 등 **OS/런타임이 이미 잘 구현된 락 제공**
    
- Peterson처럼 **소프트웨어 락을 직접 구현할 일은 드묾**
    

 ✅ 한 줄 요약

> **Peterson’s Algorithm은 2개의 프로세스 간 상호 배제를 소프트웨어만으로 보장하는 고전 알고리즘이지만**,  
> 현대 CPU의 **명령 재배치와 멀티코어 메모리 모델** 때문에 **실제 환경에서는 거의 사용되지 않습니다.**
##### Race Condition 이 무엇인가요?
✅ 핵심 정의

> **Race Condition이란**  
> 여러 실행 흐름이 **공유 자원에 동시에 접근**하고,  
> 그 중 적어도 하나가 **쓰기(write)** 작업을 수행할 때 발생하며,  
> **정확한 실행 순서를 보장하지 않으면 잘못된 결과를 초래할 수 있는 상황**입니다.

---
 ✅ 발생 조건 (3가지 동시 조건)

|조건|설명|
|---|---|
|① 공유 자원이 있다|같은 변수, 구조체, 버퍼 등|
|② 둘 이상의 실행 흐름이 접근한다|스레드, 프로세스|
|③ 그 중 적어도 하나는 **쓰기 연산**을 한다|읽기만 하는 경우는 안전 (Read-Only)|

---
 ✅ 결과

- 프로그램이 **비결정적(Nondeterministic)**으로 동작
    
- **간헐적인 버그** 발생 (테스트 시 통과 → 운영 중 오류)
    
- **데이터 손상, 불일치, 크래시, 보안 문제 등 유발**
    

 ✅ 해결 방법

|방법|설명|
|---|---|
|🔒 **Lock(Mutex, Semaphore)**|공유 자원 접근을 직렬화|
|🧮 **Atomic 연산**|원자적 연산으로 동시성 제어|
|📦 **Thread-local 변수**|공유 자원 자체를 제거|
|🔁 **메시지 큐, Actor Model**|상태를 공유하지 않고 메시지로 처리|

---
 ✅ 한 줄 요약

> **Race Condition은 실행 순서에 따라 결과가 달라질 수 있는 동시성 문제**로,  
> 공유 자원을 사용할 때 **적절한 동기화가 없으면 발생**합니다.

##### Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
✅ 결론

> ❌ **락은 Thread-Safe를 보장하는 "유일한 방법"은 아닙니다.**  
> ✅ 락 없이도 다음과 같은 방식으로 **Thread-Safe한 동작을 구현**할 수 있습니다.

 ✅ 락 없이 Thread-Safe를 구현하는 방법들

|방법|설명|대표 예시|
|---|---|---|
|1️⃣ **원자 연산 (Atomic Operations)**|`std::atomic`, `__sync_*` 등으로 **경쟁 없이 데이터 변경**|`std::atomic<int> counter++;`|
|2️⃣ **불변 객체 (Immutable Object)**|값을 절대 수정하지 않고, 새 객체 생성 → **공유하지 않음**|Java `String`, Kotlin `val`|
|3️⃣ **Thread-local Storage**|각 스레드에 **독립적인 변수 저장** → 공유 자원 자체를 없앰|`__thread`, `ThreadLocal<T>`|
|4️⃣ **함수형 프로그래밍 스타일**|**상태를 공유하지 않고 순수 함수만 사용**|`map/filter/reduce` 구조|
|5️⃣ **Lock-free / Wait-free 알고리즘**|CAS 등으로 병렬 동기화 → **락 없이 안정성 보장**|ConcurrentQueue, MPMC 구조|
|6️⃣ **메시지 기반 처리 (Actor Model)**|자원을 공유하지 않고 **메시지 전달로 상태 변경**|Akka, Erlang, Go channel|

 ✅ 예시: 락 없이 원자 연산으로 Thread-Safe 구현

 ❌ 일반 int (Race Condition 발생)

 ✅ atomic 사용 (Thread-Safe)

 ✅ 언제 락을 안 써도 되나요?

|상황|락 없어도 OK?|이유|
|---|---|---|
|단순 카운터|✅ 가능|`std::atomic` 사용|
|읽기 전용 데이터|✅ 가능|변경이 없으면 동기화 불필요|
|스레드 간 상태 공유 없음|✅ 가능|공유 자원이 없으면 경쟁도 없음|
|자원 접근 순서 보장 불필요|✅ 가능|예: 로그, 캐시 등에선 순서 무관할 수 있음|

 ✅ 락 없이 구현할 때 주의할 점

|주의점|설명|
|---|---|
|❗ 메모리 일관성 보장 필요|atomic도 memory ordering 고려해야 함|
|❗ 복잡한 구조에선 오히려 위험|락 없이 구현이 더 복잡하거나 오류 가능성 높음|
|❗ 디버깅이 어려움|Lock-free 코드는 오류 발생 시 재현과 추적이 어려움|
 ✅ 한 줄 요약

> **Thread-Safe를 보장하려면 반드시 락을 쓸 필요는 없으며**,  
> 원자 연산, 불변성, 쓰레드 로컬, 메시지 전달, lock-free 알고리즘 등 **다양한 고성능 대안**이 존재합니다.

### 13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.

### 14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
### 15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
### 16. Thrashing 이란 무엇인가요?
### 17. 가상 메모리란 무엇인가요?
### 18. 세그멘테이션과 페이징의 차이점은 무엇인가요?
### 19. TLB는 무엇인가요?
### 20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
### 21. 페이지 교체 알고리즘에 대해 설명해 주세요.

### 22. File Descriptor와, File System에 에 대해 설명해 주세요.
### 23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
