### 1. 시스템 콜이 무엇인지 설명해 주세요.
##### 설명
💡 시스템 콜(System Call)이란?

시스템 콜(System Call)은 사용자 프로그램이 **운영체제 커널의 기능을 요청**하기 위해 사용하는 **인터페이스**입니다.

운영체제는 **사용자 프로그램이 직접 하드웨어나 중요 자원(CPU, 메모리, 디스크 등)에 접근하지 못하게 제한**하고 있습니다. 따라서 파일 입출력, 프로세스 생성, 네트워크 통신 같은 작업을 하려면 **운영체제에 요청**을 해야 하는데, 이때 사용하는 것이 **시스템 콜**입니다.

##### 우리가 사용하는 시스템 콜의 예시를 들어주세요.
✅ 1. **파일 시스템 관련 시스템 콜**

|시스템 콜|설명|
|---|---|
|`open()`|파일을 열고 파일 디스크립터 반환|
|`read()`|파일에서 데이터를 읽음|
|`write()`|파일에 데이터를 씀|
|`close()`|파일을 닫고 자원 반환|
|`lseek()`|파일 포인터 위치를 이동|
 ✅ 2. **프로세스 제어 관련 시스템 콜**

|시스템 콜|설명|
|---|---|
|`fork()`|현재 프로세스를 복제 (자식 프로세스 생성)|
|`exec()`|다른 프로그램 실행|
|`wait()`|자식 프로세스 종료 대기|
|`exit()`|현재 프로세스 종료|
|`getpid()`|현재 프로세스의 PID 반환|
 ✅ 3. **메모리 관리 시스템 콜**

| 시스템 콜              | 설명                 |
| ------------------ | ------------------ |
| `mmap()`           | 파일이나 디바이스를 메모리에 매핑 |
| `brk()` / `sbrk()` | 힙 영역 크기 조절         |
 ✅ 4. **디바이스/입출력 제어**

|시스템 콜|설명|
|---|---|
|`ioctl()`|장치 제어 명령 수행 (예: 터미널 설정)|
 ✅ 5. **네트워크 관련 시스템 콜 (소켓)**

|시스템 콜|설명|
|---|---|
|`socket()`|소켓 생성|
|`bind()`|소켓에 주소 지정|
|`connect()`|서버에 연결|
|`send()`, `recv()`|데이터 송수신|
|`close()`|소켓 닫기|
 ✅ 6. **시간/시스템 정보**

|시스템 콜|설명|
|---|---|
|`gettimeofday()`|현재 시간 가져오기|
|`uname()`|커널 이름, 버전 등 시스템 정보 조회|

🧠 정리

- 시스템 콜은 **운영체제 자원을 요청할 때마다 사용**됨
    
- 우리가 파일을 열거나, 데이터를 읽거나, 프로세스를 생성하거나, 네트워크 통신을 할 때마다 **시스템 콜이 백그라운드에서 수행**
##### 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
✅ 시스템 콜 실행 과정 (단계별 설명)

1️. **사용자 프로그램에서 시스템 콜 호출**

사용자는 C 언어로 다음과 같이 `read()` 같은 시스템 콜을 호출합니다.

`read(fd, buffer, 100);`

 2️.**소프트웨어 인터럽트(trap) 발생 → 커널 모드 전환**

라이브러리 함수 내부에서는 시스템 콜 번호를 특정 레지스터에 담고, **특별한 CPU 명령어**를 사용하여 커널로 진입합니다.

- x86 (32-bit): `int 0x80`
    
- x86_64: `syscall` 명령어
    
- ARM: `svc` 명령어
    

➡️ 이 명령은 **트랩(trap)**을 발생시켜 현재 실행을 **커널 모드로 전환**합니다.

---
3. 커널 모드로 전환 및 시스템 콜 처리

인터럽트가 발생하면 CPU는 커널 모드로 전환되고, 운영체제는 인터럽트 벡터 테이블을 참조하여 적절한 시스템 콜 핸들러를 호출합니다. 예를 들어, `sys_write()` 함수가 호출되어 파일에 데이터를 씁니다.
    

➡️ 이 과정에서 **직접 하드웨어나 커널 데이터 구조에 접근 가능**

5. **처리 완료 후 결과값 반환**

- 커널은 작업 결과(읽은 바이트 수, 에러 코드 등)를 특정 레지스터에 저장
    
- 트랩 리턴 명령 (`iret`, `sysret` 등)을 통해 **유저 모드로 복귀**
    

6️⃣ **사용자 프로그램은 결과값 확인 후 다음 작업 진행**

사용자 프로그램은 시스템 콜의 반환값을 사용하여 다음 작업을 수행합니다.
`ssize_t bytesRead = read(fd, buffer, 100); if (bytesRead == -1) perror("read failed");`

---

 ✅ 요약 플로우 (한 줄 정리)

> 사용자 코드 → 라이브러리 함수 → 시스템 콜 번호 설정 → trap → 커널 진입 → 핸들러 실행 → 결과 반환 → 유저 모드 복귀

---

🧠 보안과 안정성을 위한 이유

- 사용자 프로그램이 직접 커널 데이터/하드웨어를 다루지 못하게 막기 위해 반드시 **제어된 인터페이스(= 시스템 콜)**를 통해야 함.
    
- 시스템 콜을 거치면 커널이 **검증/제어/로그**를 수행할 수 있어 **안정성과 보안성 확보**
##### 시스템 콜의 유형에 대해 설명해 주세요.
✅ 1. **프로세스 제어(Process Control)**

프로세스 생성, 종료, 실행 중지, 정보 요청 등 **프로세스의 생명주기 관리**에 필요한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`fork()`|현재 프로세스를 복제 (자식 프로세스 생성)|
|`exec()`|새로운 프로그램을 현재 프로세스 공간에 적재|
|`exit()`|프로세스 종료|
|`wait()`|자식 프로세스 종료까지 대기|
|`getpid()`|현재 프로세스의 PID 반환|

---

✅ 2. **파일 시스템 조작(File Manipulation)**

파일 및 디렉터리의 생성, 읽기/쓰기, 삭제 등을 위한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`open()`|파일 열기|
|`read()`|파일 읽기|
|`write()`|파일 쓰기|
|`close()`|파일 닫기|
|`unlink()`|파일 삭제|
|`lseek()`|파일 포인터 이동|

---

✅ 3. **디바이스 제어(Device Manipulation)**

파일 시스템과 유사하지만, **특수한 입출력 장치**와의 상호작용을 위한 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`ioctl()`|디바이스 제어 명령 수행|
|`read()`|디바이스로부터 읽기|
|`write()`|디바이스에 쓰기|

---

✅ 4. **정보 유지(Information Maintenance)**

프로세스, 시간, 시스템 설정 등 운영체제에 관련된 정보를 가져오거나 설정하는 시스템 콜입니다.

|시스템 콜|설명|
|---|---|
|`getpid()`|현재 프로세스 ID 가져오기|
|`alarm()`|시간 기반 알림 설정|
|`gettimeofday()`|시스템 시각 조회|
|`uname()`|커널/시스템 정보 가져오기|

---
✅ 5. **통신(Communication)**

프로세스 간 통신(IPC)을 위한 시스템 콜입니다. 주로 **소켓 기반 통신**이나 **파이프, 공유 메모리** 등을 다룹니다.

|시스템 콜|설명|
|---|---|
|`pipe()`|익명 파이프 생성 (단방향)|
|`socket()`|네트워크 소켓 생성|
|`connect()`|서버에 연결|
|`send()`, `recv()`|데이터 송수신|
|`shmget()`|공유 메모리 생성|

##### 운영체제의 Dual Mode 에 대해 설명해 주세요.
✅ 운영체제의 Dual Mode란?

**Dual Mode**는 컴퓨터 시스템이 **두 가지 실행 모드**—  
👉 **User Mode(사용자 모드)**와  
👉 **Kernel Mode(커널 모드)**를 갖는 구조를 말합니다.

이는 **보안과 안정성**을 위해 운영체제가 **실행 권한을 구분**하는 중요한 메커니즘입니다.

---
🔍 각 모드의 특징

| 구분    | 사용자 모드 (User Mode)          | 커널 모드 (Kernel Mode)              |
| ----- | --------------------------- | -------------------------------- |
| 실행 주체 | 일반 사용자 프로그램                 | 운영체제 커널                          |
| 접근 권한 | 제한됨 (I/O, 메모리 등 직접 접근 불가)   | 시스템 자원 전체 접근 가능 (하드웨어, 메모리 등)    |
| 위험도   | 낮음 (잘못된 명령은 운영체제가 감지/차단 가능) | 높음 (커널 오류는 시스템 전체 다운으로 이어질 수 있음) |
| 전환 방법 | 시스템 콜, 인터럽트 등을 통해 커널 진입     | 작업 완료 후 사용자 모드로 복귀               |
|       |                             |                                  |

---
##### 왜 유저모드와 커널모드를 구분해야 하나요?
왜 Dual Mode가 필요한가?

1. **보안(Security)**
    
    - 사용자 프로그램이 **디스크, 네트워크, 메모리** 같은 자원을 **마음대로 건드리지 못하게** 막습니다.
        
2. **안정성(Stability)**
    
    - 사용자 코드의 오류나 악의적인 행동이 시스템 전체에 영향을 주지 않도록 격리합니다.
        
3. **운영체제 통제 유지**
    - 운영체제는 시스템 자원의 **공정한 분배, 보호, 관리**를 책임집니다.
	- 이를 위해 사용자 프로그램은 반드시 **운영체제를 통해 자원을 요청**하게 설계되어야 하며, 그 통로가 **시스템 콜**입니다.
        
---
##### 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
- 시스템 콜을 구분하는 기준은 **시스템 콜 번호**
- 운영체제는 **시스템 콜 벡터 테이블**을 통해 번호 → 함수 매핑
- 이 구조 덕분에 운영체제가 **안전하게 수많은 시스템 콜을 빠르게 구분**할 수 있음
### 2. 인터럽트가 무엇인지 설명해 주세요.
##### 설명
✅ 인터럽트란?

**인터럽트(Interrupt)**는 **현재 실행 중인 작업을 잠시 멈추고**,  
운영체제가 **긴급하거나 중요한 작업을 먼저 처리할 수 있도록 제어 흐름을 전환하는 메커니즘**입니다.

즉, **CPU의 흐름을 외부/내부 이벤트가 "가로채는" 것**입니다.

✅ 왜 필요한가?

- CPU는 기본적으로 **순차적으로 명령어를 처리**합니다.
    
- 하지만 주변 장치나 프로그램이 언제 어떤 요청을 보낼지 예측할 수 없습니다.
    
- 따라서 CPU가 **일일이 기다리지 않고**, 이벤트가 발생하면 **즉시 응답**할 수 있도록 **인터럽트가 필요**합니다.
    
✅ 인터럽트의 종류

| 유형                 | 설명                                               | 예시                 |
| ------------------ | ------------------------------------------------ | ------------------ |
| **하드웨어(외부) 인터럽트**  | 외부 장치가 CPU에게 이벤트 발생을 알리는 경우                      | 키보드 입력, 디스크 입출력 완료 |
| **소프트웨어(내부) 인터럽트** | 프로그램이 의도적으로 커널 기능을 요청하기 위해 발생시키는 인터럽트 (**Trap**) | 시스템 콜, 예외 처리       |
| **예외(Exception)**  | 프로그램 실행 중 오류가 발생한 경우                             | 0으로 나누기, 페이지 폴트    |

---

##### 인터럽트는 어떻게 처리하나요?
🔁 인터럽트 처리 과정 (6단계 요약)

1️⃣ 인터럽트 발생

- **외부 장치**(예: 키보드, 디스크)가 요청하거나
    
- **CPU 내부에서 예외나 시스템 콜**이 발생하면 인터럽트가 발생합니다.
    
 2️⃣ 현재 작업 상태 저장

- CPU는 현재 실행 중인 프로그램의 **Program Counter(PC), 레지스터** 등의 정보를 **스택에 저장**합니다.
    
- 이는 나중에 **원래 작업으로 복귀하기 위해 필수적인 단계**입니다.
    

3️⃣ 커널 모드로 전환

- 인터럽트가 발생하면 **하드웨어가 자동으로 CPU를 커널 모드로 전환**합니다.
    
- 유저 모드에서는 시스템 자원에 접근할 수 없기 때문에, **인터럽트 처리는 반드시 커널 모드에서 이루어집니다.**
    
 4️⃣ 인터럽트 벡터 테이블 참조

- CPU는 **인터럽트 번호(ID)**를 기반으로  
    **인터럽트 벡터 테이블**에서 해당 **인터럽트 핸들러 함수의 주소**를 조회합니다.
    
5️⃣ 인터럽트 핸들러 실행

- 해당 핸들러 함수가 실행되어, 요청된 작업(I/O 완료 처리, 데이터 수신 등)을 수행합니다.
    
6️⃣ 저장된 상태 복원 후 복귀

- 인터럽트 처리가 끝나면, **스택에 저장해둔 상태를 복원**하고  
    **중단된 작업으로 복귀**하여 프로그램 실행을 이어갑니다.
    

📌 예시: 키보드 인터럽트

1. 사용자가 키보드를 누름
    
2. **키보드 컨트롤러가 인터럽트(IRQ1)**를 발생시킴
    
3. CPU는 해당 인터럽트의 핸들러(0x21)를 호출
    
4. 키보드 입력을 OS 버퍼에 저장
    
5. 사용자 프로그램으로 복귀
    ✅ 정리

|단계|설명|
|---|---|
|1. 인터럽트 발생|외부 장치나 내부 예외 발생|
|2. 상태 저장|현재 CPU 상태 저장 (문맥 보존)|
|3. 모드 전환|유저 모드 → 커널 모드|
|4. 핸들러 조회|인터럽트 벡터 테이블에서 함수 찾기|
|5. 핸들러 실행|이벤트 처리|
|6. 복귀|저장된 상태 복원 후 사용자 프로그램 계속 실행|

---

##### Polling 방식에 대해 설명해 주세요.
Polling 방식이란?

**Polling(폴링)**은 **CPU가 주기적으로 장치 상태를 직접 확인(poll)**하여  
작업이 가능한지를 판단하는 **능동적 감시 방식**입니다.

> 즉, "지금 됐나?", "이제 됐나?" 하고 **계속 물어보는 방식**입니다.

---
 ✅ Polling의 동작 방식

1. CPU는 장치 레지스터나 상태 비트를 **반복적으로 읽음**
    
2. 장치가 작업을 완료하거나 준비되었는지를 확인
    
3. 준비가 되었으면 필요한 작업을 수행 (ex: 데이터 읽기)
    
4. 아니면 일정 시간 대기하거나 다시 확인
    
✅ Polling vs Interrupt

| 항목     | Polling 방식                  | 인터럽트 방식                        |
| ------ | --------------------------- | ------------------------------ |
| 감지 방법  | CPU가 직접 상태를 반복 확인           | 장치가 이벤트 발생 시 CPU에 알림           |
| 자원 효율성 | 비효율적 (CPU가 바쁘게 기다림)         | 효율적 (CPU는 다른 일 하다가 필요할 때만 반응)  |
| 반응 속도  | 빠를 수 있음 (항상 감시 중)           | 약간 지연 가능 (인터럽트 발생 후 처리)        |
| 구현 복잡도 | 간단함                         | 복잡함 (인터럽트 핸들러, 문맥 전환 등 필요)     |
| 용도 예시  |  디스플레이 등 **지속적 감시가 필요한 경우** | 네트워크 수신, 키보드 입력 등 **비정기적 이벤트** |

✅ Polling의 장점과 단점

장점

- 구현이 단순함
    
- 예측 가능한 처리 시점 (실시간성이 필요한 경우 사용 가능)
    
단점

- **CPU 낭비**: 응답이 올 때까지 계속 확인해야 함
    
- **다른 작업을 병행하기 어려움**
    
✅ 언제 Polling을 사용하는가?

- **하드 리얼타임 시스템** (항상 일정 주기로 상태 점검이 필요한 경우)
    
- **간단한 임베디드 시스템** (인터럽트 컨트롤러가 없는 경우)
    
- **I/O가 아주 빠르거나 빈번한 경우**
    

 ✅ 요약

|핵심 정리|
|---|
|Polling은 CPU가 주기적으로 장치 상태를 직접 확인하는 방식|
|구현은 간단하지만, CPU 자원을 비효율적으로 사용함|
|인터럽트 방식과는 자원 활용 방식에서 뚜렷한 차이가 있음|
##### HW / SW 인터럽트에 대해 설명해 주세요.
✅ 1. 하드웨어 인터럽트 (Hardware Interrupt)
 📌 정의

> **CPU 외부의 하드웨어 장치(디바이스)**가 CPU에 **신호를 보내 실행 흐름을 가로채는 것**입니다.

🔧 예시

- **키보드 입력**: 사용자가 키를 누르면 키보드 컨트롤러가 인터럽트를 발생시킴
    
- **디스크 입출력 완료**: 데이터 읽기/쓰기 완료 시 디스크 컨트롤러가 인터럽트 발생
    
- **네트워크 수신**: NIC(네트워크 인터페이스 카드)가 패킷 수신 완료 후 알림
    
 📌 특징

- **비동기적**으로 발생함 (CPU가 예측할 수 없음)    
- 주로 **I/O 처리에 사용**
- CPU는 장치 상태를 polling하지 않고도 효율적으로 응답 가능
    
✅ 2. 소프트웨어 인터럽트 (Software Interrupt)
 📌 정의

> **프로그램(소프트웨어)**이 **명시적으로 인터럽트를 발생시켜** 커널 기능을 요청하는 것  
> 주로 **시스템 콜 호출 시 사용**

 🔧 예시

- 리눅스 32bit: `int 0x80` 명령어로 시스템 콜 진입
    
- 리눅스 64bit: `syscall` 명령어로 시스템 콜 진입
    
- 예외(Exception): 0으로 나누기 → Division by Zero Exception 발생
    
 📌 특징
- **동기적**으로 발생함 (명령어 실행 시 발생)
- 주로 **시스템 콜, 예외 처리**에 사용
- 프로세스가 커널 기능을 요청할 때 쓰임
    
✅ 하드웨어 vs 소프트웨어 인터럽트 비교표

| 항목    | 하드웨어 인터럽트          | 소프트웨어 인터럽트                            |
| ----- | ------------------ | ------------------------------------- |
| 발생 주체 | 외부 장치 (키보드, 디스크 등) | 사용자 프로그램 또는 CPU 내부 명령                 |
| 발생 시점 | 비동기적 (예측 불가능한 시점)  | 동기적 (명령어 실행 시점)                       |
| 사용 목적 | I/O 알림, 장치 이벤트 처리  | 시스템 콜, 예외 처리                          |
| 예시    | 키보드 입력, 네트워크 수신    | `int 0x80`, `syscall`, Divide-by-zero |
| 처리 주체 | 인터럽트 핸들러           | 시스템 콜 핸들러 또는 예외 처리기                   |

✅ 정리

| 구분          | 설명                           |
| ----------- | ---------------------------- |
| **HW 인터럽트** | 외부 장치 → CPU에게 신호 (입출력 처리 등)  |
| **SW 인터럽트** | 프로그램이 명령어로 직접 발생 (시스템 콜, 예외) |
##### 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
✅ 동시에 여러 인터럽트가 발생하면 어떻게 처리할까?

1. **우선순위에 따라 처리**
- 대부분의 CPU와 인터럽트 컨트롤러는 **인터럽트마다 우선순위(Priority)**를 부여합니다.
- **우선순위가 높은 인터럽트부터 먼저 처리**하고,  
    우선순위가 낮은 인터럽트는 **나중에 처리하거나 대기시킵니다.**
    
 📌 예시

| 인터럽트 종류 | 우선순위 (예시) |
| ------- | --------- |
| 타이머     | 가장 높음     |
| 디스크 I/O | 중간        |
| 키보드 입력  | 낮음        |
 2. **중첩 인터럽트(Nested Interrupts)** 처리

- 인터럽트를 처리 중일 때 **더 높은 우선순위의 인터럽트가 발생**하면,  
    **현재 인터럽트를 일시 중단**하고, **새 인터럽트를 먼저 처리**합니다.
    
- 이후 **중단된 인터럽트 처리로 복귀**하여 이어서 실행합니다.
    

📌 이를 위해 CPU는 **인터럽트 중첩을 허용하는 구조(예: 스택 저장, 플래그 비트)**를 갖고 있어야 합니다.

---
 ✅ 인터럽트 마스킹(Interrupt Masking)

운영체제는 때로는 **일부 인터럽트를 임시적으로 무시(차단)**하기도 합니다. 이를 **마스킹(masking)**이라고 합니다.

- 중요한 작업 중일 때, **하위 우선순위 인터럽트가 들어오는 것을 막기 위해 사용**
    
- 예: 커널 크리티컬 섹션 실행 중 인터럽트 일시 마스킹
    
 ✅ 하드웨어 지원: 인터럽트 컨트롤러 (예: PIC, APIC)

- 여러 인터럽트를 관리하는 **전용 하드웨어 장치**
    
- **우선순위 조정**, **마스킹 처리**, **중첩 허용 여부** 등을 하드웨어 수준에서 제어
    
- x86 시스템에서는 **APIC (Advanced Programmable Interrupt Controller)**가 사용됨
    

 ✅ 요약

| 상황                   | 처리 방식                                |
| -------------------- | ------------------------------------ |
| 여러 인터럽트가 동시에 발생      | **우선순위**에 따라 처리                      |
| 낮은 우선순위 인터럽트 먼저 처리 중 | **중첩 인터럽트** 발생 시 높은 우선순위 인터럽트를 먼저 처리 |
| 예외 상황 또는 중요 작업 중     | **인터럽트 마스킹**으로 임시 차단 가능              |

---
🔁 예시 시나리오

1. CPU가 디스크 I/O 인터럽트 처리 중
    
2. 그 순간 타이머 인터럽트 발생 (우선순위 더 높음)
    
3. → 디스크 처리 잠시 중단 → 타이머 인터럽트 처리
    
4. → 이후 디스크 인터럽트 핸들러로 복귀하여 마저 처리
    

### 3. 프로세스가 무엇인가요?
##### 설명
✅ 프로세스란?

> **프로세스**는 **실행 중인 프로그램(Program in Execution)**입니다.

정적인 **프로그램 코드**(예: `a.out`, `chrome.exe`)가 메모리에 올라가 **CPU에 의해 실행되면서**,  
운영체제가 그 프로그램에 대해 **독립적인 실행 환경(메모리, 레지스터, PID 등)을 부여**한 것이 바로 **프로세스**입니다.

##### 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
✅ 1. 프로그램 (Program)
📌 정의

> **프로그램은 실행되지 않은 정적인 코드**입니다.

- 하드디스크에 저장된 실행 파일 (`a.exe`, `vim`, `chrome`) 등이 여기에 해당합니다.
    
- 아직 실행되지 않았기 때문에 **메모리, PID, 자원**을 가지지 않습니다.
    
✅ 2. 프로세스 (Process)
📌 정의

> **프로세스는 실행 중인 프로그램(Program in Execution)**입니다.

- 운영체제가 프로그램을 실행하면 **메모리에 올리고, PID를 부여하며, 독립된 실행 환경**을 만듭니다.
    
- 하나의 프로그램을 여러 번 실행하면 **서로 다른 프로세스**가 생성됩니다.
    
📦 프로세스가 가지는 자원

- 고유한 **메모리 공간** (코드, 데이터, 힙, 스택)
    
- 고유한 **파일 디스크립터 테이블**
    
- 고유한 **프로세스 제어 블록(PCB)**
    

✅ 3. 스레드 (Thread)
 📌 정의

> **스레드는 프로세스 내에서 실행되는 작업의 최소 단위**입니다.  
> 프로세스 안에서 **실제 코드 실행을 담당**하는 주체입니다.

- 한 프로세스는 **하나 이상의 스레드(멀티스레드)**를 가질 수 있습니다.
    
- **모든 스레드는 같은 프로세스의 메모리 공간(코드, 힙, 전역변수 등)을 공유**합니다.
    
- 하지만 **스택, 레지스터 등은 개별적으로 유지**합니다.
##### PCB가 무엇인가요?
✅ PCB란?

> **PCB(Process Control Block)**는 운영체제가 **하나의 프로세스에 대한 모든 상태 정보를 저장하는 구조체**입니다.  
> 쉽게 말하면, **"프로세스의 주민등록증 + 실행 이력 + 자원 목록"을 담은 표**입니다.

운영체제는 수많은 프로세스를 동시에 다루기 때문에, **각 프로세스를 식별하고 관리**할 필요가 있습니다. 이때 사용하는 게 바로 PCB입니다.

 ✅ PCB에 저장되는 정보

| 분류          | 정보                         | 설명                             |
| ----------- | -------------------------- | ------------------------------ |
| 📌 식별 정보    | **PID**                    | 프로세스 고유 번호                     |
| 📌 상태 정보    | **프로세스 상태**                | Running, Ready, Waiting 등      |
| 📌 문맥 정보    | **레지스터 값**, **PC**, **SP** | CPU 문맥 저장 (context switching용) |
| 📌 스케줄링 정보  | **우선순위**, **CPU 점유 시간**    | 스케줄러 참고 정보                     |
| 📌 메모리 정보   | **코드/데이터/스택/힙의 위치 정보**     | 프로세스의 주소 공간 관리                 |
| 📌 파일 정보    | **파일 디스크립터 테이블 포인터**       | 열린 파일 목록 관리                    |
| 📌 입출력 정보   | **I/O 장치 상태**              | 사용 중인 장치에 대한 정보                |
| 📌 부모/자식 정보 | **PPID, Child List**       | 프로세스 계층 관리 (ps 트리 구조 등)        |

 ✅ PCB는 어디에 저장되나요?
- **운영체제 커널 공간**에 저장됩니다.
- 프로세스마다 **1개씩 존재**합니다.
- 리눅스에서는 `task_struct` 구조체가 PCB 역할을 합니다.
    
✅ 왜 중요한가?

| 이유        | 설명                                                   |
| --------- | ---------------------------------------------------- |
| **문맥 전환** | PCB에 저장된 CPU 상태 정보로, 실행 중인 프로세스를 중단하고 다른 프로세스로 전환 가능 |
| **스케줄링**  | 스케줄러는 PCB 정보를 기반으로 어떤 프로세스를 실행할지 판단                  |
| **자원 회수** | 프로세스 종료 시 PCB를 참조하여 모든 자원 정리 가능                      |

✅ 예시 흐름: 문맥 전환 시 PCB 역할

1. 현재 프로세스 A 실행 중
    
2. 인터럽트 발생 → 커널 진입
    
3. **A의 현재 상태(레지스터 등)를 PCB A에 저장**
    
4. **PCB B에서 상태를 복원 → 프로세스 B 실행**
    
5. 운영체제는 이렇게 PCB를 통해 여러 프로세스를 스위칭하며 실행
    
✅ 요약

| 항목    | 내용                          |
| ----- | --------------------------- |
| 정의    | 프로세스 상태 정보를 담은 운영체제의 자료구조   |
| 저장 위치 | 커널 공간 (각 프로세스마다 1개)         |
| 주요 내용 | PID, 상태, 레지스터, 메모리, FD 등    |
| 핵심 역할 | 프로세스 추적, 문맥 전환, 자원 관리, 스케줄링 |
|       |                             |
##### 그렇다면, 스레드는 PCB를 갖고 있을까요?
> ✅ **스레드는 독립된 PCB를 갖지 않습니다.**  
> 대신, **스레드는 “프로세스의 PCB를 공유”하면서, 자신만의 실행 컨텍스트(스택, 레지스터 등)를 따로 가집니다.**

---
 ✅ 정리해서 답변하자면
 🧵 **스레드(Thread)**:
- 하나의 **프로세스 내부에서 실행되는 흐름 단위**
- **메모리 공간, 열린 파일, 코드 영역 등을 프로세스와 공유**
- 하지만 **자신만의 스택, 레지스터 상태, 스레드 ID(TID)** 등은 따로 가짐
    
 📄 **PCB(Process Control Block)**:
- **프로세스 전체에 대한 정보를 담은 운영체제 구조체**
- 메모리 공간, 파일 디스크립터 테이블, 우선순위 등 **프로세스 공통 정보**를 포함
    

 ✅ 그럼 스레드는 뭘 갖고 있나요?

스레드는 PCB 대신 **스레드 제어 블록(TCB, Thread Control Block)**이라는 **간단한 구조체**를 가집니다.

| 항목       | TCB (스레드 제어 블록)           |
| -------- | ------------------------- |
| TID      | 고유한 스레드 ID                |
| 스택 포인터   | 스레드별 스택 저장                |
| 프로그램 카운터 | 현재 실행 중인 명령어 위치           |
| 레지스터 상태  | 레지스터 값 저장                 |
| 스레드 상태   | Running, Ready, Blocked 등 |
| 우선순위     | 스케줄링 참고 정보 등              |

➡ 운영체제는 이 **TCB를 이용해 스레드를 문맥 전환(context switching)**합니다.

✅ 프로세스와 스레드 관계 정리

|항목|프로세스|스레드|
|---|---|---|
|제어 블록|PCB|TCB|
|주소 공간|각자 독립|프로세스와 공유|
|스택|각자 가짐|각자 가짐|
|코드/데이터|독립적|공유|
|파일 디스크립터|독립적|공유|
##### 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
✅ 리눅스에서 **프로세스 생성** 방식

 📌 사용 시스템 콜: `fork()` → `exec()`

1. `fork()`:    
    - 부모 프로세스를 **복사**하여 **자식 프로세스를 생성**
    - PCB(task_struct), 메모리 공간, 파일 디스크립터 테이블 등이 **복사됨 (copy-on-write)**
        
2. `exec()`:
    - 자식 프로세스가 **새로운 프로그램으로 자기 자신을 덮어쓰기**
    - 실행 파일을 적재하여 독립적인 새 프로그램으로 바뀜
        

✅ 리눅스에서 **스레드 생성** 방식
 📌 사용 시스템 콜: `clone()`, 혹은 `pthread_create()`

- 리눅스에서 스레드는 `clone()` 시스템 콜을 통해 생성되며,    
- `clone()`은 **어떤 자원을 부모와 공유할지 플래그로 지정**합니다.
    
 주요 플래그

|플래그|의미|
|---|---|
|`CLONE_VM`|부모와 **주소 공간(메모리)** 공유|
|`CLONE_FILES`|**파일 디스크립터 테이블** 공유|
|`CLONE_FS`|현재 작업 디렉토리 공유|
|`CLONE_THREAD`|**같은 스레드 그룹으로 생성** (TID 공유)|

이런 플래그를 조합하면 → **하나의 프로세스 안에서 새로운 스레드 생성**

 ✅ 정리: 리눅스에서 프로세스 vs 스레드 생성 비교

| 구분       | 프로세스                | 스레드                             |
| -------- | ------------------- | ------------------------------- |
| 시스템 콜    | `fork()` + `exec()` | `clone()` 또는 `pthread_create()` |
| 메모리 공간   | 별도 (복사됨)            | 공유 (CLONE_VM)                   |
| 파일 디스크립터 | 복사(copy-on-write)   | 공유 (CLONE_FILES)                |
| PID      | 독립적인 PID            | **TID는 다르지만, 같은 PID (스레드 그룹)**  |
| 자원 격리    | 강함                  | 약함 (공유된 상태)                     |

 ✅ 리눅스 내부적으로는?

- 리눅스는 **프로세스와 스레드를 구분하지 않고**, 모두 `task_struct`로 표현합니다.
    
- 단지 **어떤 자원을 공유하느냐**에 따라 **“프로세스처럼” 혹은 “스레드처럼” 동작**할 뿐입니다.
    
 🔔 핵심 요약

| 질문                      | 대답                                                 |
| ----------------------- | -------------------------------------------------- |
| 리눅스에서 프로세스는 어떻게 만들어지나요? | `fork()`로 복제 후, `exec()`로 새로운 프로그램 실행              |
| 리눅스에서 스레드는 어떻게 만들어지나요?  | `clone()` 또는 `pthread_create()`로, 자원을 공유하는 task 생성 |
| 내부적으로 둘은 어떻게 다른가요?      | 둘 다 `task_struct`로 표현되며, 공유 자원의 범위에 따라 역할이 다름      |
##### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
✅ 1. 자식 프로세스가 상태를 알리지 않고 죽을 경우
 📌 개념: 좀비 프로세스(Zombie Process)

> 자식 프로세스가 `exit()`으로 종료되었지만,  
> 부모가 아직 `wait()`으로 **종료 상태를 수거하지 않은 상태**면 → **좀비 프로세스가 됩니다.**

 🧠 이유

- 운영체제는 자식 프로세스가 종료되면, 그 **종료 코드와 PID를 부모가 확인할 수 있도록 PCB 일부를 남겨둡니다.**
    
- 부모가 `wait()` 또는 `waitpid()`를 호출하면 이 정보를 받아가고, 그 후 **운영체제가 자식의 PCB를 정리**합니다.
    
🔁 해결 방법

- 부모는 반드시 자식이 종료되면 `wait()` 호출로 **종료 상태를 수거(collect)**해야 함
    
- 부모가 수거하지 않으면 **좀비 프로세스가 쌓여서 PID 테이블 고갈 가능**
    
 ✅ 2. 부모 프로세스가 먼저 죽는 경우
 📌 개념: 고아 프로세스(Orphan Process)

> 부모 프로세스가 먼저 종료되면, **자식 프로세스는 “고아” 상태**가 됩니다.

 🔧 리눅스 처리 방식

- **고아가 된 자식 프로세스는 자동으로 `init`(PID 1) 또는 `systemd`가 부모가 됩니다.**
    
- 이 과정을 **re-parenting**이라고 합니다.
    


➡️ 이렇게 해서 고아 프로세스도 종료 시 **정상적으로 정리될 수 있도록 운영체제가 보장**합니다.

✅ 요약표

| 상황                       | 처리 방식                               |
| ------------------------ | ----------------------------------- |
| 자식이 먼저 죽고 부모가 wait() 안 함 | 좀비 프로세스 발생 → 부모가 wait()해야 정리        |
| 부모가 먼저 죽음                | 자식은 고아 프로세스가 되고, init(1)이 부모 역할을 맡음 |
| 부모와 자식이 거의 동시에 종료        | 커널이 자동으로 좀비/고아 정리 처리 (init에게 넘김)    |

---
✅ 관련 시스템 콜

|함수|설명|
|---|---|
|`exit()`|프로세스 종료 (상태코드 남김)|
|`wait()`|자식의 종료 상태 수거|
|`waitpid()`|특정 자식만 기다리기 가능|
|`kill(pid, sig)`|프로세스 강제 종료|

---

🔔 정리 한 줄 요약

> **자식이 먼저 종료되면 → 부모가 반드시 `wait()`로 수거해야 하고,  
> 부모가 먼저 죽으면 → 자식은 `init(1)`에게 위탁되어 정리됩니다.**

운영체제는 이 과정을 통해 **프로세스 테이블과 PID를 누수 없이 관리**합니다.
##### 리눅스에서, 데몬프로세스에 대해 설명해 주세요.
✅ 데몬 프로세스란?

> **데몬 프로세스**는 **백그라운드에서 독립적으로 동작하는 프로세스**로,  
> 보통 **시스템 서비스를 제공하거나, 이벤트를 지속적으로 감시**합니다.

- 일반적으로 **터미널(표준 입출력)과 분리되어 실행**
    
- **사용자의 로그인/로그아웃과 관계없이 계속 동작**
    
- 시스템 부팅 시 자동으로 시작되거나, 수동으로 시작되기도 함
    
 ✅ 데몬 프로세스의 주요 특징

| 특징            | 설명                                        |
| ------------- | ----------------------------------------- |
| **백그라운드 실행**  | 터미널과 분리되어 사용자와 직접 상호작용하지 않음               |
| **표준 입출력 없음** | stdin, stdout, stderr를 `/dev/null`로 리다이렉트 |
| **고아 프로세스화**  | 부모가 종료된 후 `init` 또는 `systemd`에게 위탁됨       |
| **무한 루프 구조**  | 보통 이벤트 감시/반복 수행을 위해 while 루프를 가짐          |
| **서비스 역할**    | 로그 기록, 네트워크 요청 수신, 스케줄링 등 시스템 서비스 수행      |

✅ 데몬 프로세스의 예시

|데몬 이름|역할|
|---|---|
|`sshd`|SSH 원격 접속 서비스|
|`crond`|주기적인 작업 스케줄링 (cron job 실행)|
|`httpd`, `nginx`|웹 서버 데몬|
|`systemd`|시스템 서비스 관리자 (init 역할 포함)|
|`journald`|시스템 로그 관리|

✅ 데몬 프로세스 만드는 방법 (일반 구조)

``` c
void daemonize() {     
	pid_t pid = fork();     
	if (pid > 0) exit(0); // 부모 종료 → 고아화   
	setsid();             // 세션 리더 분리 → 터미널과 분리     
	chdir("/");           // 작업 디렉터리 변경     
	umask(0);             // 파일 권한 마스크 해제     
	close(0); close(1); close(2); // stdin, stdout, stderr 닫기
}
```
주요 단계 설명
1. `fork()` 후 부모 종료 → 자식이 고아가 되어 init에게 위탁됨
2. `setsid()`로 세션 리더가 되어 터미널로부터 완전히 분리
3. 현재 디렉터리를 `/`로 변경하여 디렉터리 잠금 방지
4. 파일 모드 마스크 제거 (`umask(0)`)로 예측 가능한 파일 권한 설정
5. 표준 입력/출력을 `/dev/null`로 리다이렉트하거나 닫음

---
✅ 데몬은 왜 필요한가?
- **서비스 제공**: 시스템 수준에서 항상 응답할 준비를 하고 있어야 하는 경우
- **비동기 감시**: 이벤트(네트워크, 파일 변화 등)를 지속적으로 모니터링해야 할 때
- **자동화 작업**: 백업, 로그 수집, 보안 감시 등 반복 작업 실행
    
 ✅ 정리

| 항목    | 설명                                     |
| ----- | -------------------------------------- |
| 정의    | 백그라운드에서 독립적으로 실행되는 시스템 서비스 프로세스        |
| 주요 특징 | 터미널 없음, init/systemd에 위탁, 지속 실행        |
| 대표 예시 | sshd, crond, nginx, systemd            |
| 생성 방식 | fork → setsid → chdir → umask → I/O 분리 |
##### 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
✅ 리눅스 프로세스 트리의 루트: `init` 또는 `systemd` 프로세스

 📌 기본 정보

| 항목    | 설명                                                     |
| ----- | ------------------------------------------------------ |
| 이름    | `init` (전통적) / `systemd` (현대 리눅스)                      |
| PID   | 항상 **1번(PID 1)**                                       |
| 역할    | **시스템에서 최초로 실행되는 사용자 공간 프로세스**                         |
| 실행 시점 | **커널 부팅 직후**, 사용자 공간 진입 시                              |
| 실행 위치 | `/sbin/init`, `/lib/systemd/systemd`, `/bin/systemd` 등 |
 ✅ 어떤 역할을 하나요?

 🔧 시스템 전체 프로세스 트리의 "루트 노드"
- 커널이 부팅을 마치고 사용자 공간으로 넘어갈 때 **가장 먼저 실행되는 프로세스**
- 이후 모든 **서비스, 데몬, 셸, 사용자 프로세스**는 **직접 또는 간접적으로 init/systemd의 자식 또는 후손**
    
 🧼 고아 프로세스 수거

- 부모가 먼저 죽은 **고아 프로세스**는 자동으로 `PID 1`의 자식으로 재귀속(re-parenting)
- 해당 프로세스가 죽을 때 **`init`이 대신 `wait()` 호출로 좀비 정리**
    
 🛠 시스템 서비스 초기화 및 관리
- 전통적 `init`: `/etc/inittab` 기반 단계적 실행
- 현대 `systemd`: `.service`, `.target` 단위로 병렬 처리 및 의존성 관리
    

---
 ✅ 트리 구조 예시 (`pstree` 명령어)

bash

복사편집

`systemd─┬─sshd───bash───vim         ├─cron         ├─NetworkManager         └─nginx───nginx`

➡ 위 트리에서 `systemd`가 루트이며, 모든 프로세스는 직간접적으로 그 하위에 존재

---

 ✅ PID 1이 가지는 특별한 속성

| 기능            | 설명                                           |
| ------------- | -------------------------------------------- |
| 좀비 수거         | 고아 자식의 상태를 수거하여 자원 해제                        |
| signal 무시/필터링 | SIGKILL을 포함한 대부분의 신호 무시 가능                   |
| 재부팅/셧다운 트리거   | 시스템 종료는 PID 1을 통해 수행됨 (`reboot`, `shutdown`) |

---

✅ 정리

|항목|내용|
|---|---|
|루트 프로세스|`init` 또는 `systemd`|
|PID|항상 1번|
|주요 역할|사용자 공간 최초 실행, 프로세스 트리의 뿌리, 서비스 초기화 및 고아 프로세스 정리|
|실행 시점|커널 부팅 직후 사용자 공간 진입 시|
|사용자 정의 가능 여부|일부 리눅스에서는 대체 가능 (`runit`, `upstart`, 등)|

---

### 4. 프로세스 주소공간에 대해 설명해 주세요.
##### 설명
✅ 프로세스 주소 공간이란?

> 운영체제가 **각 프로세스에게 독립적인 가상 메모리 공간을 할당**한 것.  
> 각 프로세스는 자신만의 **4GB(32bit) 또는 128TB(64bit)** 주소 공간을 가지며,  
> 다른 프로세스와 **메모리를 공유하지 않습니다** (보안, 안정성 보장).

 ✅ 프로세스 주소 공간의 주요 영역 (일반적인 구성 순서)


```text
(상위 주소) 
+--------------------+ 
| 커널 영역 (유저 접근 불가) | 
+--------------------+  ← 커널 전용 (공유 영역) 
| Stack              | 
| ↓                  | 
| 함수 호출/지역 변수 |
+--------------------+ 
| Heap               | 
| ↑ malloc/new       | 
+--------------------+ 
| BSS                | 
| 초기화되지 않은 전역/static 변수 |
+--------------------+
| Data               | 
| 초기화된 전역/static 변수 |
+--------------------+ 
| Text (Code)        |
| 프로그램 명령어/코드 |
+--------------------+ 
(하위 주소)
```
🔍 각 영역 설명

| 영역             | 설명                                                     |
| -------------- | ------------------------------------------------------ |
| **Text**(Code) | 프로그램의 실행 코드 (명령어) 저장, 보통 읽기 전용                         |
| **Data**       | 초기화된 전역변수 및 static 변수                                  |
| **BSS**        | 초기화되지 않은 전역/static 변수 (메모리는 0으로 초기화됨)                  |
| **Heap**       | 동적 메모리(`malloc`, `new`)가 할당되는 공간. 런타임 중 확장됨            |
| **Stack**      | 함수 호출 시 사용되는 공간 (지역 변수, 리턴 주소 등). 호출마다 쌓이고 호출 종료 시 사라짐 |
✅ 왜 이렇게 나눌까?

- **보안**: 코드 영역은 읽기 전용으로 두어 악성 코드 삽입을 막음
- **유연성**: 힙과 스택은 동적으로 커질 수 있도록 **반대 방향**으로 확장
- **관리 용이**: 운영체제는 영역별로 접근 권한, 크기 제한 등을 설정 가능
    
✅ 커널과 유저 영역 분리
- 유저 프로세스는 **자기 주소 공간의 윗부분(높은 주소)**에 있는 **커널 영역에 접근 불가**
- 커널 모드일 때만 접근 가능 → 시스템 콜을 통해 간접적으로만 커널 기능 사용 가능
    
---
 ✅ 요약

| 구분    | 설명                                   |
| ----- | ------------------------------------ |
| 정의    | 프로세스가 실행될 때 운영체제가 제공하는 독립된 가상 메모리 공간 |
| 주요 구성 | Text, Data, BSS, Heap, Stack, 커널 영역  |
| 목적    | 보안 격리, 자원 보호, 프로세스 간 독립성 유지          |
| 관리 방법 | `MMU`, 페이지 테이블, `/proc/<pid>/maps` 등 |

##### 초기화 하지 않은 변수들은 어디에 저장될까요?
✅ 초기화하지 않은 변수들은 어디에 저장될까?

> **초기화하지 않은 전역 변수와 static 변수는 `BSS (Block Started by Symbol)` 영역에 저장됩니다.**

 📌 BSS 영역이란?
- **초기값이 없는 전역/정적 변수**들이 저장되는 프로세스 주소 공간의 **정적 메모리 영역**
- 프로그램이 시작될 때 **운영체제가 자동으로 0으로 초기화**해 줍니다.
- 즉, 코드에선 초기화하지 않았지만 **실제로는 0값을 갖고 시작합니다.**
    
 ## ✅ 왜 BSS를 따로 두는가? (정확한 이유)
1️⃣ 실행 파일 크기 감소 (디스크 공간 절약)

- `Data` 영역은 **초기값을 포함하므로, 실행 파일 내에 실제 바이너리 데이터로 저장**됩니다.  
    예: `int x = 100;` → 실행 파일 안에 0x64 저장됨
    
- 반면 `BSS`는 **초기값이 없고 0으로만 초기화되므로**,  
    **실행 파일 안에 데이터가 포함되지 않음**  
    → 단순히 “이 변수 크기만큼 공간이 필요해요”라고 **기록만 함**
    

`$ size a.out    text	   data	    bss	    dec	    hex	filename    1024	   100	    400	    1524	  5f4	a.out`

➡ `bss`는 **RAM에서만 400바이트 잡히고, 실행 파일 용량에는 포함되지 않음**

---
2️⃣ 로딩 속도 및 메모리 사용 최적화

- `Data`는 파일에서 읽어야 하므로 **디스크 I/O가 발생**
    
- `BSS`는 **메모리에서 바로 0으로만 초기화**되므로 **로딩 시 빠름**
    
- 운영체제는 `BSS` 영역을 **익명 페이지로 할당하고 memset(0) 처리**만 하면 됨
    

---
3️⃣ 메모리 보호 및 구분성 확보

- BSS와 Data를 구분함으로써:
    
    - **읽기 전용 섹션 (코드)**,
        
    - **읽기/쓰기 가능 영역 (data/bss)**,
        
    - **동적 힙, 스택 영역** 등을 **명확하게 분리 가능**
        
- 이는 **링커, 로더, 디버거, 보안 도구들이 영역별 권한을 다르게 설정**할 수 있게 해줌
        

✅ 메모리 영역별 정리

| 변수 종류                 | 저장 영역   |
| --------------------- | ------- |
| 초기화된 전역/static 변수     | Data 영역 |
| 초기화되지 않은 전역/static 변수 | BSS 영역  |
| 지역 변수 (함수 안)          | Stack   |
| 동적 할당 변수 (`malloc`)   | Heap    |

 🔔 요약

> **초기화하지 않은 전역변수와 static 변수는 BSS 영역에 저장되며,  
> 실행 시점에 운영체제가 자동으로 0으로 초기화해 줍니다.**

초기화하지 않은 지역 변수는 어디에 저장될까?

> ✅ **초기화하지 않은 지역 변수는 `Stack` 영역에 저장됩니다.**

- 함수 내에서 선언된 변수는 무조건 **Stack에 위치**
    
- 초기화하지 않으면, 해당 변수의 메모리는 **초기값 없이 할당**되며,  
    → **쓰레기 값(Garbage Value)**가 들어 있습니다.
##### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
✅ 결론 먼저

> ❌ Stack과 Heap은 **처음부터 크게 할당되지 않습니다.**  
> ✅ 대신, **필요에 따라 점진적으로 커지며**,  
> 운영체제는 **미리 정해진 최대 크기 제한**도 둡니다.

✅ Heap의 크기: 동적, `brk()`와 `mmap()`에 의해 증가

🔹 생성 방식

- `malloc()`, `new` 등이 호출되면 내부적으로 **`brk()` 또는 `mmap()`** 시스템 콜을 통해 힙을 확장합니다.
    
- 힙은 **아래에서 위 방향으로 증가**합니다.
    
🔹 최대 크기 제한

- 힙의 최대 크기는 다음으로 제한됩니다:
    - **시스템 가상 메모리 한도**
    - **프로세스 별 리소스 제한 (`ulimit`)**
    - **사용 가능한 물리/스왑 메모리**
        
✅ Stack의 크기: 작게 시작, 제한 있음
 🔹 생성 방식
- 스택은 **함수 호출 시 자동으로 할당되는 지역 변수와 리턴 주소 등**을 담습니다.
- **위에서 아래 방향으로 내려오며 확장**합니다.
- 운영체제는 **스택 오버플로우 방지를 위해 고정된 최대 크기를 설정**합니다.
    
🔹 기본 제한 예시 (리눅스 기준)
- 보통 8MB (스레드마다 다름)
    

➡ 너무 많은 재귀나 대형 배열은 스택 오버플로우를 유발

--- ✅ Stack과 Heap의 실제 동작 그림 (개념도)

```text
`높은 주소  
+------------------+  ← Stack 시작 (높은 주소)   
|   함수 호출      | ← 점점 내려감   
|   지역 변수      |  
+------------------+      
...  
|                  | ← 아직 쓰이지 않은 공간 (Stack ↕ Heap 사이 gap)       ... 
+------------------+  
|   동적 메모리     | ← Heap (malloc 등)   
|   구조체/배열     |  
+------------------+  ← Heap 시작 (낮은 주소)  
낮은 주소`
```

- 이 사이 영역은 **가상 주소 공간만 존재**하고 실제 물리 메모리는 할당되지 않을 수 있음
- Heap과 Stack이 서로를 향해 자라기 때문에, 너무 커지면 **충돌(segfault)** 가능
     ✅ 요약

| 항목  | Heap                    | Stack                         |
| --- | ----------------------- | ----------------------------- |
| 방향  | 아래 → 위                  | 위 → 아래                        |
| 크기  | 동적으로 증가 (`brk`, `mmap`) | 고정된 최대치 있음 (`ulimit -s`)      |
| 초깃값 | 작음 (필요 시 확장)            | 작음 (보통 수 MB 수준)               |
| 제한  | 가상 메모리/ulimit에 의해 제한됨   | 기본 8MB (스레드마다 다름)             |
| 위험  | 과도한 malloc → OOM        | 과도한 재귀/대형 배열 → Stack overflow |

🔔 핵심 한 줄 요약

> Stack과 Heap은 주소 공간 그림에선 넓게 보이지만,  
> 실제로는 **작게 시작해서 필요할 때 동적으로 늘어나며**,  
> **운영체제가 명확한 최대 크기를 제한하고 관리**합니다.
##### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
✅ 결론 먼저

> **Stack이 Heap보다 일반적으로 더 빠릅니다.**

---
✅ 왜 Stack이 더 빠른가?

1️⃣ **메모리 할당/해제 방식의 차이**

| 항목    | Stack                                 | Heap                             |
| ----- | ------------------------------------- | -------------------------------- |
| 할당 방식 | **컴파일 타임 or 함수 호출 시** 자동 할당           | 런타임 시 `malloc`, `free` 등으로 동적 할당 |
| 해제 방식 | 함수 종료 시 자동 해제                         | 명시적으로 `free()` 해야 함              |
| 구조    | 선입후출(Last-In-First-Out, LIFO) → 매우 단순 | 자유로운 크기/위치로 할당 → 관리 복잡           |

- 스택은 단순한 포인터 연산만으로 **몇 사이클 이내에 메모리 할당/해제**가 가능합니다.
- 반면 힙은 메모리 풀에서 **적절한 블록을 찾고, 병합, 분할, 프래그멘테이션 관리** 등 오버헤드가 큽니다.
    
2️⃣ **캐시 적중률(Locality)의 차이**

- 스택은 지역 변수 위주로 사용되며, **주소가 연속적**이라 **CPU 캐시(Locality of Reference)**에 잘 맞습니다.
    
- 힙은 할당 위치가 **분산되고 불규칙**하여 캐시 효율이 떨어질 수 있습니다.
    

 3️⃣ **함수 호출 최적화의 효과**

- 스택은 컴파일러 최적화 대상입니다 (e.g., 레지스터 할당, 스택 프레임 미사용 등)
    
- 반면, 힙 접근은 컴파일러가 더 조심스럽게 접근하며 일반적으로 비용이 큽니다.
    
📌 접근 자체는 같지만 **“주소 계산 및 접근 방식”**에서 오버헤드 차이가 납니다:

|항목|Stack|Heap|
|---|---|---|
|주소 계산 방식|컴파일 타임에 결정됨 (`rbp - 4` 등)|런타임에 포인터 간접 참조 (`ptr + offset`)|
|간접 접근|❌ 없음|✅ 객체 참조 필요 (`ref.field`)|


 ✅ 요약

|비교 항목|Stack|Heap|
|---|---|---|
|접근 속도|✅ 빠름|❌ 상대적으로 느림|
|할당/해제 비용|매우 낮음|상대적으로 높음|
|캐시 적중률|높음 (연속성 좋음)|낮음 (주소 불규칙)|
|사용 용도|지역 변수, 빠른 처리|동적 크기, 수명 긴 객체|

---

🔔 핵심 한 줄 요약

> **Stack은 구조가 단순하고 연속적이기 때문에 Heap보다 빠른 접근 속도를 보입니다.**  
> 하지만 용도와 상황에 따라 **Heap도 필수적인 메모리 영역**입니다.

필요하시면 실제 캐시 히트율, glibc `malloc` 알고리즘(`ptmalloc`), 스택 프레임 구조 등도 설명드릴 수 있습니다.
##### 다음과 같이 공간을 분할하는 이유가 있을까요?
운영체제가 **프로세스 주소 공간을 Text / Data / BSS / Heap / Stack 등으로 명확히 분할하는 이유는**, 단순한 구조적 나눔이 아니라 **성능, 보안, 안정성, 효율성**을 모두 고려한 **합리적 설계 결정**입니다.
 ✅ 1. **보안 (Security)**

🔐 서로 다른 권한 적용

- **Text 영역**: 읽기만 가능 (`r--`) → 코드 변조 방지    
- **Data / BSS / Heap / Stack**: 읽기-쓰기 가능 (`rw-`)
- **Stack 실행 금지 (NX/XD 비트)**: 버퍼 오버플로우로부터 보호
    
 예시:

- 스택에 코드 삽입 후 실행 시도 → `Segmentation Fault` 발생  
    (스택은 실행 권한 없음)
    
✅ 2. **안정성 (Stability)**

🔄 서로 독립적으로 확장 가능

- **Heap**은 아래 방향으로, **Stack**은 위 방향으로 확장  
    → 충돌 위험을 막기 위해 **중간에 여유 공간(gap)** 설정
    
 📉 예외 상황 관리

- **Stack Overflow**, **Heap Overflow** 시 별도 에러 처리 가능  
    → 메모리 구조가 구분되어 있어 **오류 위치 파악이 쉬움**
    
 ✅ 3. **성능 최적화 (Performance)**
 💡 캐시 지역성(Locality)

- Stack은 연속된 함수 호출 → 지역성 좋음 → 캐시 효율 높음
    
- Heap은 동적이지만, 영역 분리 덕분에 캐시 성능 최적화 가능
    
🧠 MMU/페이지 테이블 관리 최적화
- 서로 다른 영역에 **다른 페이지 속성** 적용 가능 (예: 공유 여부, 권한)
    

✅ 4. **유지보수/디버깅 편의성**

- 디버깅 시 `BSS`, `Heap`, `Stack` 등 메모리 영역이 구분되어 있으면  
    **오류 추적, 변수 추적, 영역별 할당 문제 확인이 쉬움**
    
 ✅ 5. **시스템 호출/링커/로더 지원을 위한 표준화**

- `ELF`(Executable and Linkable Format) 파일 포맷에서는  
    `.text`, `.data`, `.bss`, `.rodata` 등 섹션이 표준화되어 있음
    
- 커널은 이를 기반으로 **정확한 메모리 맵을 생성하고, 페이지 테이블을 설정**함
    

✅ 한눈에 보는 영역별 목적

|영역|목적|
|---|---|
|**Text**|코드 저장, 읽기 전용, 보안 강화|
|**Data**|초기화된 전역/static 변수 저장|
|**BSS**|0으로 초기화될 전역/static 변수 (공간만 필요)|
|**Heap**|런타임 동적 메모리 할당 (유연성 중심)|
|**Stack**|함수 호출, 지역 변수 저장 (속도 중심)|

🔔 핵심 요약

> **프로세스 주소 공간을 나누는 이유는 단순한 관습이 아니라**,  
> **보안, 성능, 에러 처리, 디버깅, 시스템 효율까지 고려한 운영체제의 설계 최적화 결과**입니다.
##### 스레드의 주소공간은 어떻게 구성되어 있을까요?
✅ 핵심 결론

> **스레드는 같은 프로세스 내에서 실행되므로, 주소 공간을 프로세스와 공유합니다.**  
> 다만, **스레드마다 고유한 Stack이 존재하며**, 나머지 메모리 영역은 전부 공유됩니다.

✅ 스레드의 주소 공간 구성 요약

|메모리 영역|스레드 간 공유 여부|설명|
|---|---|---|
|**Text (Code)**|✅ 공유|실행 코드|
|**Data**|✅ 공유|초기화된 전역/static 변수|
|**BSS**|✅ 공유|초기화되지 않은 전역/static 변수|
|**Heap**|✅ 공유|`new`, `malloc` 등 동적 할당 메모리|
|**Stack**|❌ **비공유**|**스레드마다 고유** (지역 변수 등 저장)|
|**Thread-Local Storage (TLS)**|❌ 비공유|`__thread` 또는 `ThreadLocal<T>`와 같은 스레드 전용 데이터|

✅ 그림으로 이해하는 구조
```
공유된 프로세스 주소 공간
──────────────────────────── 
|       Text (Code)        | ← 모든 스레드 공유
|       Data / BSS         | ← 전역 변수 공유 
|       Heap               | ← new, malloc 등 공유 ────────────────────────────
|       Stack (Thread 1)   | ← 고유
──────────────────────────── 
|       Stack (Thread 2)   | ← 고유
──────────────────────────── 
|       Stack (Thread N)   | ← 고유
────────────────────────────

```


- 각 스레드는 **자신만의 스택**을 갖고, 함수 호출/지역 변수 등을 그 위에 올림
- 그 외 메모리 공간은 **전부 공유**됨 → 자원 공유, 동기화 문제 발생 가능
    
✅ 그럼 스택은 어디에 생기나요?

- 스레드 생성 시 커널이 별도 **스택 메모리 영역**을 할당
    
- 보통 `pthread_create()`나 Java `Thread` 생성 시 내부적으로 호출
    
- Linux에서는 스레드 스택 크기 기본값은 `ulimit -s`로 확인 가능 (보통 8MB)
##### "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.
✅ 결론부터 말씀드리면:

> **네, 스택 영역은 자료구조의 스택(LIFO)과 매우 밀접하게 관련이 있고**,  
> **힙 영역은 자료구조의 힙(priority queue 구조)와는 직접적인 관련은 없습니다.**  
> 단지 **"자유롭게 메모리를 할당하는 공간"**이라는 의미에서 **Heap이라는 이름이 붙은 것**입니다.

---
 ✅ 1. 스택(Stack) 영역 ≒ 자료구조 스택(LIFO)

|관점|설명|
|---|---|
|이름 유래|자료구조의 **스택 (Last-In-First-Out)** 구조에서 유래|
|저장 내용|**함수 호출 시의 지역 변수, 리턴 주소, 매개변수 등**|
|할당/해제 방식|**컴파일러/CPU가 자동으로 스택 프레임을 push/pop**함|
|동작 구조|함수 호출 시 스택 프레임 push → 리턴 시 pop → **완벽한 LIFO**|

➡ 이 구조는 자료구조 스택과 거의 동일한 **LIFO 방식**으로 메모리를 할당/회수합니다.

 ✅ 2. 힙(Heap) 영역 ≠ 자료구조 힙(Binary Heap, Priority Queue)

| 관점       | 설명                                                             |
| -------- | -------------------------------------------------------------- |
| 이름 유래    | "무질서하게, 자유롭게 흩어진 공간"이라는 **비유적 의미**의 "Heap"에서 유래                |
| 저장 내용    | **런타임에 동적으로 할당된 객체/메모리 (`new`, `malloc`)**                     |
| 할당/해제 방식 | **프로그래머가 명시적으로 `free`, `delete`해야 함 (또는 GC가 정리)**              |
| 내부 동작    | 실제 구현은 다양한 메모리 풀/알고리즘 (`ptmalloc`, `dlmalloc`, `jemalloc`)로 관리 |

➡ 운영체제의 힙은 **자료구조의 힙(우선순위 큐)**과는 전혀 무관하며,  
**"구조화되지 않은, 동적 할당 메모리 풀"이라는 뜻에서의 heap**입니다.

 ✅ 정리

|항목|자료구조와의 관계|
|---|---|
|**Stack 영역**|✅ 자료구조 스택(LIFO)과 **거의 동일한 방식**으로 동작|
|**Heap 영역**|❌ 자료구조 힙과는 무관, 단지 **동적으로 메모리를 관리하는 영역**|

##### IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
✅ 결론부터

> **Shared Memory는 일반적으로 각 프로세스의 주소 공간 중 “Heap 근처” 또는 “mmap 영역”에 매핑됩니다.**  
> **고정된 위치는 아니며**, OS가 가상 주소 공간의 여유 영역에 매핑합니다.  
> **Heap, Stack과 별도로 존재하지만 가상 메모리 상에 들어갑니다.**

 ✅ 왜 Heap 근처(mmap 영역)에 들어가는가?

1. **동적으로 크기를 지정하기 때문에**
    
    - 공유 메모리는 `malloc`처럼 크기를 지정해서 요청
        
    - Stack처럼 컴파일 타임에 위치/크기가 정해지는 것이 아님
        
2. **`mmap()` 시스템 콜로 할당되기 때문에**
    
    - 공유 메모리는 내부적으로 `mmap()` 또는 `shmat()`을 통해 **특정 가상 주소에 매핑**
        
    - `mmap()`으로 할당된 메모리는 보통 **Heap과 Stack 사이의 mmap 영역**에 들어감
        
3. **주소 공간 격리를 유지하면서도 메모리 공유가 가능**
    
    - 실제 메모리는 공유되지만, **각 프로세스의 가상 주소 공간에 독립적으로 매핑**됨
        
✅ 왜 이런 방식으로 구현하는가?

| 이유                    | 설명                                              |
| --------------------- | ----------------------------------------------- |
| 주소 공간 격리 유지           | 실제 물리 메모리는 공유하되, 각 프로세스의 **가상 주소 공간은 독립적으로 구성** |
| 유연한 매핑 지원             | `mmap()`은 원하는 주소에 매핑하거나 OS에 위임할 수 있어 유연함        |
| 보안 및 권한 제어 가능         | 매핑 시 `PROT_READ`, `PROT_WRITE` 등을 설정 가능         |
| 빠른 성능 (Zero-copy IPC) | 커널을 거치지 않고 **직접 메모리 접근으로 통신 가능**                |

---
 ✅ 요약

|질문|답변|
|---|---|
|공유 메모리는 주소 공간의 어디에 들어가나요?|보통 **Heap과 Stack 사이의 mmap 영역**에 매핑됩니다|
|고정된 위치인가요?|❌ 아니며, `mmap()`으로 **동적으로 배정된 가상 주소**에 매핑됩니다|
|그 이유는 무엇인가요?|주소 공간의 유연성 확보, 격리 유지, 성능 최적화, 시스템 콜 동작 방식 때문입니다|
#####  스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
✅ 1. 스택(Stack) 영역의 크기
 📌 크기 결정 시점

- **스레드 생성 시** 운영체제가 스택의 크기를 결정합니다.    
- 메인 스레드: 시스템 기본값 (보통 리눅스는 **8MB**)
- 서브 스레드: `pthread_attr_setstacksize()` 또는 JVM 설정 등으로 조정 가능
    

 📌 사용자 변경 가능 여부

| 변경 방식                         | 설명                                    |
| ----------------------------- | ------------------------------------- |
| `ulimit -s`                   | 현재 세션의 **스택 최대 크기(KB 단위)** 조정 가능      |
| `setrlimit()`                 | 프로그램 내부에서 **런타임 시 한도 설정** 가능 (C에서 사용) |
| `pthread_attr_setstacksize()` | POSIX 스레드 생성 시 스택 크기 지정 가능            |
| Java 옵션                       | `-Xss` → JVM 스레드 스택 크기 지정             |


➡ 일반 사용자도 가능. **로그인 쉘, 스크립트, 실행 시마다 적용** 가능

---
✅ 2. 힙(Heap) 영역의 크기

📌 크기 결정 시점

- **런타임에 필요할 때 동적으로 증가**
    
- `malloc()`, `new` 등으로 요청한 만큼 커짐
    
- 내부적으로는 `brk()` 또는 `mmap()`으로 힙을 확장
    
📌 최대 크기 제한

- 힙은 이론적으로 매우 크지만, 실제 한도는 다음에 의해 제한됩니다:
    

| 제한 요소       | 설명                                         |
| ----------- | ------------------------------------------ |
| `ulimit -v` | 가상 메모리 총량 제한 (heap + stack + code 등 포함)    |
| 시스템 메모리     | 실제 사용 가능한 물리 메모리 + 스왑                      |
| OS 설정       | 일부 시스템에서는 `overcommit`, `rlimit`에 따라 제한 가능 |
| JVM 옵션      | Java에서는 `-Xmx`로 최대 힙 크기 지정                 |
 ✅ 요약표

| 항목     | 크기 결정 시점    | 사용자 조정 가능?    | 조정 방법 예시                                           |
| ------ | ----------- | ------------- | -------------------------------------------------- |
| **스택** | 스레드 생성 시    | ✅ 가능          | `ulimit -s`, `-Xss`, `pthread_attr_setstacksize()` |
| **힙**  | 런타임 중 동적 확장 | ✅ 가능 (상한선 설정) | `ulimit -v`, `-Xmx`, `setrlimit()` 등               |

 🔔 핵심 요약

> **스택은 스레드 생성 시 크기가 설정되며, 힙은 런타임 중 점진적으로 커지지만 상한은 운영체제나 사용자 설정으로 제한됩니다.**  
> 일반 사용자도 `ulimit`, 실행 옵션 등을 통해 **크기 조정이 가능합니다.**

### 5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.
- 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
- 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
- preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
- Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?

### 6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
- 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
- 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
- 컨텍스트 스위칭은 언제 일어날까요?

### 7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
- RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
- 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
- 동시성과 병렬성의 차이에 대해 설명해 주세요.
- 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
- FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?
- 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?
- 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?

### 8. 뮤텍스와 세마포어의 차이점은 무엇인가요?
- 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
- Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
- 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?

### 9. Deadlock 에 대해 설명해 주세요.
- Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
- 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
- 어떤 방식으로 예방할 수 있을까요?
- 왜 현대 OS는 Deadlock을 처리하지 않을까요?
- Wait Free와 Lock Free를 비교해 주세요.

### 10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.
- 링커와, 로더의 차이에 대해 설명해 주세요.
- 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
- JIT에 대해 설명해 주세요.
- 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
- Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
- 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?

### 11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
- Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
- 메시지 큐는 단방향이라고 할 수 있나요?

### 12. Thread Safe 하다는 것은 어떤 의미인가요?
- Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
- Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
- Race Condition 이 무엇인가요?
- Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?

### 13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.

### 14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.

### 15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)

### 16. Thrashing 이란 무엇인가요?


### 17. 가상 메모리란 무엇인가요?


### 18. 세그멘테이션과 페이징의 차이점은 무엇인가요?

### 19. TLB는 무엇인가요?

### 20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.


### 21. 페이지 교체 알고리즘에 대해 설명해 주세요.

### 22. File Descriptor와, File System에 에 대해 설명해 주세요.
### 23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
