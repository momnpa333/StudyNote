
#### 1. 자기소개
##### 자기소개
안녕하십니까, 토스 페이먼츠에 지원한 권다운입니다.  

저는 안정적으로 서비스를 제공할 수 있도록 시스템 아키텍처와 성능 최적화에 꾸준히 관심을 가져왔습니다.  
특히, Redis 기반의 분산 락을 도입하여 데이터 일관성을 보장하거나, 조회수가 몰리는 API에서 병목 현상을 해결한 경험이 있습니다.  
이처럼 실제 문제를 분석하고 해결하며 사용자 경험을 개선하는 과정에 보람을 느끼고 있습니다.

저는 주어진 문제에 논리적으로 접근하고, 꾸준히 개선하며 더 나은 서비스를 만들어가는 데에 노력하였고, 이를 통해 YBM넷의 기술적 성장과 서비스 고도화에 기여하고 싶습니다.
#### 2. 레디스를 활용한 이유
##### 1. 관계형 데이터베이스를 활용했을 때
관계형 데이터베이스만 사용했을 때의 한계

1. **쓰기 부하에 약함**

- 유저 프로필 조회는 매우 자주 발생하는 이벤트이며, 조회할 때마다 **조회수 증가를 위해 쓰기 연산이 발생**합니다.
    
- 관계형 데이터베이스는 일반적으로 **쓰기 연산(INSERT/UPDATE)**에 대해 **트랜잭션 처리, WAL, 인덱스 관리 등 부가 작업이 많아**, I/O 부하가 큽니다.
    
- 특히 **인기 유저에게 트래픽이 몰리는 경우, 특정 row에 대해 집중적인 업데이트**가 발생하고, 이는 **락 경합과 디스크 병목**으로 이어져 전체 성능 저하를 유발합니다.
    

2. **락 경합**

- RDB는 row-level lock이나 shared/exclusive lock을 통해 정합성을 보장하지만, 이로 인해 **다중 트랜잭션 간 충돌**이 발생할 수 있습니다.
    
- 실제로도 Redisson 락을 도입한 이후 락 범위가 커졌을 때 병목이 발생했으며, 이는 RDB 환경에서도 **락을 통한 동시성 제어가 성능 병목이 될 수 있음**을 의미합니다.
    

 3. **실시간 응답 지연**

- 유저가 프로필을 클릭할 때마다 DB에 접근해 조회수를 UPDATE하면, **읽기와 쓰기 모두에서 지연**이 발생합니다.
    
- TPS가 중요한 실시간 서비스에서는 수 밀리초의 차이도 UX에 영향을 줄 수 있으며, DB 접근 없이 Redis만으로 처리하는 쪽이 **현저히 빠른 응답 속도**를 보장합니다.
    

---

✅ Redis를 함께 사용한 이유

|항목|관계형 DB|Redis|
|---|---|---|
|쓰기 처리 속도|느림 (디스크 기반, 락 존재)|빠름 (메모리 기반, 비동기 또는 atomic 연산)|
|동시성 제어|트랜잭션 기반, 경합 가능성 있음|분산 락 또는 atomic 연산으로 제어|
|실시간 처리|지연 발생 가능|낮은 지연 (ms 단위)|
|조회수 증가 같은 카운터 연산|락 필요, 경합 심함|`INCR` 한 줄로 원자적 처리 가능|

---

💡 정리

> 조회수 증가처럼 **읽기와 쓰기 모두가 빈번하게 발생하는 실시간 로직**은, RDB만으로 처리할 경우 **성능 저하, 락 경합, 응답 지연** 등의 문제가 발생할 수 있습니다.
> 
> 반면, **Redis는 메모리 기반의 빠른 처리와 원자적 연산 기능**을 제공하며, **RDB의 단점을 보완**할 수 있어 함께 사용하는 것이 적절합니다.
##### 2. 관계형 데이터베이스도 메모리 버퍼를 통해 io접근을 최소화 할수 있는데 굳이 redis가 필요했나요?
관계형 데이터베이스도 버퍼 캐시를 사용해 자주 조회되는 데이터를 메모리에 올려두고 디스크 I/O를 줄이지만, 기본적으로 디스크 기반 구조이기 때문에 트랜잭션 처리, 인덱스 관리, WAL 등의 부가 작업이 항상 수반됩니다. 특히, 쓰기 연산이 빈번할 경우에는 락 경합이나 디스크 병목으로 인해 성능 저하가 발생할 수 있습니다.

반면 Redis는 처음부터 끝까지 메모리에서 동작하고, 조회수 증가 같은 단순한 연산은 `INCR` 하나로 원자적으로 처리할 수 있어서 **락 없이도 빠르고 정확한 처리**가 가능합니다.

실제로 기존에는 Redis에서 값을 읽고 +1 후 다시 저장하는 방식이었는데, Redisson 분산락으로 인한 병목이 생겼고, INCR로 바꾸면서 TPS가 580 → 1117로 거의 두 배 가까이 향상됐습니다.

이런 경험을 통해 실시간성이 중요한 기능에서는 Redis가 단순 캐시 그 이상으로 중요한 역할을 한다는 것을 체감했습니다.
##### 관계형 DB도 버퍼 캐시로 I/O 줄이는데, Redis가 근본적으로 어떤 점에서 더 유리하다고 보시나요?
> 관계형 DB는 일부 데이터만 메모리 버퍼에 유지하고, 나머지는 디스크에 존재하므로, 캐시 적중이 안 되는 경우엔 디스크 I/O가 불가피합니다. 또한 트랜잭션 처리, 인덱스 업데이트, 로그 기록 등 부가 작업도 함께 동반되어 처리 경로가 길어집니다.
> 
> 반면 Redis는 모든 데이터를 메모리에 상주시켜 처리하므로 **디스크 I/O 자체가 거의 없고**, 모든 연산이 **O(1) 수준의 빠른 응답 속도**를 가집니다. 또한 별도의 인덱스나 SQL 실행 계획이 없기 때문에 단순 연산에 훨씬 유리합니다.
> 
> 특히 실시간 트래픽이 집중되는 상황에서는 Redis가 훨씬 예측 가능한 성능을 보여줬고, 락 최소화와 비동기 처리를 함께 활용해 응답 시간을 안정적으로 유지할 수 있었습니다.
##### 트랜잭션 처리, 인덱스 업데이트, 로그 기록은 왜 시간이 오래걸리나요 메모리내에서 처리가 불가한가요

✅ 왜 메모리 내에서만 처리할 수 없는가?

1. **지속성(내구성, Durability)을 보장해야 하므로 디스크 I/O가 필요함**

- RDB는 **ACID의 Durability**(트랜잭션 완료된 데이터는 반드시 저장돼야 함)를 보장해야 합니다.
    
- 그래서 쓰기 연산 시, 단순히 메모리에 올리는 것이 아니라 **디스크에 기록**하여 장애 발생 시에도 복구 가능해야 합니다.
    
- 대표적인 방식이 **WAL (Write-Ahead Logging)**으로, 데이터를 변경하기 전에 **변경 로그를 디스크에 먼저 기록**합니다.

2. **인덱스 구조 업데이트는 메모리와 디스크 모두 영향을 받음**

- RDB 인덱스(B+Tree 등)는 보통 **디스크 기반 구조**로 구성되어 있습니다.
    
- INSERT/UPDATE 시 인덱스를 재정렬하거나 노드를 분할해야 할 수 있으며, 이는 디스크 페이지 단위로 접근 및 수정이 필요합니다.
    
- 일부 핫 데이터를 메모리에서 유지하더라도, 결국 변경된 인덱스는 디스크에 반영해야 하므로 **디스크 I/O가 발생**합니다.
    

3. **트랜잭션은 격리성과 정합성을 위해 다양한 부가 작업이 필요**

- 트랜잭션은 단순한 데이터 변경이 아니라, **락 설정**, **MVCC용 undo/redo 로그 관리**, **트랜잭션 ID 추적** 등의 복잡한 메타 작업이 포함됩니다.
    
- 이런 부가 작업은 내부적으로 메모리뿐 아니라 디스크와의 연동 없이 구현하기 어렵습니다.
    
- 예: 다른 트랜잭션이 읽기 전에 변경 사항을 로그로 저장하거나, 롤백 시 복구할 데이터를 남겨야 함.
    

---

❗️즉, 메모리만 써서 빠르게 처리할 수 없는 이유는?

- RDB는 **데이터 정합성과 내구성**을 무엇보다 중요하게 생각하며,
    
- **장애 복구, 트랜잭션 롤백, 인덱스 정합성 보장**을 위해 반드시 디스크 기반 작업을 포함해야 합니다.
    
- 반면 Redis는 **“장애 시 데이터 유실을 허용하더라도 빠른 응답이 더 중요”**한 시스템에 적합하므로, 디스크 작업을 생략하거나 비동기로 처리합니다.
    

---
💡 요약:

> RDB의 트랜잭션 처리, 인덱스 업데이트, 로그 기록은 단순 메모리 연산이 아니라, **지속성과 정합성을 위한 디스크 기록이 필수**입니다.  
> 이 때문에 Redis와 달리 디스크 I/O가 성능 병목이 될 수 있고, 이는 RDB가 안정성과 정확성을 우선시하는 설계 철학에 기반합니다.

---

면접에서는 이 내용을 바탕으로 이렇게 요약하면 좋습니다:

✅ 면접 답변 예시:

> RDB는 단순히 메모리에서 데이터를 처리하는 게 아니라, 장애 복구와 정합성을 보장하기 위해 WAL 기록, 인덱스 업데이트, 트랜잭션 메타데이터 관리 등 **디스크 기반 작업이 필수적**입니다.  
> 반면 Redis는 실시간성이 더 중요한 경우에 메모리 기반으로 동작하면서 이런 부하를 피할 수 있어, 조회수 증가 같은 단순 고빈도 연산에 훨씬 적합했습니다.
#### 3. 레디스 구조
✅ 1. **Redis의 기본 구조: In-Memory Key-Value Store**

- Redis는 **메모리 기반의 Key-Value 저장소**입니다.
    
- 모든 데이터는 **메모리(RAM)**에 저장되며, 선택적으로 디스크에 **백업(AOF, RDB)**을 할 수 있습니다.
    
- 데이터는 Key-Value 쌍으로 저장되며, 다양한 **데이터 타입**을 지원합니다 (단순 문자열뿐만 아니라, 리스트, 집합, 정렬된 집합 등).
    

 ✅ 2. **Redis의 자료구조 (Value 타입)**

|자료형|설명|사용 예시|
|---|---|---|
|**String**|가장 기본적인 자료형. 숫자, 텍스트, JSON 등 모두 저장 가능|`INCR`, `GET`, `SET` 등|
|**List**|순서가 있는 문자열 목록. 양방향 삽입 가능|메시지 큐, 로그|
|**Set**|중복 없는 원소들의 집합|유니크 방문자 목록|
|**Sorted Set (ZSet)**|점수(score)로 정렬되는 집합|랭킹, 우선순위 큐|
|**Hash**|하나의 Key에 여러 필드와 값을 저장|사용자 프로필, 객체 저장|
|**Bitmap / HyperLogLog / Stream**|비트 연산, 근사 카운팅, 로그 수집 등 특수 목적용 자료형|고급 용도|
 ✅ 3. **Persistence (지속성) 구조: AOF & RDB**

- Redis는 메모리 기반이지만, 장애 복구를 위해 데이터를 디스크에 저장할 수 있습니다.
    

|방식|설명|특징|
|---|---|---|
|**RDB (Snapshot)**|일정 시간 간격으로 전체 데이터를 디스크에 저장|빠름, 간단하지만 일부 유실 가능|
|**AOF (Append Only File)**|모든 쓰기 명령을 순차적으로 파일에 기록|장애 복구 시 유리하지만 파일이 큼|
|둘 다 사용 가능|안정성과 성능을 모두 확보할 수 있음||

> Redis는 `fsync()`를 통한 flush 정책도 설정할 수 있어, **쓰기 성능 vs 내구성**을 조절할 수 있습니다.

---
✅ 4. **싱글 스레드 이벤트 루프 기반 구조**

- Redis는 **단일 스레드**로 동작하며, 내부적으로는 **이벤트 루프** 기반으로 동작합니다.
    
- 하나의 클라이언트 요청을 **빠르게 처리한 후 다음 요청으로 이동**합니다 → context switching 없음 → **속도 빠름**
    
- 하지만 하나의 요청이 너무 오래 걸리면 전체 지연이 발생할 수 있으므로, 보통 **짧고 빠른 연산**에 적합합니다.
    
✅ 면접 답변용 요약

> Redis는 메모리 기반의 Key-Value 저장소로, 다양한 자료구조(String, Hash, Set 등)를 지원합니다.  
> 단일 스레드 이벤트 루프 기반 구조로 빠른 응답이 가능하며, `INCR`, `SET`, `GET` 같은 연산이 대부분 O(1) 시간 내에 처리됩니다.  
> 지속성을 위해 RDB 스냅샷이나 AOF 로그를 통해 디스크에 데이터를 저장할 수 있고, 요구사항에 따라 적절한 방식으로 설정 가능합니다.  
> 이런 구조 덕분에 Redis는 캐시, 세션 저장, 실시간 통계, 분산락 등 다양한 목적으로 널리 사용됩니다.

#### 4. 레디스 활용 방법
##### 방법
✅ RedisVisitCount – 조회수 집계용 엔티티
 📦 구조 요약

```java
@RedisHash("VisitCount")
public class RedisVisitCount {    
	@Id 
	private Long hostId;     
	private int dailyVisited;    
	private int totalVisited; 
}
```
✅ 역할

- 특정 유저(`hostId`) 프로필의 **총 조회수**와 **일일 조회수**를 Redis에 저장
    
- 매번 DB에 접근하지 않고도, 조회 요청마다 이 객체의 `visit()` 메서드를 통해 두 카운트를 Redis 상에서 즉시 증가
    
- 주기적 배치 작업 등을 통해 `updateVisited()`를 호출하여 DB에 총 조회수를 반영하고, 일일 조회수를 리셋
    
 ⚙️ 사용 목적 및 장점

- **빠른 카운팅 처리(INCR 대체)**: 객체 필드 기반으로 Redis에서 처리하여 API 응답 지연 최소화
    
- **DB 쓰기 부하 감소**: 조회마다 DB를 UPDATE하지 않고, 일정 주기로만 동기화
    
- **일별 통계와 누적 통계를 동시에 관리** 가능
    
✅ RedisVisitor – 방문자 중복 체크용 엔티티

📦 구조 요약

```java
@RedisHash("Visitor") 
public class RedisVisitor {
	@Id 
	private String id; // "{hostId}:{visitorIp}"    
	private Long hostId;   
	private String visitorIp;     
	private LocalDateTime visitTime; 
}
```
✅ 역할
- 방문자 정보를 Redis에 저장하여 **같은 IP가 동일 host를 짧은 시간 내 반복 조회하는 것을 방지**
    
- TTL을 설정하면, 예를 들어 하루가 지나면 자동으로 만료되어 다음날 방문으로 인정 가능
   
⚙️ 사용 목적 및 장점

- **중복 방문 방지**: `SETNX` 개념처럼 Redis에 키가 없을 때만 조회수 증가 허용
    
- **TTL 기반 자동 만료**: 방문기록은 일정 시간이 지나면 만료되어 재방문 허용
    
- **추후 분석(방문 시간, 지역 등)**을 위한 기록 저장도 가능
    

---
🧠 면접 답변 예시

> 유저 프로필 조회 기능에서 Redis를 활용해 조회수를 관리했습니다.  
> `RedisVisitCount`는 hostId를 기준으로 총 조회수와 일일 조회수를 Redis 객체로 저장하고, 매 요청마다 메모리 내에서 증가시켜 빠르게 처리합니다.  
> 주기적으로 DB와 동기화하여 totalVisited를 반영하며, 일일 조회수는 리셋됩니다.
> 
> 중복 조회 방지를 위해 `RedisVisitor`를 설계했고, hostId와 IP를 조합한 키로 Redis에 저장합니다.  
> 일정 시간 동안 중복 방문이 감지되면 조회수 증가를 막고, TTL 설정을 통해 자동 만료되도록 했습니다.
> 
> 이 구조는 조회수 증가와 중복 방문 처리라는 서로 다른 목적에 맞춰 각각 최적화된 키와 값 설계를 적용한 예입니다.

🚀 성능상의 이점 요약

- 조회 시 DB 접근 없음 → **응답 지연 최소화**
    
- 조회수 증가 및 중복 처리 모두 Redis에서 수행 → **트래픽 분산**
    
- TTL 활용 및 RedisHash 구조 → **유지보수 용이**
##### 왜 Redis는 조회수 증가와 같은 고빈도 쓰기 작업에 적합하다고 판단하셨나요?
> Redis는 메모리 기반 저장소이기 때문에 디스크 I/O가 발생하지 않아, 쓰기 작업 시 빠른 응답 속도를 보장할 수 있습니다.  
> 특히 조회수 증가와 같은 고빈도 쓰기 작업은 `INCR` 명령어를 사용해 락 없이 원자적으로 처리할 수 있어, 동시성이 높아도 안정적으로 동작합니다.  
> 반면, 관계형 데이터베이스는 트랜잭션 처리나 로그 기록, 인덱스 관리로 인해 상대적으로 쓰기 성능이 저하될 수 있어, Redis를 활용하는 쪽이 더 적합하다고 판단했습니다.

---
    
##### 2. **왜 INCR 명령을 사용할 때 락이 필요 없다고 할 수 있나요? 내부적으로 어떤 보장 구조가 있나요?**
`INCR` 명령어는 별도의 락 없이도 안전하게 사용할 수 있습니다.  
Redis는 내부적으로 **싱글 스레드 이벤트 루프 구조**를 사용하기 때문에, 여러 클라이언트에서 동시에 요청이 들어와도 **하나씩 순차적으로 처리됩니다.**  
따라서 `INCR` 같은 연산은 **동시 접근에도 레이스 컨디션이 발생하지 않고**, 항상 **원자적으로 처리됩니다.**  
이 구조 덕분에 고빈도 쓰기 작업에서도 락 없이도 안정성과 일관성을 보장할 수 있습니다.
    
#####  **왜 Redis에 저장한 데이터를 RDB 대신 Redis에 둬야 했나요? 무조건 캐시가 아닌 저장소로도 활용한 이유는 무엇인가요?**
조회수 증가처럼 **짧은 시간 안에 매우 자주 발생하는 쓰기 작업**의 경우, RDB에 직접 접근하면 디스크 I/O와 락 경합으로 인해 성능 병목이 발생할 수 있습니다.  
그래서 저는 Redis를 단순 캐시가 아닌, **임시 저장소(write buffer)**로 사용하여 조회 시마다 Redis에만 값을 증가시키고,  
주기적으로 배치 작업을 통해 RDB와 **비동기적으로 동기화**하는 구조로 설계했습니다.

Redis는 `INCR` 같은 명령이 원자적으로 처리되고, 메모리 기반이라 쓰기 속도가 빠르기 때문에 이런 목적에 매우 적합했습니다.  
이처럼 Redis를 저장소처럼 활용하면, 실시간 처리 성능을 유지하면서도 RDB와의 정합성도 주기적으로 확보할 수 있어 캐시를 넘어서는 활용이 가능하다고 판단했습니다.

    
##### 4. **왜 Redisson 분산락을 사용했나요? 애플리케이션 내부 락(synchronized 등)으로는 안 되었던 이유는 무엇인가요?**
> > 유저 프로필 조회수 증가 로직에서, 특정 유저에게 트래픽이 집중되면 **조회수가 중복 증가하거나 누락되는 현상**이 발생할 수 있어, 동시성 제어가 필요했습니다.  
> 처음에는 `synchronized` 같은 애플리케이션 내부 락도 고려했지만, 이는 **단일 인스턴스에서만 유효**하고 **다중 서버 환경에서는 전혀 효과가 없다는 단점**이 있었습니다.

> 현재는 서버가 1대이긴 하지만, **향후 스케일 아웃을 고려해 설계를 유연하게 가져가는 것이 필요하다고 판단**했습니다.  
> 그리고 이미 조회수 캐싱, 중복 방지 등을 위해 Redis를 사용하고 있었기 때문에, **추가로 Redisson을 도입하는 데 별다른 리소스가 들지 않았고, Redis 기반 분산 락을 쉽게 구현할 수 있었습니다.**

> Redisson의 `RLock`은 Redis 키 기반으로 글로벌 락을 관리해주기 때문에, **멀티 인스턴스 간 자원 충돌을 방지하는 안전한 방법**이었고,  
> 이후에는 Redis의 `INCR` 연산이 원자적이라는 점을 활용해 **락 사용 범위를 최소화**하여 성능을 더욱 개선할 수 있었습니다.
    
##### 5. **왜 Redis의 키 설계에서 날짜, IP, userId 등을 분리해서 포함하셨나요? 단일 키로는 안 되었나요?**
해당 Redis 키는 방문자 중복을 방지하기 위한 용도로 사용되기 때문에, 단순히 `hostId`만으로는 부족합니다.  
예를 들어, 어떤 유저의 프로필을 **같은 방문자가 반복해서 조회**할 때, 매번 조회수를 증가시키면 **조회수가 실제보다 부풀려질 수 있습니다.**

그래서 방문자를 식별할 수 있는 최소 단위인 `IP`를 키에 포함해, **같은 IP에서 동일 host를 반복 조회하더라도 일정 시간 내에는 조회수를 한 번만 증가시키도록** 설계했습니다.

만약 `hostId`만 키로 사용했다면, **모든 방문자가 동일한 Redis 키에 덮어써지므로 중복 방문 여부를 판별할 수 없게 되고**,  
결국 **중복 방문 필터링이 불가능해져 부정확한 통계가 생성되었을 것**입니다.
또한 TTL을 24시간으로 설정한다면, IP + hostId 조합 키가 **하루가 지나면 자동으로 만료되고**,  
**다음날 동일 사용자가 다시 방문해도 새로운 방문으로 인정되도록 구성**됩니다.  
    
    
##### **Redis 데이터를 1시간마다 DB로 동기화한다고 하셨는데, 동기화 주기를 1시간으로 설정한 이유는 무엇인가요? 더 자주 하거나 늦게 하면 안 되나요?**
> 동기화 주기를 1시간으로 설정한 이유는 **데이터 정확성, 시스템 부하, 구현 복잡도 간의 균형**을 고려한 결과입니다.
> 
> 먼저, 조회수 데이터는 서비스 품질에 중요한 지표이긴 하지만, **실시간 정합성이 꼭 필요한 데이터는 아니기 때문에** 약간의 지연을 허용할 수 있습니다.
> 
> 너무 자주(예: 1분, 5분 주기) 동기화를 수행하면, Redis에서 DB로의 쓰기 부하가 많아져 **오히려 성능 이점이 줄어들고**,  
> 너무 늦게(예: 6시간, 12시간 주기) 하면, **Redis 장애 시 유실되는 데이터의 양이 커지고**, 통계 지표 반영도 늦어집니다.
> 
> 따라서 1시간은 다음과 같은 균형점이라고 판단했습니다:

- 서비스 사용량 기준, **1시간 단위면 충분한 통계 주기** 확보 가능
    
- 시스템에 큰 부하 없이 **쓰기 빈도 제어 가능**
    
- 장애 시 유실 가능성을 **작게 제한**하면서도 안정적인 운영 가능
##### **동기화 중 예외가 발생하면 Redis의 데이터는 그대로 남아 있나요? 아니면 유실될 위험이 있나요?**
> 현재 동기화 과정에서 예외가 발생하면, Redis의 데이터가 **DB에 반영되지 않고 유실될 가능성**이 있습니다.  
> 예외 처리를 아직 별도로 구현하지 않았기 때문에, **장애 상황에 대한 대응이 부족한 상태**입니다.
> 
> 다만 이 문제는 인지하고 있었고, 개선을 한다면 다음과 같은 방향을 생각하고 있습니다:

- 동기화 배치 작업에 **예외 로깅 + 실패 시 재시도 로직(Retry)** 추가
    
- 또는 Redis의 조회수 변경 로그를 **큐(Kafka 등)** 또는 **로컬 파일로 적재**하여 **장애 시 재처리 가능성 확보**
    
- Redis 데이터를 초기화하기 전에 **DB 반영 여부 확인 후 처리**하는 구조 적용
    

> 실제 운영에서는 이러한 **예외 처리 및 복구 설계가 핵심적**이기 때문에, 해당 부분은 반드시 개선이 필요한 요소로 인식하고 있습니다.
##### **동기화 실패가 반복되면** 어떻게 처리하시겠습니까?
> 동기화 실패가 반복되면, 단순 예외가 아닌 **지속적 장애 상황**으로 판단해야 하며,  
> 데이터를 보존하면서도 재처리 가능한 구조가 필요하다고 생각합니다.
> 
> 예를 들어, Redis 데이터를 DB에 반영하기 전에 **로그 큐나 동기화 상태 플래그로 보존**하고,  
> 실패 시에는 **재시도 큐에 넣거나, 관리자 알림을 통해 수동 대응**할 수 있도록 구성할 수 있습니다.
> 
> 현재 프로젝트에서는 아직 완전한 복원 구조를 갖추진 않았지만,  
> 이후 운영 안정성을 높이기 위해 **이러한 자동화된 장애 복구 설계도 도입할 계획이었습니다.**
##### Redis는 휘발성이 강한데 조회수를 Redis에만 먼저 저장하고, 나중에 DB로 동기화하는 구조로 간 이유는 무엇인가요?
✅ 면접용 답변 구조

🔹 1. 조회수의 성격 고려: **실시간 반영 vs 완전 정합성**

> 조회수는 정합성이 완벽히 보장되어야 하는 결제 금액이나 주문 수량 같은 핵심 데이터와는 달리,  
> **실시간 반응성과 사용자 체감 경험이 더 중요한 지표**입니다.
> 
> 예를 들어, 누적 조회수나 일일 방문자 수는 **1~2건의 오차보다 빠른 응답이 더 가치** 있는 경우가 많습니다.

---
🔹 2. Redis 선택 이유: **쓰기 병목 해소 + 성능 향상**

> 초기에 DB에 직접 조회수를 누적하는 방식은 **트래픽 집중 시 I/O 병목**이 발생했고,  
> 락 경합 및 쓰기 부하로 인해 **응답 지연 및 TPS 저하** 문제가 생겼습니다.
> 
> Redis의 INCR 연산은 락 없이 빠르게 누적할 수 있고,  
> 캐시 기반으로 **DB 트래픽을 완충하는 레이어**로 활용하기에 적합했습니다.

🔹 3. 동기화 설계로 유실 리스크 완화

> 물론 Redis는 휘발성이 있어 장애 시 유실 위험이 있습니다.  
> 이를 보완하기 위해 **1시간 주기로 DB에 동기화**하고,  
> Redis에서 데이터를 초기화하기 전에 DB 반영 성공 여부를 먼저 확인하도록 설계했습니다.
> 
> 그리고 장애가 치명적인 서비스라면, Redis 외에도 **변경 로그를 별도 큐에 저장**하는 구조로 보완할 수도 있습니다.

✅ 최종 답변 예시

> 조회수는 실시간 반응성이 중요한 지표이기 때문에, 초기에는 성능 병목을 줄이기 위해 **Redis를 캐시 겸 버퍼 계층으로 사용**했습니다.  
> Redis의 INCR 연산은 락 없이 빠르게 동작하고, DB 트래픽을 줄이는 데 효과적이었습니다.
> 
> 유실 가능성은 물론 인지하고 있었으며, 이를 보완하기 위해 **1시간 주기 동기화와 재시도 가능 구조**를 갖췄습니다.  
> 실제로 트래픽 테스트 결과 TPS가 2배 가까이 향상되었고, 사용자 응답 지연도 크게 줄어드는 성과가 있었습니다.
##### 👉 **Redis가 아닌 Kafka 같은 메시지 큐를 써서 로그 기반으로 DB에 반영하는 방식은 고려해보셨나요?**

🔹 1. Kafka 방식의 장점은 인지하고 있다

> Kafka와 같은 메시지 큐를 사용하는 방식은 **조회수 증가 요청을 로그로 기록하고**,  
> 별도 컨슈머가 이를 비동기로 처리해 **DB에 반영하는 구조**입니다.
> 
> 이 방식은 특히 장애 시에도 **메시지를 유실하지 않고 복구 가능**하다는 장점이 있어,  
> **정확한 기록이 중요한 로그성 이벤트나 과금 시스템에 적합**하다고 생각합니다.

 🔹 2. 당시 Redis를 선택한 이유 (비용 vs 효과)
Kafka 도입 시에는 별도의 **브로커, 토픽 관리, 컨슈머 처리 실패 대응, 메시지 순서 보장** 등을 설계해야 하므로  
운영 복잡도가 커지고, 서비스 규모 대비 **과한 설계가 될 수 있다는 판단**이 있었습니다.>
Kafka 도입보다는 **구현 난이도와 인프라 부담이 낮은 Redis 기반 INCR + 주기 동기화 구조**로 우선 접근했습니다.

🔹 3. 확장 가능성도 고려하고 있음

> 다만, 트래픽이 더 커지거나 조회수 데이터의 **정확성 요구가 높아질 경우**,  
> Redis 대신 Kafka 기반 로그 수집 → DB 적재 구조로의 전환도 충분히 고려할 수 있다고 생각합니다.
> 
> 실제로 이후 확장 계획에 대해 논의할 때, Kafka 기반 구조도 검토한 경험이 있습니다.
#### 5. 방문자 수 로직 개선 관련 면접 예상 질문
##### 기존의 방문자 수 로직에서 어떤 문제가 발생했나요?
> **기존 방문자 수 로직은 사용자가 프로필에 접근할 때마다 RDB를 통해 방문 기록을 확인하고 조회수를 증가시키는 구조였습니다.** 하지만 이 방식은 다음과 같은 문제를 일으켰습니다:

1. **동시성 제어 미흡으로 인한 중복 집계**
    
    - 여러 사용자가 동시에 접속할 경우 동일한 방문자(IP)에 대한 중복 기록이 발생했습니다.
        
2. **데이터베이스 접근으로 인한 성능 저하**
    
    - 모든 요청마다 RDB에 접근해 트랜잭션을 수행해야 했기 때문에 TPS가 급격히 떨어지고, API 응답 지연도 발생했습니다.
        
3. **락 경합 및 데드락 가능성 증가**
    
    - 방문 기록을 갱신하면서 공유락(S Lock)과 배타락(X Lock)이 자주 충돌했고, 이는 트랜잭션 병목과 데드락 위험으로 이어졌습니다.
        

---

**이러한 문제를 해결하기 위해 방문자 중복 체크와 조회수 관리를 Redis로 이전했습니다.**

- **방문자 중복 체크**는 Redis에 `hostId + IP` 조합을 키로 저장하고,
    
- **조회수 증가**는 Redis의 `INCR` 명령을 활용해 원자적으로 처리했습니다.
    

초기에는 `hostId` 기준으로 Redisson 분산락을 걸고, Redis에서 값을 조회 후 수정하여 저장하는 방식이었지만,  
락을 소유하는 시간이 길어지고 임계영역도 넓어져 오히려 병목이 발생했습니다.

이에 **락 범위를 세분화**하고, **INCR 연산은 락 없이**, **중복 체크만 분산락으로 보호**하는 구조로 개선했습니다.

- **락 기준을 `hostId + IP` 조합**으로 바꿔서 병렬성을 높였고
    
- **조회수 증가 처리는 락 없이 INCR로 즉시 처리**하도록 변경했습니다.
    

이 구조 변경 이후 **락 경쟁이 크게 줄고, 응답 시간도 단축**되었으며,  
TPS 기준으로 약 **580 → 1100 이상**, **처리량이 2배 가까이 개선**되었습니다.

    
- 해당 문제로 인해 시스템에 어떤 영향을 미쳤나요?
- 방문자 수 로직을 개선하기 위해 어떤 기술을 도입하셨나요?
##### Async 사용 이유
✅ `@Async` 도입 이유와 효과

기존에는 사용자가 프로필에 접근할 때마다, **방문자 중복 체크 및 조회수 증가 로직을 동기적으로 처리**하고 있었습니다.  
이로 인해 전체 API 응답 시간이 길어지고, TPS가 떨어지는 문제가 있었습니다.

이를 해결하기 위해, **조회수 증가 로직을 `@Async`를 이용해 비동기 처리**로 전환했습니다.

- 사용자의 프로필 응답은 **즉시 반환**하고
    
- 조회수 증가 및 Redis 갱신은 **백그라운드 스레드에서 처리**되도록 변경했습니다.

> 결과적으로 API 응답 속도가 개선되고, TPS도 크게 증가하는 성과를 얻었습니다.

##### Async를 사용하는 데 있어 어떤 트레이드오프가 있다고 생각하나요?
 **성능 향상 vs. 자원 고갈 위험**

- 비동기로 처리하면 TPS가 향상되고 응답 시간이 줄어들지만,  
    **스레드 풀 설정이 부적절하거나 요청량이 폭주하면**  
    스레드가 쌓이면서 **메모리 과부하나 RejectedExecutionException**이 발생할 수 있습니다.
    
- 실제로 저도 기본 `SimpleAsyncTaskExecutor`를 사용하다 스레드 자원이 고갈된 경험이 있어,  
    이후 `ThreadPoolTaskExecutor`를 명시적으로 설정해 해결했습니다.
---
 2. **응답 최적화 vs. 예외 감지 어려움**

- `@Async`는 호출자와 실행자가 분리되기 때문에, **실패해도 사용자나 호출자는 이를 인지할 수 없습니다.**
    
- 예외가 전달되지 않기 때문에, **로깅, 모니터링 체계가 반드시 함께 설계되어야** 합니다.
3. **비동기 처리 vs. 트랜잭션 일관성**
- `@Async`는 별도 스레드에서 동작하기 때문에, 부모 트랜잭션과 **컨텍스트가 분리**됩니다.
    
- 트랜잭션이 완료되기 전에 비동기 작업이 먼저 실행되면, **데이터 정합성에 문제가 생길 수 있습니다.**
    
- 그래서 저는 비동기 로직을 트랜잭션 이후에 안전하게 호출하거나,  
    큐 기반 처리로 전환할 수 있는 구조도 함께 고려했습니다.
    
3. **단순 처리 vs. 순서 보장 필요성**

- `@Async`는 작업 순서나 완료 시점을 보장하지 않기 때문에,  
    **실시간성이나 순차적 처리가 필요한 작업에는 적합하지 않습니다.**
    
- 저는 Redis `INCR`처럼 **원자성이 보장되는 작업에 한해서** 비동기를 도입했습니다.
✅ 결론

> 따라서 `@Async`는 무조건 적용하기보다는,  
> **비동기로 분리해도 결과가 치명적이지 않고,**  
> **지연되더라도 시스템 정합성에 영향을 주지 않는 작업에 한해서 사용하는 것이 안전**하다고 판단하고 있습니다.

#### 8.  프로젝트 아키텍처 설명
#### 9. ELB를 사용한 이유
#### 10. 복합 인덱스를 사용한 이유
##### 복합 인덱스를 생성할 때 성능 최적화에 도움이 되기도 하지만, 단점도 분명 존재합니다. 이에 대해 어떻게 생각하시나요?
> 복합 인덱스는 조회 성능을 크게 개선할 수 있지만,  
> 동시에 **쓰기 성능 저하나 인덱스 갱신에 따른 락 경합** 등의 단점도 있다고 생각합니다.

> 실제로 인덱스를 생성하면 매번 데이터 수정 시 인덱스도 함께 갱신되어야 하기 때문에,  
> **쓰기 처리량이 많은 시스템에서는 오히려 병목 요인이 될 수 있습니다.**

> 하지만 제가 복합 인덱스를 생성했던 케이스에서는,  
> **해당 API의 트래픽 패턴이 조회:쓰기 비율이 약 8:1로 조회 중심의 구조**였고,  
> 해당 인덱스가 **추후 다른 조회 기능에서도 재사용될 가능성이 높다고 판단**했습니다.

> 따라서 **쓰기 비용보다 읽기 성능 향상이 훨씬 크다고 판단해 복합 인덱스를 적용**했고,  
> 실제로 조회 속도가 유의미하게 개선되어 전체 API 응답 성능에도 긍정적인 영향을 줄 수 있었습니다.
##### 복합 인덱스 말고 다른 방법으로 성능개선할 방법은 없나요
> 복합 인덱스는 성능 개선에 도움이 될 수 있지만, **항상 기대만큼 효과를 보장하지는 않는다고 생각합니다.**
> 
> 실제로 복합 인덱스를 활용해 성능 개선을 기대했지만, **쿼리 패턴과 데이터 분포 등의 영향으로 개선 효과가 미미**했던 경험이 있습니다.  
> 오히려 **N+1 문제를 해결하면서 쿼리 수와 I/O가 크게 줄었고**, 전체 응답 시간이 개선되는 효과를 체감했습니다.
> 
> 이처럼 인덱스 외에도 다양한 최적화 기법이 있다고 생각합니다.  
> 예를 들어,
> 
> - **Join 전략을 잘 활용해 필요한 데이터만 조회**하거나
>     
> - **Offset 기반 페이징 대신 커서 기반으로 전환**하여 불필요한 스캔을 줄이는 것도 좋은 접근입니다.
>     
> 
> 따라서 저는 항상 문제의 원인을 먼저 정확히 파악하고, **인덱스 외에도 쿼리 구조, 캐시, 트래픽 특성까지 함께 고려해** 성능 개선 방향을 판단하려고 합니다.

##### N+1 문제가 발생한 이유가 무엇인가요?
**지연 로딩(Lazy Loading)** 때문에 자주 발생하며, 쿼리 성능 저하의 대표적인 원인 중 하나입니다. 아래에 개념과 원인을 정리해드립니다.

✅ N+1 문제란?

- 하나의 쿼리(N=1)로 **부모 엔티티들을 조회**한 뒤,
    
- 각 부모마다 연관된 자식 엔티티를 **별도의 쿼리(N개)**로 조회하면서
    
- **총 N+1개의 쿼리가 실행되는 비효율적인 상황**을 말합니다.
    
✅ 발생 원인
✔ 1. **JPA의 지연 로딩 전략 (Lazy Loading)**

- JPA에서는 연관 관계가 기본적으로 `LAZY`로 설정되어 있습니다.
    
- 부모 엔티티를 먼저 조회하고, 연관된 자식 엔티티를 조회할 때 실제 SQL이 **개별적으로 실행**됩니다.
 ✔ 2. **조회 대상이 컬렉션/객체인 연관 관계 필드**

- `@OneToMany`, `@ManyToOne`, `@OneToOne` 등 연관 필드를 **루프 내에서 접근할 경우**  
    지연 로딩으로 인해 매번 쿼리가 발생합니다.


#### 11. 퍼사드 패턴을 활용한 이유
##### 서비스가 비대화 되었다고 하셨는데, 어떤 상황에서 서비스가 커지게 되었나요?
처음에는 서비스가 단순해서 하나의 `Service` 클래스에서 여러 기능을 같이 구현해도 큰 문제가 없었는데요,  
점점 기능이 많아지다 보니까 한 서비스에서 **여러 도메인의 repository나 다른 서비스를 직접 참조**하게 되는 일이 많아졌습니다.

예를 들어, 그룹 관련 기능을 처리하는 `GroupService`에서 프로필 데이터를 조회하거나 수정하기 위해 `ProfileService`를 직접 호출하는 식으로요.  
이렇게 되니까 클래스 자체가 비대해지고, 서비스 간에 **서로 참조하는 구조**가 생기면서 **순환 참조 가능성**도 생기더라고요.

또 하나의 API가 여러 도메인을 엮어서 처리하게 되니까 **테스트도 어려워지고**, 특정 도메인만 독립적으로 수정하기도 힘들어졌습니다.

그래서 구조를 정리하면서, 도메인별로 **읽기/쓰기 책임을 분리해서 Reader와 Writer로 나누고**,  
API 단에서는 이들을 감싸는 **퍼사드(Facade) 서비스**를 하나 만들어서 의존성 방향을 단순화시켰습니다.

이렇게 나누고 나니 각 도메인 서비스는 독립적으로 테스트가 가능하고,  
API 단에서는 하나의 퍼사드만 의존하니까 **의존성도 깔끔해지고 유지보수성도 훨씬 좋아졌습니다.**

##### 퍼사드 패턴을 사용하면서 단점은 없었나요?”
퍼사드 패턴을 도입하면서 구조가 깔끔해지고 의존성도 정리되긴 했지만, 단점도 분명히 느꼈습니다.

먼저, 퍼사드가 **너무 많은 도메인을 한 데서 orchestration 하게 되다 보니**,  
퍼사드 자체가 다시 **비대해질 수 있는 가능성**이 생기더라고요.  
실제로 API가 복잡해질수록 퍼사드에 로직이 몰리게 돼서,  
퍼사드가 또 하나의 거대한 서비스처럼 되는 걸 방지하려고 **비즈니스 로직은 Reader/Writer에만 두고**, 퍼사드는 최대한 얇게 유지하려고 신경 썼습니다.

또 한 가지는, 퍼사드를 새로 만들면서 **호출 흐름이 한 단계 더 생기게 되니까**,  
코드 흐름을 처음 보는 사람 입장에서는 “이 서비스가 어디까지 역할을 하는지”를 바로 파악하기 어려운 점도 있었습니다.  
그래서 문서화나 메서드 명세를 명확히 해주는 게 필요했고요.

이런 단점들이 있긴 했지만, 결과적으로는 서비스 간 결합도를 줄이고 유지보수를 쉽게 만드는 데 도움이 됐다고 생각합니다.

##### 퍼사드 패턴을 굳이 사용해야 했나요?
네, 사실 퍼사드 패턴이 꼭 필요한 구조는 아닐 수도 있었고, 단순히 서비스 클래스를 여러 개로 쪼개는 것만으로도 어느 정도는 구조 정리가 가능했을 거라고 생각합니다.

그런데 문제는, 도메인 간의 의존 관계가 점점 많아지면서 **AService가 BService를 직접 호출하고, BService는 또 CService를 호출하는** 식으로  
서비스 간 **순환 구조가 생길 수 있었고**, 테스트나 변경에 취약해지는 상황이 반복됐습니다.

그래서 저는 **서비스 간 의존을 끊고, 도메인별 로직은 Reader/Writer에만 넣고**,  

**API 레벨에서는 퍼사드 하나만 거치도록** 해서 호출 흐름을 명확하게 만들자는 판단을 했습니다.

퍼사드를 얇게 유지하면서 도메인 로직은 분산하고, 퍼사드는 **조합과 흐름 제어만 담당하게 하자**는 구조로 정리했기 때문에  
결과적으로 **의존성 관리, 변경 대응, 테스트 구성 측면에서 이점이 컸습니다.**

굳이 퍼사드를 써야 하는 건 아니었지만, 저희 프로젝트 상황에서는 **구조 안정성과 유지보수 측면에서 의미 있는 선택**이었다고 생각합니다.

##### 퍼사드에 대해 테스트는 어떻게 하셨나요?
> 퍼사드는 여러 도메인의 Reader/Writer를 조합해서 로직을 실행하는 계층이라,  
> 테스트할 때는 퍼사드 자체를 **단위 테스트보다는 작은 통합 테스트**에 가깝게 다뤘습니다.
> 
> 내부에서 사용하는 Reader나 Writer는 모두 **mock 객체로 주입해서**,  
> 퍼사드가 올바른 조합 순서로 각 도메인 로직을 호출하는지, 조건 분기나 예외 흐름이 정상적인지를 검증했습니다.
> 
> 예를 들어, 그룹 API 퍼사드에서 ‘그룹 정보를 조회하고, 거기에 속한 유저 프로필을 불러온다’는 흐름이 있다면,  
> 그룹 Reader에서 groupId를 반환하게 Mock 설정하고,  
> 프로필 Reader가 그 ID를 받아 호출되는지를 `verify`로 확인했습니다.
> 
> 퍼사드의 책임은 로직 조합과 흐름 제어이기 때문에, 내부 도메인 로직의 정확성까지 검증하진 않았고요.  
> **각 도메인의 Reader/Writer는 별도로 단위 테스트를 작성해서 책임을 분리**했습니다.
> 
> 이렇게 하니까 테스트도 분산되고, 퍼사드 변경이 생겨도 내부 도메인 테스트는 그대로 유지할 수 있어 유지보수에도 도움이 됐습니다.
#### 12. 데드락이 발생한 이유와 연관관계를 제거한 이유
##### 데드락이 발생한 이유에 대해 설명해 주세요
저희 프로젝트에서 데드락이 발생한 이유는, `Answer` 테이블이 `User` 테이블을 외래키로 참조하고 있었기 때문입니다.

`Answer`를 저장할 때, 데이터베이스는 외래키 제약조건을 만족하는지 확인하기 위해  
해당 `User` 레코드가 존재하는지 검사하고, 이 과정에서 **공유락(S Lock)** 을 걸게 됩니다.

그런데 같은 트랜잭션 안에서 **포인트를 증가시키는 `UPDATE user` 쿼리**도 함께 실행되면서  
이번에는 같은 레코드에 **베타락(X Lock)** 을 걸려고 시도하게 됩니다.

이 상황에서 두 개의 트랜잭션이 서로 S Lock을 물고 X Lock을 요청하게 되면  
서로의 락이 풀리길 기다리는 **락 대기 순환(Circular Wait)** 이 발생하게 되고,  
결국 **데드락(Deadlock)** 이 발생합니다.

이건 **DB의 무결성 검사 로직과 트랜잭션 내 락 순서 충돌**로 인한 문제였습니다.  
그래서 해결책으로는 `User`와의 연관관계를 끊고, **userId만 필드로 저장해서**  
무결성 검사 자체가 일어나지 않도록 처리해서 데드락을 해결했습니다.

##### 연관관계를 제거하면 정합성은 어떻게 보장했나요?
예를 들어 `Answer`를 등록할 때, 입력으로 들어온 `userId`가 실제로 존재하는지  
사전에 `UserRepository.existsById(userId)` 같은 메서드를 사용해서 체크하고,  
존재하지 않으면 예외를 던지는 방식으로 처리했습니다.

이렇게 하면 비즈니스 흐름상 문제가 되는 데이터가 DB에 들어가는 걸 막을 수 있고,  
동시에 DB 입장에서는 외래키 무결성 검사를 하지 않기 때문에 **락이 걸리지 않아 데드락도 피할 수 있습니다.**

그 책임을 명확히 인지하고 필요한 검증 로직을 추가함으로써 일관성을 유지했습니다.
#### 13. 더미데이터를 설정한 이유 및 vuser 설정 이유
#### 14. 테스트 자동화
#### 15. 필터가 아닌 인터셉트를 이용해서 로그인을 구현한 이유
#### 16. 토스페이 안붙힌 이유

