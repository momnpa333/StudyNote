### **캐시 읽기 전략 (Read Cache Strategy)**

#### **Look Aside 패턴**

- Cache Aside 패턴이라고도 불림.
- 데이터를 찾을때 우선 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략.   
    만일 캐시에 데이터가 없으면 DB에서 조회함.
- 반복적인 읽기가 많은 호출에 적합.
- 캐시와 DB가 분리되어 가용되기 때문에 원하는 데이터만 별도로 구성하여 캐시에 저장
- 캐시와 DB가 분리되어 가용되기 때문에 캐시 장애 대비 구성이 되어있음.  
    만일 redis가 다운 되더라도 DB에서 데이터를 가져올수 있어 서비스 자체는 문제가 없음.
- 대신에 캐시에 붙어있던 connection이 많았다면, redis가 다운된 순간 순간적으로 DB로 몰려서 부하 발생

출처: [https://inpa.tistory.com/entry/REDIS-📚-캐시Cache-설계-전략-지침-총정리](https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC) [Inpa Dev 👨‍💻:티스토리]

#### **Read Through 패턴**

- 캐시에서만 데이터를 읽어오는 전략 (inline cache)
- Look Aside 와 비슷하지만 **데이터 동기화를 라이브러리 또는 캐시 제공자에게 위임**하는 방식이라는 차이가 있음.
- 따라서 데이터를 조회하는데 있어 전체적으로 속도가 느림.
- 또한 데이터 조회를 전적으로 캐시에만 의지하므로, redis가 다운될 경우 서비스 이용에 차질이 생길수 있음.
- 대신에 캐시와 DB간의 데이터 동기화가 항상 이루어져 데이터 정합성 문제에서 벗어날수 있음
- 역시 읽기가 많은 워크로드에 적합

출처: [https://inpa.tistory.com/entry/REDIS-📚-캐시Cache-설계-전략-지침-총정리](https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC) [Inpa Dev 👨‍💻:티스토리]

### **캐시 쓰기 전략 (Write Cache Strategy)**

#### **Write Back 패턴**

- Write Behind 패턴 이라고도 불림.
- 캐시와 DB 동기화를 비동기하기 때문에 동기화 과정이 생략
- 데이터를 저장할때 DB에 바로 쿼리하지않고, 캐시에 모아서 일정 주기 배치 작업을 통해 DB에 반영
- 캐시에 모아놨다가 DB에 쓰기 때문에 쓰기 쿼리 회수 비용과 부하를 줄일 수 있음
- Write가 빈번하면서 Read를 하는데 많은 양의 Resource가 소모되는 서비스에 적합
- 데이터 정합성 확보
- 자주 사용되지 않는 불필요한 리소스 저장.
- 캐시에서 오류가 발생하면 데이터를 영구 소실함.

출처: [https://inpa.tistory.com/entry/REDIS-📚-캐시Cache-설계-전략-지침-총정리](https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC) [Inpa Dev 👨‍💻:티스토리]

캐시에 모든 데이터를 다 담아둘 수 없기 때문에, 캐시의 크기가 제한되고 그에 따라 캐시가 대체되어야 합니다. 캐시 교체 알고리즘에 따라 어떤 파일을 버리고 새로운 캐시를 저장할지 결정하는 것이 캐시 교체 알고리즘입니다.

> 종류

1. FIFO(First in First Out)

 - 가장 먼저 들어간 캐시를 교체.

2. LFU(Least Frequently Used)

 - 사용 횟수가 가장 적은 캐시를 교체.

3. LRU(Least Recently Used)

 - 가장 오랫동안 사용되지 않은 것 교체

> LRU(Least Recently Used) 캐시 동작 방식

 가장 오랫동안 사용되지 않은 파일을 교체하는 정책으로, Doubly Linked List와 HashMap으로 구현됩니다.

> Doubly Linked List

 Doubly Linked List는 새로 추가되면 Tail에 추가되므로, Head에 가까울수록 오래 사용되지 않은 캐시이고 크기가 부족하면 Head의 캐시를 지우고 Tail에 새로운 캐시를 붙여 저장합니다.

 LRU에서는 맨 앞에 있는 캐시를 지우고, 맨 뒤에 추가하는 동작만 구현되면 되므로 탐색에 대한 시간 복잡도가 O(1)이 됩니다.

> HashMap

 HashMap 자체는 Key와 Value로 구성되어 캐시와 달리 교체에 대한 별도의 정책이 없습니다.

 또한, 해싱(Hashing)을 사용하기 때문에 데이터의 검색이 빠르게 처리됩니다. 키가 중복저장 되지 않으므로, LRU에서 실제 데이터를 캐시에서 불러오는데 시간 복잡도가 O(1)이 됩니다

> LRU 캐시 구현

 간단한 형태의 LRU 캐시를 구현해 보았습니다. Kotlin으로 간단하게 사용할 DoublyLinkedList와 Node를 구현하고, MutableMap이 HashMap으로 구현되어 있으므로 이를 이용해 데이터를 저장합니다.